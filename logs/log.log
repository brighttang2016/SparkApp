[INFO ]2016-12-29 16:53:12  [nioEventLoopGroup-4-3:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):86667] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 16:53:12  [nioEventLoopGroup-4-3:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):86667] - Rdd服务
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):302] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):303] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):303] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - Changing view acls to: pujjr
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):326] - Changing modify acls to: pujjr
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - Changing view acls groups to: 
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - Changing modify acls groups to: 
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):328] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):671] - Successfully started service 'sparkDriver' on port 65533.
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):687] - Registering MapOutputTracker
[INFO ]2016-12-29 16:58:08  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):704] - Registering BlockManagerMaster
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):789] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-6fb975de-f633-491b-91c2-92988027baa1
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):807] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):873] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):939] - Logging initialized @1451ms
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1015] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@366ef90e{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@33e01298{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@73ff4fae{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1034] - Started o.s.j.s.ServletContextHandler@b968a76{/storage,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1034] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1034] - Started o.s.j.s.ServletContextHandler@2611b9a3{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1034] - Started o.s.j.s.ServletContextHandler@54227100{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1035] - Started o.s.j.s.ServletContextHandler@6b5894c8{/environment,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1035] - Started o.s.j.s.ServletContextHandler@1433046b{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1035] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1035] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1036] - Started o.s.j.s.ServletContextHandler@5778826f{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1036] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1041] - Started o.s.j.s.ServletContextHandler@4763c727{/static,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1042] - Started o.s.j.s.ServletContextHandler@72445aba{/,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1043] - Started o.s.j.s.ServletContextHandler@61bcd567{/api,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1043] - Started o.s.j.s.ServletContextHandler@1c80e49b{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1050] - Started ServerConnector@2cac4385{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1050] - Started @1563ms
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1051] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1053] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 16:58:09  [appclient-register-master-threadpool-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1145] - Connecting to master spark://192.168.137.16:7077...
[INFO ]2016-12-29 16:58:09  [netty-rpc-connection-0:org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:250):1187] - Successfully created connection to /192.168.137.16:7077 after 25 ms (0 ms spent in bootstraps)
[INFO ]2016-12-29 16:58:09  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1255] - Connected to Spark cluster with app ID app-20161225161528-0004
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1271] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49181.
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1272] - Server created on 172.18.10.41:49181
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1274] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49181)
[INFO ]2016-12-29 16:58:09  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1277] - Registering block manager 172.18.10.41:49181 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49181)
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1279] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49181)
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1391] - Started o.s.j.s.ServletContextHandler@4acf72b6{/metrics/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1402] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WARN ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1405] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1434] - Started o.s.j.s.ServletContextHandler@632aa1a3{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1434] - Started o.s.j.s.ServletContextHandler@3b582111{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1435] - Started o.s.j.s.ServletContextHandler@130a0f66{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1436] - Started o.s.j.s.ServletContextHandler@12365c88{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1437] - Started o.s.j.s.ServletContextHandler@6e0d4a8{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 16:58:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1449] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 16:58:09  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1463] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):360] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):362] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):362] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):384] - Changing view acls to: pujjr
[INFO ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):385] - Changing modify acls to: pujjr
[INFO ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):385] - Changing view acls groups to: 
[INFO ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):386] - Changing modify acls groups to: 
[INFO ]2016-12-29 16:58:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):386] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):774] - Successfully started service 'sparkDriver' on port 49219.
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):795] - Registering MapOutputTracker
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):815] - Registering BlockManagerMaster
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):902] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-8275a8ab-963b-4083-9b5a-009cecd9dc05
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):923] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):999] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):1072] - Logging initialized @1796ms
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1159] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1178] - Started o.s.j.s.ServletContextHandler@23b3aa8c{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1179] - Started o.s.j.s.ServletContextHandler@99407c2{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1179] - Started o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1180] - Started o.s.j.s.ServletContextHandler@226eba67{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1180] - Started o.s.j.s.ServletContextHandler@1cb7936c{/stages,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1180] - Started o.s.j.s.ServletContextHandler@35342d2f{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1181] - Started o.s.j.s.ServletContextHandler@128c502c{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1181] - Started o.s.j.s.ServletContextHandler@45667d98{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1181] - Started o.s.j.s.ServletContextHandler@65eabaab{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1182] - Started o.s.j.s.ServletContextHandler@7123be6c{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1182] - Started o.s.j.s.ServletContextHandler@1de9d54{/storage,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1182] - Started o.s.j.s.ServletContextHandler@77a2aa4a{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1183] - Started o.s.j.s.ServletContextHandler@47ad69f7{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1183] - Started o.s.j.s.ServletContextHandler@2b917fb0{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1183] - Started o.s.j.s.ServletContextHandler@5e5073ab{/environment,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1183] - Started o.s.j.s.ServletContextHandler@3c4262d1{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1184] - Started o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1184] - Started o.s.j.s.ServletContextHandler@30c0d731{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1184] - Started o.s.j.s.ServletContextHandler@6d5037a9{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1184] - Started o.s.j.s.ServletContextHandler@422b8438{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1191] - Started o.s.j.s.ServletContextHandler@30669dac{/static,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1191] - Started o.s.j.s.ServletContextHandler@629adce{/,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1192] - Started o.s.j.s.ServletContextHandler@6a282fdd{/api,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1192] - Started o.s.j.s.ServletContextHandler@743c6ce4{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1200] - Started ServerConnector@499683c4{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1201] - Started @1926ms
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1201] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1203] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 16:58:23  [appclient-register-master-threadpool-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1316] - Connecting to master spark://192.168.137.16:7077...
[INFO ]2016-12-29 16:58:23  [netty-rpc-connection-0:org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:250):1367] - Successfully created connection to /192.168.137.16:7077 after 24 ms (0 ms spent in bootstraps)
[INFO ]2016-12-29 16:58:23  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1459] - Connected to Spark cluster with app ID app-20161225161542-0005
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1479] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49242.
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1480] - Server created on 172.18.10.41:49242
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1483] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49242)
[INFO ]2016-12-29 16:58:23  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1486] - Registering block manager 172.18.10.41:49242 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49242)
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1489] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49242)
[INFO ]2016-12-29 16:58:23  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1626] - Started o.s.j.s.ServletContextHandler@6cd64ee8{/metrics/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1646] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WARN ]2016-12-29 16:58:23  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1654] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 16:58:24  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1686] - Started o.s.j.s.ServletContextHandler@6ad16c5d{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 16:58:24  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1687] - Started o.s.j.s.ServletContextHandler@6f911326{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:24  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1688] - Started o.s.j.s.ServletContextHandler@4821aa9f{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 16:58:24  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1689] - Started o.s.j.s.ServletContextHandler@32130e61{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 16:58:24  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1691] - Started o.s.j.s.ServletContextHandler@4596f8f3{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 16:58:24  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1704] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 16:58:24  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1719] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 16:58:48  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):26560] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 16:58:51  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):28711] - Rdd服务
[INFO ]2016-12-29 16:59:20  [nioEventLoopGroup-4-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):58073] - Code generated in 986.042467 ms
[INFO ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):301] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):302] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):302] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):326] - Changing view acls groups to: 
[INFO ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:00:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):664] - Successfully started service 'sparkDriver' on port 49281.
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):680] - Registering MapOutputTracker
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):696] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):781] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-98cc36b0-2e23-4ecf-b942-78c902915088
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):798] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):867] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):931] - Logging initialized @1434ms
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1005] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1020] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1021] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1021] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1022] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1022] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1022] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1022] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1025] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1025] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1025] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1025] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1039] - Started ServerConnector@38385b21{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1039] - Started @1543ms
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1039] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1041] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:00:36  [appclient-register-master-threadpool-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1129] - Connecting to master spark://192.168.137.16:7077...
[INFO ]2016-12-29 17:00:36  [netty-rpc-connection-0:org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:250):1172] - Successfully created connection to /192.168.137.16:7077 after 24 ms (0 ms spent in bootstraps)
[INFO ]2016-12-29 17:00:36  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1242] - Connected to Spark cluster with app ID app-20161225161755-0006
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1258] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49303.
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1259] - Server created on 172.18.10.41:49303
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1261] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49303)
[INFO ]2016-12-29 17:00:36  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1264] - Registering block manager 172.18.10.41:49303 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49303)
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1266] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49303)
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1378] - Started o.s.j.s.ServletContextHandler@a23a01d{/metrics/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1392] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WARN ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1395] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1424] - Started o.s.j.s.ServletContextHandler@1af1347d{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1425] - Started o.s.j.s.ServletContextHandler@20765ed5{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1425] - Started o.s.j.s.ServletContextHandler@76b0ae1b{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1426] - Started o.s.j.s.ServletContextHandler@4c432866{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1428] - Started o.s.j.s.ServletContextHandler@199e4c2b{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:00:36  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1440] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:00:36  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1453] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:00:41  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):5844] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:00:41  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):5904] - Rdd服务
[INFO ]2016-12-29 17:00:43  [nioEventLoopGroup-4-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8242] - Code generated in 157.914479 ms
[INFO ]2016-12-29 17:00:43  [nioEventLoopGroup-4-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):8310] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:00:43  [nioEventLoopGroup-4-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):8311] - Rdd服务
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):303] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):304] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):304] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):328] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):328] - Changing view acls groups to: 
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):329] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):329] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):661] - Successfully started service 'sparkDriver' on port 49342.
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):680] - Registering MapOutputTracker
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):696] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):782] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-0e5873b1-84a2-4462-894e-7fb8b3304fd9
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):800] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:00:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):868] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:00:53  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):938] - Logging initialized @1449ms
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1025] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1040] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1041] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1042] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1042] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1043] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1044] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1044] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1044] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1045] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1045] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1046] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1046] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1046] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1054] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1055] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1056] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1056] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1062] - Started ServerConnector@3fc9dfc5{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1063] - Started @1576ms
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1063] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1065] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:00:54  [appclient-register-master-threadpool-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1156] - Connecting to master spark://192.168.137.16:7077...
[INFO ]2016-12-29 17:00:54  [netty-rpc-connection-0:org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:250):1199] - Successfully created connection to /192.168.137.16:7077 after 25 ms (0 ms spent in bootstraps)
[INFO ]2016-12-29 17:00:54  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1276] - Connected to Spark cluster with app ID app-20161225161813-0007
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1295] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49364.
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1296] - Server created on 172.18.10.41:49364
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1298] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49364)
[INFO ]2016-12-29 17:00:54  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1302] - Registering block manager 172.18.10.41:49364 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49364)
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1305] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49364)
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1430] - Started o.s.j.s.ServletContextHandler@4acf72b6{/metrics/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1481] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WARN ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1485] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1517] - Started o.s.j.s.ServletContextHandler@632aa1a3{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1518] - Started o.s.j.s.ServletContextHandler@3b582111{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1518] - Started o.s.j.s.ServletContextHandler@130a0f66{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1519] - Started o.s.j.s.ServletContextHandler@12365c88{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1521] - Started o.s.j.s.ServletContextHandler@6e0d4a8{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:00:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1532] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:00:54  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1544] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:01:30  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):37446] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:01:30  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):37496] - Rdd服务
[INFO ]2016-12-29 17:01:32  [nioEventLoopGroup-4-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):39738] - Code generated in 141.689005 ms
[INFO ]2016-12-29 17:01:32  [nioEventLoopGroup-4-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):39804] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:01:32  [nioEventLoopGroup-4-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):39805] - Rdd服务
[INFO ]2016-12-29 17:04:33  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):296] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):298] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):298] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):321] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):321] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):322] - Changing view acls groups to: 
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):322] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):323] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):657] - Successfully started service 'sparkDriver' on port 49407.
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):671] - Registering MapOutputTracker
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):687] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):796] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-e52c14e6-d58e-4f76-86f5-8c3b31e94bab
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):813] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):878] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):944] - Logging initialized @1433ms
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1015] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1034] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1034] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1038] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1039] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1040] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1040] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1046] - Started ServerConnector@3fc9dfc5{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:04:34  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1046] - Started @1535ms
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1047] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:04:34  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1049] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:04:35  [appclient-register-master-threadpool-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1133] - Connecting to master spark://192.168.137.16:7077...
[INFO ]2016-12-29 17:04:35  [netty-rpc-connection-0:org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:250):1173] - Successfully created connection to /192.168.137.16:7077 after 23 ms (0 ms spent in bootstraps)
[INFO ]2016-12-29 17:04:35  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1239] - Connected to Spark cluster with app ID app-20161225162154-0008
[INFO ]2016-12-29 17:04:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1255] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49429.
[INFO ]2016-12-29 17:04:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1256] - Server created on 172.18.10.41:49429
[INFO ]2016-12-29 17:04:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1258] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49429)
[INFO ]2016-12-29 17:04:35  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1261] - Registering block manager 172.18.10.41:49429 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49429)
[INFO ]2016-12-29 17:04:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1264] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49429)
[INFO ]2016-12-29 17:04:35  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1383] - Started o.s.j.s.ServletContextHandler@4acf72b6{/metrics/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1394] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WARN ]2016-12-29 17:04:35  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1399] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:04:35  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1429] - Started o.s.j.s.ServletContextHandler@632aa1a3{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:04:35  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1429] - Started o.s.j.s.ServletContextHandler@3b582111{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:35  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1430] - Started o.s.j.s.ServletContextHandler@130a0f66{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:04:35  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1431] - Started o.s.j.s.ServletContextHandler@12365c88{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:04:35  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1433] - Started o.s.j.s.ServletContextHandler@6e0d4a8{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:04:35  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1444] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:04:35  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1456] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:04:43  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):9440] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:04:43  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):9496] - Rdd服务
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):310] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):312] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):312] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):337] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):337] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):338] - Changing view acls groups to: 
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):338] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):339] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):663] - Successfully started service 'sparkDriver' on port 49466.
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):680] - Registering MapOutputTracker
[INFO ]2016-12-29 17:05:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):697] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):781] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-fd9b9933-5193-4abe-9f27-192e0c2e0323
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):799] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):869] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):937] - Logging initialized @1445ms
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1012] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1027] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1038] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1039] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1040] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1040] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1046] - Started ServerConnector@3fc9dfc5{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1047] - Started @1556ms
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1047] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1049] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1120] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1145] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49475.
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1145] - Server created on 172.18.10.41:49475
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1147] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49475)
[INFO ]2016-12-29 17:05:29  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1149] - Registering block manager 172.18.10.41:49475 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49475)
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1152] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49475)
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1280] - Started o.s.j.s.ServletContextHandler@3ef41c66{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1296] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1324] - Started o.s.j.s.ServletContextHandler@b09fac1{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1325] - Started o.s.j.s.ServletContextHandler@61019f59{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1326] - Started o.s.j.s.ServletContextHandler@74518890{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1327] - Started o.s.j.s.ServletContextHandler@3f3ddbd9{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1328] - Started o.s.j.s.ServletContextHandler@71b1a49c{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:05:29  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1339] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:05:29  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1351] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:05:32  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):4452] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:05:32  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):4499] - Rdd服务
[INFO ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):299] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):301] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):301] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):323] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):323] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):324] - Changing view acls groups to: 
[INFO ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:06:09  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):654] - Successfully started service 'sparkDriver' on port 49529.
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):670] - Registering MapOutputTracker
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):686] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):768] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-de761c3a-67ee-4c24-87d0-c6a83ee93451
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):785] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):851] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):916] - Logging initialized @1431ms
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):992] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1008] - Started o.s.j.s.ServletContextHandler@7bc10d84{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1008] - Started o.s.j.s.ServletContextHandler@275fe372{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1008] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1009] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1009] - Started o.s.j.s.ServletContextHandler@26a4842b{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1009] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1009] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1009] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1010] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1010] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1011] - Started o.s.j.s.ServletContextHandler@4b3c354a{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1011] - Started o.s.j.s.ServletContextHandler@78fb9a67{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1011] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1011] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1012] - Started o.s.j.s.ServletContextHandler@b968a76{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1012] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1012] - Started o.s.j.s.ServletContextHandler@2611b9a3{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1012] - Started o.s.j.s.ServletContextHandler@54227100{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1013] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1013] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1018] - Started o.s.j.s.ServletContextHandler@3f446bef{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1019] - Started o.s.j.s.ServletContextHandler@7829b776{/,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1020] - Started o.s.j.s.ServletContextHandler@5778826f{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1020] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1028] - Started ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1028] - Started @1544ms
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1028] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1030] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1111] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1136] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49538.
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1137] - Server created on 172.18.10.41:49538
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1138] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49538)
[INFO ]2016-12-29 17:06:10  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1140] - Registering block manager 172.18.10.41:49538 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49538)
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1143] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49538)
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1255] - Started o.s.j.s.ServletContextHandler@c20be82{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1270] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1295] - Started o.s.j.s.ServletContextHandler@1b70203f{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1296] - Started o.s.j.s.ServletContextHandler@15051a0{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1296] - Started o.s.j.s.ServletContextHandler@62e8f862{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1297] - Started o.s.j.s.ServletContextHandler@3c49fab6{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1299] - Started o.s.j.s.ServletContextHandler@6c2d4cc6{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:06:10  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1332] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:06:11  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1344] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:06:13  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):4277] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:06:13  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):4327] - Rdd服务
[INFO ]2016-12-29 17:06:13  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:68):4328] - 666
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):306] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):308] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):308] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):337] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):339] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):340] - Changing view acls groups to: 
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):340] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):341] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):691] - Successfully started service 'sparkDriver' on port 49591.
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):707] - Registering MapOutputTracker
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):723] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):808] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-b482dcb3-3453-4ead-b7b4-fb5a866cdb62
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):825] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:08:14  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):894] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):960] - Logging initialized @1458ms
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1032] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1050] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1050] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1050] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1052] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1052] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1059] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1059] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1066] - Started ServerConnector@3fc9dfc5{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1066] - Started @1566ms
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1067] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1069] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1144] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1169] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49600.
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1170] - Server created on 172.18.10.41:49600
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1171] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49600)
[INFO ]2016-12-29 17:08:15  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1173] - Registering block manager 172.18.10.41:49600 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49600)
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1176] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49600)
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1295] - Started o.s.j.s.ServletContextHandler@3ef41c66{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1308] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1331] - Started o.s.j.s.ServletContextHandler@15051a0{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1332] - Started o.s.j.s.ServletContextHandler@b09fac1{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1333] - Started o.s.j.s.ServletContextHandler@3c49fab6{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1333] - Started o.s.j.s.ServletContextHandler@74518890{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1335] - Started o.s.j.s.ServletContextHandler@6134ac4a{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:08:15  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1345] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:08:15  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1357] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:08:18  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):4213] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:08:18  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):4265] - Rdd服务
[INFO ]2016-12-29 17:08:20  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6748] - Code generated in 149.393531 ms
[INFO ]2016-12-29 17:08:20  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6836] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:08:20  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6851] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:08:20  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6851] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:08:20  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6852] - Parents of final stage: List()
[INFO ]2016-12-29 17:08:20  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6853] - Missing parents: List()
[INFO ]2016-12-29 17:08:20  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6859] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:08:21  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6976] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[INFO ]2016-12-29 17:08:21  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7001] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:08:21  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7003] - Added broadcast_0_piece0 in memory on 172.18.10.41:49600 (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:08:21  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7006] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:08:21  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7010] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:08:21  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7011] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:08:21  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7046] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:08:21  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7052] - Running task 0.0 in stage 0.0 (TID 0)
[INFO ]2016-12-29 17:08:21  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7134] - Code generated in 12.20837 ms
[INFO ]2016-12-29 17:08:21  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7139] - closed connection
[INFO ]2016-12-29 17:08:21  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7151] - Finished task 0.0 in stage 0.0 (TID 0). 1181 bytes result sent to driver
[INFO ]2016-12-29 17:08:21  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7156] - Finished task 0.0 in stage 0.0 (TID 0) in 127 ms on localhost (1/1)
[INFO ]2016-12-29 17:08:21  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7158] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:08:21  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7160] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.140 s
[INFO ]2016-12-29 17:08:21  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7164] - Job 0 finished: count at RddServiceImpl.java:85, took 0.327919 s
[INFO ]2016-12-29 17:08:21  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:86):7266] - 666
[INFO ]2016-12-29 17:08:21  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7285] - Removed broadcast_0_piece0 on 172.18.10.41:49600 in memory (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):301] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):302] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):303] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):349] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):349] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):350] - Changing view acls groups to: 
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):351] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):351] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):676] - Successfully started service 'sparkDriver' on port 49638.
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):692] - Registering MapOutputTracker
[INFO ]2016-12-29 17:08:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):709] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):801] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-e713487b-0793-4475-99e7-17663f814ec5
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):820] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):896] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):963] - Logging initialized @1472ms
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1037] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1053] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1053] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1054] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1054] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1054] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1055] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1055] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1055] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1056] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1056] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1056] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1057] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1057] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1057] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1057] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1063] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1064] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1064] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1065] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1071] - Started ServerConnector@77ee5bcb{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1071] - Started @1581ms
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1071] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1073] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1142] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1165] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49647.
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1166] - Server created on 172.18.10.41:49647
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1168] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49647)
[INFO ]2016-12-29 17:08:57  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1171] - Registering block manager 172.18.10.41:49647 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49647)
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1173] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49647)
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1295] - Started o.s.j.s.ServletContextHandler@13c612bd{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1319] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1343] - Started o.s.j.s.ServletContextHandler@62df0ff3{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1343] - Started o.s.j.s.ServletContextHandler@62e8f862{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1344] - Started o.s.j.s.ServletContextHandler@4c5204af{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1345] - Started o.s.j.s.ServletContextHandler@14c053c6{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1346] - Started o.s.j.s.ServletContextHandler@73e132e0{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:08:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1356] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:08:57  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1368] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:09:01  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):5350] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:09:01  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):5398] - Rdd服务
[INFO ]2016-12-29 17:09:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7681] - Code generated in 152.582705 ms
[INFO ]2016-12-29 17:09:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7759] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7774] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7775] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7776] - Parents of final stage: List()
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7777] - Missing parents: List()
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7783] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7881] - Block broadcast_0 stored as values in memory (estimated size 12.0 KB, free 906.0 MB)
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7938] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.8 KB, free 906.0 MB)
[INFO ]2016-12-29 17:09:04  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7940] - Added broadcast_0_piece0 in memory on 172.18.10.41:49647 (size: 5.8 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7943] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7946] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:09:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7948] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:09:04  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7986] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:09:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7992] - Running task 0.0 in stage 0.0 (TID 0)
[INFO ]2016-12-29 17:09:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8339] - Code generated in 12.308829 ms
[INFO ]2016-12-29 17:09:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9059] - closed connection
[INFO ]2016-12-29 17:09:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9070] - Finished task 0.0 in stage 0.0 (TID 0). 1254 bytes result sent to driver
[INFO ]2016-12-29 17:09:05  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9075] - Finished task 0.0 in stage 0.0 (TID 0) in 1107 ms on localhost (1/1)
[INFO ]2016-12-29 17:09:05  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9077] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:09:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9080] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 1.122 s
[INFO ]2016-12-29 17:09:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9086] - Job 0 finished: count at RddServiceImpl.java:85, took 1.326043 s
[INFO ]2016-12-29 17:09:05  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:86):9088] - 666
[INFO ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):318] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):321] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):321] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):352] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):353] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):354] - Changing view acls groups to: 
[INFO ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):355] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:09:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):356] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):695] - Successfully started service 'sparkDriver' on port 49686.
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):711] - Registering MapOutputTracker
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):727] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):813] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-2fd081ae-455b-4fe8-a5ee-2fcfb2fe0d38
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):829] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):896] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):961] - Logging initialized @1465ms
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1034] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1047] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1048] - Started o.s.j.s.ServletContextHandler@366ef90e{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@33e01298{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1049] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1050] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1050] - Started o.s.j.s.ServletContextHandler@73ff4fae{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1050] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1050] - Started o.s.j.s.ServletContextHandler@b968a76{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@2611b9a3{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@54227100{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1051] - Started o.s.j.s.ServletContextHandler@6b5894c8{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1052] - Started o.s.j.s.ServletContextHandler@1433046b{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1052] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1052] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1052] - Started o.s.j.s.ServletContextHandler@5778826f{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1053] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1058] - Started o.s.j.s.ServletContextHandler@4763c727{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1059] - Started o.s.j.s.ServletContextHandler@72445aba{/,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1059] - Started o.s.j.s.ServletContextHandler@61bcd567{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1060] - Started o.s.j.s.ServletContextHandler@1c80e49b{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1067] - Started ServerConnector@2cac4385{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:09:21  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1067] - Started @1571ms
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1067] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1069] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:09:21  [appclient-register-master-threadpool-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1158] - Connecting to master spark://192.168.137.16:7077...
[INFO ]2016-12-29 17:09:21  [netty-rpc-connection-0:org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:250):1199] - Successfully created connection to /192.168.137.16:7077 after 23 ms (0 ms spent in bootstraps)
[INFO ]2016-12-29 17:09:21  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1268] - Connected to Spark cluster with app ID app-20161225162640-0009
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1285] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49708.
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1286] - Server created on 172.18.10.41:49708
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1288] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49708)
[INFO ]2016-12-29 17:09:21  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1291] - Registering block manager 172.18.10.41:49708 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49708)
[INFO ]2016-12-29 17:09:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1293] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49708)
[INFO ]2016-12-29 17:09:22  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1415] - Started o.s.j.s.ServletContextHandler@4acf72b6{/metrics/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1428] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WARN ]2016-12-29 17:09:22  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1431] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:09:22  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1463] - Started o.s.j.s.ServletContextHandler@632aa1a3{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:09:22  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1464] - Started o.s.j.s.ServletContextHandler@3b582111{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:22  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1465] - Started o.s.j.s.ServletContextHandler@130a0f66{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:09:22  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1465] - Started o.s.j.s.ServletContextHandler@12365c88{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:09:22  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1467] - Started o.s.j.s.ServletContextHandler@6e0d4a8{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:09:22  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1478] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:09:22  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1490] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:09:28  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):8023] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:09:28  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):8082] - Rdd服务
[INFO ]2016-12-29 17:09:30  [nioEventLoopGroup-4-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10343] - Code generated in 141.909516 ms
[INFO ]2016-12-29 17:09:31  [nioEventLoopGroup-4-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10405] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10418] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10419] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10419] - Parents of final stage: List()
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10421] - Missing parents: List()
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10427] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10550] - Block broadcast_0 stored as values in memory (estimated size 12.0 KB, free 906.0 MB)
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10587] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.8 KB, free 906.0 MB)
[INFO ]2016-12-29 17:09:31  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10618] - Added broadcast_0_piece0 in memory on 172.18.10.41:49708 (size: 5.8 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10621] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10625] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:09:31  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10627] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):300] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):301] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):301] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):326] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - Changing view acls groups to: 
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):328] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):681] - Successfully started service 'sparkDriver' on port 49756.
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):696] - Registering MapOutputTracker
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):713] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:11:53  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):795] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-dd463e6a-e6b6-4072-abf4-b47aa2686ca0
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):812] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):884] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):969] - Logging initialized @1495ms
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1057] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1073] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1073] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1074] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1074] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1074] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1075] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1075] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1075] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1076] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1076] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1077] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1077] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1077] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1077] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1078] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1078] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1078] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1078] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1079] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1079] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1086] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1087] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1088] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1088] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1103] - Started ServerConnector@3fc9dfc5{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1103] - Started @1630ms
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1103] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1107] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:11:54  [appclient-register-master-threadpool-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1213] - Connecting to master spark://192.168.137.16:7077...
[INFO ]2016-12-29 17:11:54  [netty-rpc-connection-0:org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:250):1263] - Successfully created connection to /192.168.137.16:7077 after 26 ms (0 ms spent in bootstraps)
[INFO ]2016-12-29 17:11:54  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1336] - Connected to Spark cluster with app ID app-20161225162913-0010
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1353] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49778.
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1354] - Server created on 172.18.10.41:49778
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1356] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49778)
[INFO ]2016-12-29 17:11:54  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1359] - Registering block manager 172.18.10.41:49778 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49778)
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1361] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49778)
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1475] - Started o.s.j.s.ServletContextHandler@4acf72b6{/metrics/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1509] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[WARN ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1513] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1541] - Started o.s.j.s.ServletContextHandler@632aa1a3{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1542] - Started o.s.j.s.ServletContextHandler@3b582111{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1542] - Started o.s.j.s.ServletContextHandler@130a0f66{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1543] - Started o.s.j.s.ServletContextHandler@12365c88{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1544] - Started o.s.j.s.ServletContextHandler@6e0d4a8{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:11:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1555] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:11:54  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1567] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:11:57  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):4336] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:11:57  [nioEventLoopGroup-4-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):4385] - Rdd服务
[INFO ]2016-12-29 17:11:59  [nioEventLoopGroup-4-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6696] - Code generated in 146.126603 ms
[INFO ]2016-12-29 17:11:59  [nioEventLoopGroup-4-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6758] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:11:59  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6772] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:11:59  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6772] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:11:59  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6773] - Parents of final stage: List()
[INFO ]2016-12-29 17:11:59  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6774] - Missing parents: List()
[INFO ]2016-12-29 17:11:59  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6780] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:12:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6916] - Block broadcast_0 stored as values in memory (estimated size 12.0 KB, free 906.0 MB)
[INFO ]2016-12-29 17:12:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6950] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.8 KB, free 906.0 MB)
[INFO ]2016-12-29 17:12:00  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6953] - Added broadcast_0_piece0 in memory on 172.18.10.41:49778 (size: 5.8 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:12:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6956] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:12:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6959] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:12:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6961] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):298] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):300] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):300] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):322] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):322] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):323] - Changing view acls groups to: 
[INFO ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):323] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:12:20  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):324] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):662] - Successfully started service 'sparkDriver' on port 49821.
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):688] - Registering MapOutputTracker
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):704] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):790] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-d227f650-90ef-4c3e-b409-5fa18dc81550
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):805] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):870] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):935] - Logging initialized @1475ms
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1008] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@5ed731d0{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@3234f74e{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@7bc10d84{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@275fe372{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1025] - Started o.s.j.s.ServletContextHandler@40e10ff8{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1025] - Started o.s.j.s.ServletContextHandler@557a1e2d{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1026] - Started o.s.j.s.ServletContextHandler@26a4842b{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1026] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1026] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1027] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@31e75d13{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@a5b0b86{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@4b3c354a{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@78fb9a67{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@73ff4fae{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@b968a76{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@2611b9a3{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@54227100{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1037] - Started o.s.j.s.ServletContextHandler@6b5894c8{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1037] - Started o.s.j.s.ServletContextHandler@1433046b{/,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1038] - Started o.s.j.s.ServletContextHandler@3f446bef{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1039] - Started o.s.j.s.ServletContextHandler@7829b776{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1048] - Started ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1048] - Started @1589ms
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1048] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1051] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1140] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1168] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49830.
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1169] - Server created on 172.18.10.41:49830
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1171] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49830)
[INFO ]2016-12-29 17:12:21  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1174] - Registering block manager 172.18.10.41:49830 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49830)
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1176] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49830)
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1303] - Started o.s.j.s.ServletContextHandler@c20be82{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1319] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1347] - Started o.s.j.s.ServletContextHandler@b09fac1{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1348] - Started o.s.j.s.ServletContextHandler@61019f59{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1349] - Started o.s.j.s.ServletContextHandler@74518890{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1350] - Started o.s.j.s.ServletContextHandler@3f3ddbd9{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1352] - Started o.s.j.s.ServletContextHandler@71b1a49c{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:12:21  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1363] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:12:21  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1377] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:12:24  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):4247] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:12:24  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):4301] - Rdd服务
[INFO ]2016-12-29 17:12:27  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6578] - Code generated in 155.60393 ms
[INFO ]2016-12-29 17:12:27  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6657] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6675] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6676] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6677] - Parents of final stage: List()
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6679] - Missing parents: List()
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6686] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6798] - Block broadcast_0 stored as values in memory (estimated size 12.0 KB, free 906.0 MB)
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6824] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.8 KB, free 906.0 MB)
[INFO ]2016-12-29 17:12:27  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6826] - Added broadcast_0_piece0 in memory on 172.18.10.41:49830 (size: 5.8 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6828] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6832] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:12:27  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6833] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:12:27  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6866] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:12:27  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6872] - Running task 0.0 in stage 0.0 (TID 0)
[INFO ]2016-12-29 17:12:27  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7246] - Code generated in 12.855909 ms
[INFO ]2016-12-29 17:12:28  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7932] - closed connection
[INFO ]2016-12-29 17:12:28  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7944] - Finished task 0.0 in stage 0.0 (TID 0). 1254 bytes result sent to driver
[INFO ]2016-12-29 17:12:28  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7949] - Finished task 0.0 in stage 0.0 (TID 0) in 1099 ms on localhost (1/1)
[INFO ]2016-12-29 17:12:28  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7950] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7954] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 1.112 s
[INFO ]2016-12-29 17:12:28  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7960] - Job 0 finished: count at RddServiceImpl.java:85, took 1.301243 s
[INFO ]2016-12-29 17:12:28  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):7974] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:12:28  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):7974] - Rdd服务
[INFO ]2016-12-29 17:12:28  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8161] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8162] - Got job 1 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8162] - Final stage: ResultStage 1 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8162] - Parents of final stage: List()
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8162] - Missing parents: List()
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8162] - Submitting ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8172] - Block broadcast_1 stored as values in memory (estimated size 12.0 KB, free 906.0 MB)
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8174] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KB, free 906.0 MB)
[INFO ]2016-12-29 17:12:28  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8175] - Added broadcast_1_piece0 in memory on 172.18.10.41:49830 (size: 5.8 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8176] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8176] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:12:28  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8176] - Adding task set 1.0 with 1 tasks
[INFO ]2016-12-29 17:12:28  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8178] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:12:28  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8178] - Running task 0.0 in stage 1.0 (TID 1)
[INFO ]2016-12-29 17:12:29  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8875] - closed connection
[INFO ]2016-12-29 17:12:29  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8877] - Finished task 0.0 in stage 1.0 (TID 1). 1254 bytes result sent to driver
[INFO ]2016-12-29 17:12:29  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8878] - ResultStage 1 (count at RddServiceImpl.java:85) finished in 0.702 s
[INFO ]2016-12-29 17:12:29  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8879] - Finished task 0.0 in stage 1.0 (TID 1) in 701 ms on localhost (1/1)
[INFO ]2016-12-29 17:12:29  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8879] - Job 1 finished: count at RddServiceImpl.java:85, took 0.717731 s
[INFO ]2016-12-29 17:12:29  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8882] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):309] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):310] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):310] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):335] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):335] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):336] - Changing view acls groups to: 
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):337] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):338] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):673] - Successfully started service 'sparkDriver' on port 49871.
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):689] - Registering MapOutputTracker
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):705] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):788] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-0359a247-4898-44c1-bdcd-dc5e133debdf
[INFO ]2016-12-29 17:12:54  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):805] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):871] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):940] - Logging initialized @1454ms
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1014] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1028] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1029] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1030] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1031] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1032] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1033] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1038] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1039] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1040] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1040] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1047] - Started ServerConnector@3fc9dfc5{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1047] - Started @1562ms
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1047] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1049] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1127] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1151] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49880.
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1152] - Server created on 172.18.10.41:49880
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1153] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49880)
[INFO ]2016-12-29 17:12:55  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1156] - Registering block manager 172.18.10.41:49880 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49880)
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1158] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49880)
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1299] - Started o.s.j.s.ServletContextHandler@3ef41c66{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1320] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1350] - Started o.s.j.s.ServletContextHandler@15051a0{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1351] - Started o.s.j.s.ServletContextHandler@b09fac1{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1352] - Started o.s.j.s.ServletContextHandler@3c49fab6{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1353] - Started o.s.j.s.ServletContextHandler@74518890{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1354] - Started o.s.j.s.ServletContextHandler@6134ac4a{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:12:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1366] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:12:55  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1381] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:12:59  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):5771] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:13:00  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):5826] - Rdd服务
[INFO ]2016-12-29 17:13:02  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8167] - Code generated in 148.409472 ms
[INFO ]2016-12-29 17:13:02  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8272] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8290] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8291] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8292] - Parents of final stage: List()
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8294] - Missing parents: List()
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8301] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8434] - Block broadcast_0 stored as values in memory (estimated size 12.0 KB, free 906.0 MB)
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8489] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.8 KB, free 906.0 MB)
[INFO ]2016-12-29 17:13:02  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8492] - Added broadcast_0_piece0 in memory on 172.18.10.41:49880 (size: 5.8 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8495] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8498] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:13:02  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8499] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:13:02  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8534] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:13:02  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8541] - Running task 0.0 in stage 0.0 (TID 0)
[INFO ]2016-12-29 17:13:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8910] - Code generated in 12.131238 ms
[INFO ]2016-12-29 17:13:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9617] - closed connection
[INFO ]2016-12-29 17:13:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9629] - Finished task 0.0 in stage 0.0 (TID 0). 1254 bytes result sent to driver
[INFO ]2016-12-29 17:13:03  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9635] - Finished task 0.0 in stage 0.0 (TID 0) in 1118 ms on localhost (1/1)
[INFO ]2016-12-29 17:13:03  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9637] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9641] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 1.133 s
[INFO ]2016-12-29 17:13:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9648] - Job 0 finished: count at RddServiceImpl.java:85, took 1.375385 s
[INFO ]2016-12-29 17:13:03  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):9664] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:13:03  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):9664] - Rdd服务
[INFO ]2016-12-29 17:13:03  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9740] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9743] - Got job 1 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9743] - Final stage: ResultStage 1 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9744] - Parents of final stage: List()
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9744] - Missing parents: List()
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9744] - Submitting ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9751] - Block broadcast_1 stored as values in memory (estimated size 12.0 KB, free 906.0 MB)
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9767] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KB, free 906.0 MB)
[INFO ]2016-12-29 17:13:03  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9768] - Added broadcast_1_piece0 in memory on 172.18.10.41:49880 (size: 5.8 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9768] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9769] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:13:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9769] - Adding task set 1.0 with 1 tasks
[INFO ]2016-12-29 17:13:03  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9775] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:13:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9776] - Running task 0.0 in stage 1.0 (TID 1)
[INFO ]2016-12-29 17:13:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10452] - closed connection
[INFO ]2016-12-29 17:13:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10453] - Finished task 0.0 in stage 1.0 (TID 1). 1341 bytes result sent to driver
[INFO ]2016-12-29 17:13:04  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10454] - Finished task 0.0 in stage 1.0 (TID 1) in 684 ms on localhost (1/1)
[INFO ]2016-12-29 17:13:04  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10455] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:13:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10455] - ResultStage 1 (count at RddServiceImpl.java:85) finished in 0.686 s
[INFO ]2016-12-29 17:13:04  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10455] - Job 1 finished: count at RddServiceImpl.java:85, took 0.714715 s
[INFO ]2016-12-29 17:14:48  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:14:48  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):317] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:14:48  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):318] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:14:48  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):318] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):341] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):341] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):342] - Changing view acls groups to: 
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):342] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):343] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):680] - Successfully started service 'sparkDriver' on port 49922.
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):705] - Registering MapOutputTracker
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):723] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):807] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-7bc7adab-5262-468f-8fcc-5d5bf9035ba6
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):823] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):891] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):985] - Logging initialized @1526ms
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1062] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1078] - Started o.s.j.s.ServletContextHandler@7bc10d84{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1078] - Started o.s.j.s.ServletContextHandler@275fe372{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1078] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1079] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1079] - Started o.s.j.s.ServletContextHandler@26a4842b{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1079] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1080] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1080] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1080] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1080] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1081] - Started o.s.j.s.ServletContextHandler@4b3c354a{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1081] - Started o.s.j.s.ServletContextHandler@78fb9a67{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1081] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1081] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1082] - Started o.s.j.s.ServletContextHandler@b968a76{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1082] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1082] - Started o.s.j.s.ServletContextHandler@2611b9a3{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1083] - Started o.s.j.s.ServletContextHandler@54227100{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1083] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1083] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1089] - Started o.s.j.s.ServletContextHandler@3f446bef{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1089] - Started o.s.j.s.ServletContextHandler@7829b776{/,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1090] - Started o.s.j.s.ServletContextHandler@5778826f{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1090] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1098] - Started ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:14:49  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1099] - Started @1641ms
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1099] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1101] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1182] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1207] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49931.
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1208] - Server created on 172.18.10.41:49931
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1210] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49931)
[INFO ]2016-12-29 17:14:49  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1213] - Registering block manager 172.18.10.41:49931 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49931)
[INFO ]2016-12-29 17:14:49  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1217] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49931)
[INFO ]2016-12-29 17:14:50  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1363] - Started o.s.j.s.ServletContextHandler@3ef41c66{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:14:50  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1387] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:14:50  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1416] - Started o.s.j.s.ServletContextHandler@15051a0{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:14:50  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1417] - Started o.s.j.s.ServletContextHandler@b09fac1{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:50  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1419] - Started o.s.j.s.ServletContextHandler@3c49fab6{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:14:50  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1420] - Started o.s.j.s.ServletContextHandler@74518890{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:14:50  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1423] - Started o.s.j.s.ServletContextHandler@6134ac4a{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:14:50  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1434] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:14:50  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1446] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:14:58  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):9553] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:14:58  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):9608] - Rdd服务
[INFO ]2016-12-29 17:15:00  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11974] - Code generated in 161.047668 ms
[INFO ]2016-12-29 17:15:00  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12056] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12076] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12077] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12078] - Parents of final stage: List()
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12079] - Missing parents: List()
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12088] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12205] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12234] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:00  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12237] - Added broadcast_0_piece0 in memory on 172.18.10.41:49931 (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12241] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12244] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:15:00  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12246] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:15:00  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12281] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:15:00  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12287] - Running task 0.0 in stage 0.0 (TID 0)
[INFO ]2016-12-29 17:15:01  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12389] - Code generated in 10.640842 ms
[INFO ]2016-12-29 17:15:01  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12396] - closed connection
[INFO ]2016-12-29 17:15:01  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12408] - Finished task 0.0 in stage 0.0 (TID 0). 1181 bytes result sent to driver
[INFO ]2016-12-29 17:15:01  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12414] - Finished task 0.0 in stage 0.0 (TID 0) in 150 ms on localhost (1/1)
[INFO ]2016-12-29 17:15:01  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12415] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12418] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.164 s
[INFO ]2016-12-29 17:15:01  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12424] - Job 0 finished: count at RddServiceImpl.java:85, took 0.366842 s
[INFO ]2016-12-29 17:15:01  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):12539] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:15:01  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):12540] - Rdd服务
[INFO ]2016-12-29 17:15:01  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12550] - Removed broadcast_0_piece0 on 172.18.10.41:49931 in memory (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:15:01  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12580] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12581] - Got job 1 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12581] - Final stage: ResultStage 1 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12581] - Parents of final stage: List()
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12581] - Missing parents: List()
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12582] - Submitting ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12585] - Block broadcast_1 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12590] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:01  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12593] - Added broadcast_1_piece0 in memory on 172.18.10.41:49931 (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12594] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12594] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12595] - Adding task set 1.0 with 1 tasks
[INFO ]2016-12-29 17:15:01  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12599] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:15:01  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12601] - Running task 0.0 in stage 1.0 (TID 1)
[INFO ]2016-12-29 17:15:01  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12621] - closed connection
[INFO ]2016-12-29 17:15:01  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12622] - Finished task 0.0 in stage 1.0 (TID 1). 1181 bytes result sent to driver
[INFO ]2016-12-29 17:15:01  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12624] - Finished task 0.0 in stage 1.0 (TID 1) in 26 ms on localhost (1/1)
[INFO ]2016-12-29 17:15:01  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12625] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:15:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12625] - ResultStage 1 (count at RddServiceImpl.java:85) finished in 0.030 s
[INFO ]2016-12-29 17:15:01  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12626] - Job 1 finished: count at RddServiceImpl.java:85, took 0.045436 s
[INFO ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[WARN ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):300] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):302] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):302] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):325] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):326] - Changing view acls groups to: 
[INFO ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):326] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:15:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):327] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):658] - Successfully started service 'sparkDriver' on port 49972.
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):674] - Registering MapOutputTracker
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):689] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):770] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-66647aa7-27d2-4597-a2f2-39c65723790a
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):789] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):857] - Registering OutputCommitCoordinator
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):923] - Logging initialized @1447ms
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):998] - jetty-9.2.z-SNAPSHOT
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1013] - Started o.s.j.s.ServletContextHandler@40e10ff8{/jobs,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1014] - Started o.s.j.s.ServletContextHandler@557a1e2d{/jobs/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1014] - Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1014] - Started o.s.j.s.ServletContextHandler@7e38a7fe{/jobs/job/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1015] - Started o.s.j.s.ServletContextHandler@366ef90e{/stages,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1015] - Started o.s.j.s.ServletContextHandler@33e01298{/stages/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1015] - Started o.s.j.s.ServletContextHandler@31e75d13{/stages/stage,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1016] - Started o.s.j.s.ServletContextHandler@a5b0b86{/stages/stage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1016] - Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/pool,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1016] - Started o.s.j.s.ServletContextHandler@78fb9a67{/stages/pool/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1017] - Started o.s.j.s.ServletContextHandler@73ff4fae{/storage,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1017] - Started o.s.j.s.ServletContextHandler@21aa6d6c{/storage/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1017] - Started o.s.j.s.ServletContextHandler@b968a76{/storage/rdd,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1017] - Started o.s.j.s.ServletContextHandler@2f9a01c1{/storage/rdd/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1018] - Started o.s.j.s.ServletContextHandler@2611b9a3{/environment,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1018] - Started o.s.j.s.ServletContextHandler@54227100{/environment/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1018] - Started o.s.j.s.ServletContextHandler@6b5894c8{/executors,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1018] - Started o.s.j.s.ServletContextHandler@1433046b{/executors/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1018] - Started o.s.j.s.ServletContextHandler@3f446bef{/executors/threadDump,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1019] - Started o.s.j.s.ServletContextHandler@7829b776{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1023] - Started o.s.j.s.ServletContextHandler@5778826f{/static,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@5b64c4b7{/,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1024] - Started o.s.j.s.ServletContextHandler@4763c727{/api,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1025] - Started o.s.j.s.ServletContextHandler@72445aba{/stages/stage/kill,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1032] - Started ServerConnector@3fc9dfc5{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1032] - Started @1557ms
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1032] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1034] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1108] - Starting executor ID driver on host localhost
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1133] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49981.
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1134] - Server created on 172.18.10.41:49981
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1135] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 49981)
[INFO ]2016-12-29 17:15:28  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1138] - Registering block manager 172.18.10.41:49981 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 49981)
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1140] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 49981)
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1267] - Started o.s.j.s.ServletContextHandler@3ef41c66{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1283] - Use an existing SparkContext, some configuration may not take effect.
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1306] - Started o.s.j.s.ServletContextHandler@15051a0{/SQL,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1307] - Started o.s.j.s.ServletContextHandler@b09fac1{/SQL/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1309] - Started o.s.j.s.ServletContextHandler@3c49fab6{/SQL/execution,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1309] - Started o.s.j.s.ServletContextHandler@74518890{/SQL/execution/json,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1311] - Started o.s.j.s.ServletContextHandler@6134ac4a{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:15:28  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1321] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:15:28  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1333] - 服务启动成功，监听端口：10080
[INFO ]2016-12-29 17:15:31  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):3923] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:15:31  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):3971] - Rdd服务
[INFO ]2016-12-29 17:15:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6297] - Code generated in 158.913778 ms
[INFO ]2016-12-29 17:15:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6394] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:15:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6410] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:15:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6411] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:15:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6411] - Parents of final stage: List()
[INFO ]2016-12-29 17:15:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6413] - Missing parents: List()
[INFO ]2016-12-29 17:15:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6418] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6518] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6543] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:34  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6545] - Added broadcast_0_piece0 in memory on 172.18.10.41:49981 (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6548] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6551] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6553] - Adding task set 0.0 with 1 tasks
[INFO ]2016-12-29 17:15:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6587] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:15:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6597] - Running task 0.0 in stage 0.0 (TID 0)
[INFO ]2016-12-29 17:15:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6669] - Code generated in 10.407268 ms
[INFO ]2016-12-29 17:15:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6673] - closed connection
[INFO ]2016-12-29 17:15:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6686] - Finished task 0.0 in stage 0.0 (TID 0). 1181 bytes result sent to driver
[INFO ]2016-12-29 17:15:34  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6691] - Finished task 0.0 in stage 0.0 (TID 0) in 120 ms on localhost (1/1)
[INFO ]2016-12-29 17:15:34  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6693] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6695] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.134 s
[INFO ]2016-12-29 17:15:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6711] - Job 0 finished: count at RddServiceImpl.java:85, took 0.315835 s
[INFO ]2016-12-29 17:15:34  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):6724] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:15:34  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):6724] - Rdd服务
[INFO ]2016-12-29 17:15:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6840] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6850] - Got job 1 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6851] - Final stage: ResultStage 1 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6851] - Parents of final stage: List()
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6852] - Missing parents: List()
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6852] - Submitting ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6856] - Block broadcast_1 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6860] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:15:34  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6865] - Added broadcast_1_piece0 in memory on 172.18.10.41:49981 (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6866] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6866] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6866] - Adding task set 1.0 with 1 tasks
[INFO ]2016-12-29 17:15:34  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6870] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:15:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6872] - Removed broadcast_0_piece0 on 172.18.10.41:49981 in memory (size: 5.5 KB, free: 906.0 MB)
[INFO ]2016-12-29 17:15:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6875] - Running task 0.0 in stage 1.0 (TID 1)
[INFO ]2016-12-29 17:15:34  [Spark Context Cleaner:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6897] - Cleaned accumulator 1
[INFO ]2016-12-29 17:15:34  [Spark Context Cleaner:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6897] - Cleaned accumulator 0
[INFO ]2016-12-29 17:15:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6914] - closed connection
[INFO ]2016-12-29 17:15:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6915] - Finished task 0.0 in stage 1.0 (TID 1). 1181 bytes result sent to driver
[INFO ]2016-12-29 17:15:34  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6918] - Finished task 0.0 in stage 1.0 (TID 1) in 50 ms on localhost (1/1)
[INFO ]2016-12-29 17:15:34  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6919] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:15:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6919] - ResultStage 1 (count at RddServiceImpl.java:85) finished in 0.052 s
[INFO ]2016-12-29 17:15:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6920] - Job 1 finished: count at RddServiceImpl.java:85, took 0.079092 s
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):62] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):70] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):71] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:232):71] - UgiMetrics, User and group related metrics
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.authentication.util.KerberosName.<clinit>(KerberosName.java:88):233] - Kerberos krb5 configuration not found, setting default realm to empty
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:301):236] -  Creating new Groups object
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:46):238] - Trying to load the custom-built native-hadoop library...
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:50):240] - Loaded the native-hadoop library
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:50):241] - Using JniBasedUnixGroupsMapping for Group resolution
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:45):241] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.Groups.<init>(Groups.java:112):297] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.login(UserGroupInformation.java:221):302] - hadoop login
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:156):303] - hadoop login commit
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:186):327] - using local user:NTUserPrincipal: pujjr
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:192):327] - Using user: "NTUserPrincipal: pujjr" with name pujjr
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:202):328] - User entry: "pujjr"
[DEBUG]2016-12-29 17:16:31  [main:org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:826):329] - UGI loginUser:pujjr (auth:SIMPLE)
[WARN ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):337] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):338] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):338] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):361] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):362] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):362] - Changing view acls groups to: 
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):363] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):364] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[DEBUG]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):373] - Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):447] - Using SLF4J as the default logging framework
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):451] - java.nio.Buffer.address: available
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):451] - sun.misc.Unsafe.theUnsafe: available
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):452] - sun.misc.Unsafe.copyMemory: available
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):452] - java.nio.Bits.unaligned: true
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):453] - Platform: Windows
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):454] - Java version: 8
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):454] - -Dio.netty.noUnsafe: false
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):454] - sun.misc.Unsafe: available
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):454] - -Dio.netty.noJavassist: false
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):531] - Javassist: available
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):532] - -Dio.netty.tmpdir: C:\Users\pujjr\AppData\Local\Temp (java.io.tmpdir)
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):532] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):532] - -Dio.netty.noPreferDirect: false
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):534] - Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):537] - Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):544] - -Dio.netty.eventLoopThreads: 8
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):557] - -Dio.netty.noKeySetOptimization: false
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):557] - -Dio.netty.selectorAutoRebuildThreshold: 512
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.numHeapArenas: 8
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.numDirectArenas: 8
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.pageSize: 8192
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.maxOrder: 11
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.chunkSize: 16777216
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.tinyCacheSize: 512
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.smallCacheSize: 256
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.normalCacheSize: 64
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.cacheTrimInterval: 8192
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):627] - -Dio.netty.initialSeedUniquifier: 0x23c62d9b37258738 (took 7 ms)
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):651] - -Dio.netty.allocator.type: unpooled
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):651] - -Dio.netty.threadLocalDirectBufferSize: 65536
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:86):714] - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
[DEBUG]2016-12-29 17:16:31  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):714] - \proc\sys\net\core\somaxconn: 200 (non-existent)
[DEBUG]2016-12-29 17:16:31  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):724] - Shuffle server started on port :50024
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):727] - Successfully started service 'sparkDriver' on port 50024.
[DEBUG]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):728] - Using serializer: class org.apache.spark.serializer.JavaSerializer
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):741] - Registering MapOutputTracker
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):755] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:16:31  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):843] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-8ad2be18-f047-484c-9b14-2c35fc25b2f2
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):861] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):932] - Registering OutputCommitCoordinator
[DEBUG]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):1033] - Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:176):1101] - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):1103] - Logging initialized @1611ms
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1112] - o.s.j.s.ServletContextHandler@4044fb95{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@aa549e5,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1116] - org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1116] - org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-72758afa,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1117] - o.s.j.s.ServletContextHandler@40cb698e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3382f8ae,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1118] - org.spark_project.jetty.servlet.ServletHandler@3382f8ae added {org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1118] - org.spark_project.jetty.servlet.ServletHandler@3382f8ae added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-60641ec8,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1119] - o.s.j.s.ServletContextHandler@75390459{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7756c3cd,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1119] - org.spark_project.jetty.servlet.ServletHandler@7756c3cd added {org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1119] - org.spark_project.jetty.servlet.ServletHandler@7756c3cd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2313052e,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1120] - o.s.j.s.ServletContextHandler@2bd2b28e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@16746061,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1120] - org.spark_project.jetty.servlet.ServletHandler@16746061 added {org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1120] - org.spark_project.jetty.servlet.ServletHandler@16746061 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1120] - o.s.j.s.ServletContextHandler@52045dbe{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@674658f7,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1121] - org.spark_project.jetty.servlet.ServletHandler@674658f7 added {org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1121] - org.spark_project.jetty.servlet.ServletHandler@674658f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1121] - o.s.j.s.ServletContextHandler@565b064f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@26425897,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1121] - org.spark_project.jetty.servlet.ServletHandler@26425897 added {org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1121] - org.spark_project.jetty.servlet.ServletHandler@26425897 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-73163d48,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1122] - o.s.j.s.ServletContextHandler@56a4479a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62163b39,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1123] - org.spark_project.jetty.servlet.ServletHandler@62163b39 added {org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1123] - org.spark_project.jetty.servlet.ServletHandler@62163b39 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1123] - o.s.j.s.ServletContextHandler@62f4ff3b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1698fc68,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1123] - org.spark_project.jetty.servlet.ServletHandler@1698fc68 added {org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1124] - org.spark_project.jetty.servlet.ServletHandler@1698fc68 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-4504d271,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1124] - o.s.j.s.ServletContextHandler@65b3a85a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@34997338,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1124] - org.spark_project.jetty.servlet.ServletHandler@34997338 added {org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1124] - org.spark_project.jetty.servlet.ServletHandler@34997338 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-57eda880,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1125] - o.s.j.s.ServletContextHandler@2b5825fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53d1b9b3,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1125] - org.spark_project.jetty.servlet.ServletHandler@53d1b9b3 added {org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1125] - org.spark_project.jetty.servlet.ServletHandler@53d1b9b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2cae1042,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1128] - o.s.j.s.ServletContextHandler@788fcafb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4febb875,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1128] - org.spark_project.jetty.servlet.ServletHandler@4febb875 added {org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1128] - org.spark_project.jetty.servlet.ServletHandler@4febb875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-25e2a451,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1128] - o.s.j.s.ServletContextHandler@1698ee84{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c626be,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1129] - org.spark_project.jetty.servlet.ServletHandler@10c626be added {org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1129] - org.spark_project.jetty.servlet.ServletHandler@10c626be added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1129] - o.s.j.s.ServletContextHandler@63b1d4fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@42e3ede4,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1129] - org.spark_project.jetty.servlet.ServletHandler@42e3ede4 added {org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1129] - org.spark_project.jetty.servlet.ServletHandler@42e3ede4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1130] - o.s.j.s.ServletContextHandler@75459c75{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@183e8023,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1130] - org.spark_project.jetty.servlet.ServletHandler@183e8023 added {org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1130] - org.spark_project.jetty.servlet.ServletHandler@183e8023 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-45efc20d,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1131] - o.s.j.s.ServletContextHandler@30bcf3c1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2a3c96e3,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1131] - org.spark_project.jetty.servlet.ServletHandler@2a3c96e3 added {org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1132] - org.spark_project.jetty.servlet.ServletHandler@2a3c96e3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-15cafec7,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1132] - o.s.j.s.ServletContextHandler@5b444398{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@cb191ca,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1132] - org.spark_project.jetty.servlet.ServletHandler@cb191ca added {org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1132] - org.spark_project.jetty.servlet.ServletHandler@cb191ca added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-42f48531,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1135] - o.s.j.s.ServletContextHandler@6821ea29{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@338494fa,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1135] - org.spark_project.jetty.servlet.ServletHandler@338494fa added {org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1135] - org.spark_project.jetty.servlet.ServletHandler@338494fa added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1136] - o.s.j.s.ServletContextHandler@758c83d8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@129b4fe2,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1136] - org.spark_project.jetty.servlet.ServletHandler@129b4fe2 added {org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1136] - org.spark_project.jetty.servlet.ServletHandler@129b4fe2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1137] - o.s.j.s.ServletContextHandler@10993713{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58359ebd,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1137] - org.spark_project.jetty.servlet.ServletHandler@58359ebd added {org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1137] - org.spark_project.jetty.servlet.ServletHandler@58359ebd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1137] - o.s.j.s.ServletContextHandler@72cf2de5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2bb7bd00,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1137] - org.spark_project.jetty.servlet.ServletHandler@2bb7bd00 added {org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1138] - org.spark_project.jetty.servlet.ServletHandler@2bb7bd00 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1138] - o.s.j.s.ServletContextHandler@45c8d09f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53812a9b,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1145] - org.spark_project.jetty.servlet.ServletHandler@53812a9b added {org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1146] - org.spark_project.jetty.servlet.ServletHandler@53812a9b added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-5974109,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1146] - o.s.j.s.ServletContextHandler@502f1f4c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6f8f9349,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1147] - org.spark_project.jetty.servlet.ServletHandler@6f8f9349 added {org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1147] - org.spark_project.jetty.servlet.ServletHandler@6f8f9349 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1147] - o.s.j.s.ServletContextHandler@4fbda97b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@75f5fd58,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1150] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1150] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-f73dcd6,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1151] - o.s.j.s.ServletContextHandler@30d4b288{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1151] - org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a added {org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1151] - org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1170] - org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c mime types IncludeExclude@207ea13{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4bff1903,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62dae540}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1171] - org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c added {o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1171] - org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16 mime types IncludeExclude@654d8173{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@56c9bbd8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@630cb4a4}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1172] - org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16 added {o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1172] - org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc mime types IncludeExclude@f79a760{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@14f5da2c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@12dae582}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1172] - org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc added {o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1173] - org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29 mime types IncludeExclude@5b057c8c{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1eb6749b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@652a7737}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1173] - org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29 added {o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1174] - org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d mime types IncludeExclude@2bef51f2{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@650eab8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@30f5a68a}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1177] - org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d added {o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1177] - org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956 mime types IncludeExclude@4f2c9ba6{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4e28bdd1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@53f48368}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1178] - org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956 added {o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1178] - org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9 mime types IncludeExclude@f0e995e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4c37b5b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@73db4768}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1178] - org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9 added {o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1179] - org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed mime types IncludeExclude@3c435123{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@50fe837a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3a62c01e}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1179] - org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed added {o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1179] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663 mime types IncludeExclude@5ce33a58{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@78a287ed,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@546ccad7}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1180] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663 added {o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1180] - org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287 mime types IncludeExclude@1623134f{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7a527389,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@485a3466}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1180] - org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287 added {o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1180] - org.spark_project.jetty.servlets.gzip.GzipHandler@25748410 mime types IncludeExclude@2b43529a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4264b240,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b04476e}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1180] - org.spark_project.jetty.servlets.gzip.GzipHandler@25748410 added {o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1181] - org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a mime types IncludeExclude@6bb75258{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@c260bdc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@75e01201}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1181] - org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a added {o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1181] - org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b mime types IncludeExclude@76f7d241{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4a335fa8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3f363cf5}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1183] - org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b added {o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1184] - org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1 mime types IncludeExclude@4baf352a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1bb1fde8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@15eebbff}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1184] - org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1 added {o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1184] - org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11 mime types IncludeExclude@30990c1b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2453f95d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@44828f6b}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1185] - org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11 added {o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1185] - org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d mime types IncludeExclude@553f1d75{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6e1d8f9e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3e34ace1}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1185] - org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d added {o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1185] - org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067 mime types IncludeExclude@4f071df8{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4de41af9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@56ace400}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1185] - org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067 added {o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1186] - org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea mime types IncludeExclude@305f7627{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5d018107,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6cbcf243}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1186] - org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea added {o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1186] - org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25 mime types IncludeExclude@62435e70{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@339bf286,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@38be305c}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1186] - org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25 added {o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1186] - org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad mime types IncludeExclude@5ed731d0{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3234f74e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7bc10d84}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1187] - org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad added {o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1188] - org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372 mime types IncludeExclude@40e10ff8{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@557a1e2d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@26a4842b}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1188] - org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372 added {o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1188] - org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe mime types IncludeExclude@366ef90e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@33e01298,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@31e75d13}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1188] - org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe added {o.s.j.s.ServletContextHandler@502f1f4c{/,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1189] - org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86 mime types IncludeExclude@4b3c354a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@78fb9a67,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@73ff4fae}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1189] - org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86 added {o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1189] - org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c mime types IncludeExclude@b968a76{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2f9a01c1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2611b9a3}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1189] - org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c added {o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1196] - org.spark_project.jetty.server.Server@2dbf4cbd added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1205] - HttpConnectionFactory@1de5f0ef{HTTP/1.1} added {HttpConfiguration@376a312c{32768/8192,8192/8192,https://:0,[]},POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1207] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@2dbf4cbd,UNMANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1208] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1208] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1208] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@7c56e013,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1209] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {HttpConnectionFactory@1de5f0ef{HTTP/1.1},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1210] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af,MANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1211] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c] added {org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1212] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1212] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc] added {org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1212] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29] added {org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1212] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1213] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956] added {org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1213] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9] added {org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1213] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed] added {org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1213] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1214] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1214] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410] added {org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1214] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1214] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1215] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1] added {org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1215] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11] added {org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1215] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1215] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067] added {org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1215] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea] added {org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1215] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25] added {org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1216] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad] added {org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1216] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372] added {org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1216] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1216] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86] added {org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1216] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c] added {org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1220] - org.spark_project.jetty.server.Server@2dbf4cbd added {ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040},AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1221] - org.spark_project.jetty.server.Server@2dbf4cbd added {org.spark_project.jetty.server.handler.ErrorHandler@6a66a204,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1222] - org.spark_project.jetty.server.Server@2dbf4cbd added {org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c],AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1222] - starting org.spark_project.jetty.server.Server@2dbf4cbd
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1224] - jetty-9.2.z-SNAPSHOT
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1233] - starting org.spark_project.jetty.server.Server@2dbf4cbd
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1233] - starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1234] - STARTED @1743ms SparkUI{STARTED,8<=8<=200,i=8,q=0}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1235] - starting org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1235] - starting org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1235] - STARTED @1744ms org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1235] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1236] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1236] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1236] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1237] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1237] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1237] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1237] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1238] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1238] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1238] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1238] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1238] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1239] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1239] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1239] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1239] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1239] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1239] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1239] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1240] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1240] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1240] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1240] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1240] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1240] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1240] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1240] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1241] - starting o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1242] - starting o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1242] - starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1243] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-72758afa from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1243] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1243] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1243] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1244] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1244] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-72758afa=org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1244] - starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1244] - STARTED @1753ms org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1244] - starting org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1245] - STARTED @1754ms org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1246] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@6d0b5baf for org.apache.spark.ui.JettyUtils$$anon$2-72758afa
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1246] - Started o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1247] - STARTED @1755ms o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1247] - STARTED @1755ms org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1247] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1247] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1247] - starting o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1247] - starting o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1247] - starting org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1247] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1247] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1247] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1247] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1248] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1248] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-60641ec8=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1248] - starting org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1248] - STARTED @1757ms org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1248] - starting org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1248] - STARTED @1757ms org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1248] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@2a3591c5 for org.apache.spark.ui.JettyUtils$$anon$2-60641ec8
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1248] - Started o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1249] - STARTED @1757ms o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1249] - STARTED @1757ms org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1249] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1249] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1249] - starting o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1249] - starting o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1249] - starting org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1249] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2313052e from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1250] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1250] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1250] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1250] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1250] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2313052e=org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1250] - starting org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1250] - STARTED @1759ms org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1250] - starting org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1251] - STARTED @1759ms org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1251] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@346a361 for org.apache.spark.ui.JettyUtils$$anon$2-2313052e
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1251] - Started o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1251] - STARTED @1760ms o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1251] - STARTED @1760ms org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1251] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1251] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1251] - starting o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1251] - starting o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1252] - starting org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1252] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1252] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1252] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1252] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1252] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1252] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1252] - starting org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1253] - STARTED @1761ms org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1253] - starting org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1253] - STARTED @1762ms org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1253] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@186978a6 for org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1253] - Started o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1253] - STARTED @1762ms o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1253] - STARTED @1762ms org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1254] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1254] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1254] - starting o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1254] - starting o.s.j.s.ServletContextHandler@52045dbe{/stages,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1254] - starting org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1254] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1254] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1254] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1254] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1254] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1255] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1255] - starting org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1255] - STARTED @1763ms org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1255] - starting org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1255] - STARTED @1764ms org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1255] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@482d776b for org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1255] - Started o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1255] - STARTED @1764ms o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1255] - STARTED @1764ms org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1255] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1255] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1256] - starting o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1256] - starting o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1256] - starting org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1256] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-73163d48 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1256] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1256] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1256] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1256] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1256] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-73163d48=org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1256] - starting org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1257] - STARTED @1765ms org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1257] - starting org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1257] - STARTED @1765ms org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1257] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@132ddbab for org.apache.spark.ui.JettyUtils$$anon$2-73163d48
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1257] - Started o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1257] - STARTED @1766ms o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1257] - STARTED @1766ms org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1257] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1257] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1257] - starting o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1257] - starting o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1258] - starting org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1258] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1258] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1258] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1258] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1258] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1258] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1258] - starting org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1258] - STARTED @1767ms org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1259] - starting org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1259] - STARTED @1767ms org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1259] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@acb0951 for org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1259] - Started o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1259] - STARTED @1768ms o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1259] - STARTED @1768ms org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1259] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1259] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1259] - starting o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1259] - starting o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1259] - starting org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1260] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-4504d271 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1260] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1260] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1260] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1260] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1260] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-4504d271=org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1260] - starting org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1260] - STARTED @1769ms org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1260] - starting org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1260] - STARTED @1769ms org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1261] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@267f474e for org.apache.spark.ui.JettyUtils$$anon$2-4504d271
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1261] - Started o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1261] - STARTED @1769ms o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1261] - STARTED @1770ms org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1261] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1261] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1261] - starting o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1261] - starting o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1261] - starting org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1261] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-57eda880 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1261] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1262] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1262] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1262] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1262] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-57eda880=org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1262] - starting org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1262] - STARTED @1771ms org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1262] - starting org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1262] - STARTED @1771ms org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1262] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@28276e50 for org.apache.spark.ui.JettyUtils$$anon$2-57eda880
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1262] - Started o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1263] - STARTED @1771ms o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1263] - STARTED @1771ms org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1263] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1263] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1263] - starting o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1263] - starting o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1263] - starting org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1263] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1263] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1263] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1263] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1263] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1264] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2cae1042=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1264] - starting org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1264] - STARTED @1773ms org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1264] - starting org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1264] - STARTED @1773ms org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1264] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3efe7086 for org.apache.spark.ui.JettyUtils$$anon$2-2cae1042
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1264] - Started o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1264] - STARTED @1773ms o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1264] - STARTED @1773ms org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1264] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1265] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1265] - starting o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1265] - starting o.s.j.s.ServletContextHandler@788fcafb{/storage,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1265] - starting org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1265] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1265] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1265] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1265] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1265] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1265] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-25e2a451=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1266] - starting org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1267] - STARTED @1775ms org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1267] - starting org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1267] - STARTED @1776ms org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1267] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@741b3bc3 for org.apache.spark.ui.JettyUtils$$anon$2-25e2a451
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1268] - Started o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1268] - STARTED @1776ms o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1268] - STARTED @1776ms org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1268] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1268] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1268] - starting o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1268] - starting o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1268] - starting org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1268] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1268] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1268] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1268] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1269] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1269] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1269] - starting org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1269] - STARTED @1778ms org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1269] - starting org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1269] - STARTED @1778ms org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1270] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@63648ee9 for org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1270] - Started o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1270] - STARTED @1779ms o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1270] - STARTED @1779ms org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1270] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1270] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1270] - starting o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1270] - starting o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1270] - starting org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1270] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1271] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1271] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1271] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1271] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1271] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1272] - starting org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1272] - STARTED @1781ms org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1272] - starting org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1272] - STARTED @1781ms org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1272] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@45be7cd5 for org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1273] - Started o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1273] - STARTED @1781ms o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1273] - STARTED @1781ms org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1273] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1273] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1273] - starting o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1273] - starting o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1273] - starting org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1273] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1273] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1273] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1273] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1274] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1274] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-45efc20d=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1274] - starting org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1274] - STARTED @1783ms org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1275] - starting org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1275] - STARTED @1783ms org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1275] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3185fa6b for org.apache.spark.ui.JettyUtils$$anon$2-45efc20d
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1275] - Started o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1275] - STARTED @1784ms o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1275] - STARTED @1784ms org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1275] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1275] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1276] - starting o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1276] - starting o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1276] - starting org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1276] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1276] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1276] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1276] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1276] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1277] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-15cafec7=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1277] - starting org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1277] - STARTED @1785ms org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1278] - starting org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1278] - STARTED @1786ms org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1278] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5b58ed3c for org.apache.spark.ui.JettyUtils$$anon$2-15cafec7
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1278] - Started o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1278] - STARTED @1787ms o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1279] - STARTED @1787ms org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1279] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1279] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1279] - starting o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1279] - starting o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1279] - starting org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1279] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-42f48531 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1280] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1280] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1280] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1280] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1281] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-42f48531=org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1281] - starting org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1281] - STARTED @1790ms org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1281] - starting org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1281] - STARTED @1790ms org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1281] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3a320ade for org.apache.spark.ui.JettyUtils$$anon$2-42f48531
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1281] - Started o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1282] - STARTED @1790ms o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1282] - STARTED @1790ms org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1282] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1282] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1282] - starting o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1282] - starting o.s.j.s.ServletContextHandler@6821ea29{/executors,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1282] - starting org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1282] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1283] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1283] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1283] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1283] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1283] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1283] - starting org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1283] - STARTED @1792ms org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1284] - starting org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1284] - STARTED @1792ms org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1284] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7813cb11 for org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1284] - Started o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1284] - STARTED @1793ms o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1285] - STARTED @1793ms org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1285] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1285] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1285] - starting o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1285] - starting o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1285] - starting org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1285] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1285] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1285] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1286] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1286] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1286] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1286] - starting org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1286] - STARTED @1795ms org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1286] - starting org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1286] - STARTED @1795ms org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1286] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@21005f6c for org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1286] - Started o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1287] - STARTED @1795ms o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1287] - STARTED @1795ms org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1287] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1287] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1287] - starting o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1287] - starting o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1287] - starting org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1287] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1287] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1287] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1287] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1288] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1288] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1288] - starting org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1288] - STARTED @1797ms org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1288] - starting org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1288] - STARTED @1797ms org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1288] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@545de5a4 for org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1288] - Started o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1288] - STARTED @1797ms o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1288] - STARTED @1797ms org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1288] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1289] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1289] - starting o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1289] - starting o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1289] - starting org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1289] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1291] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1292] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1292] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1292] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1292] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1292] - starting org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1292] - STARTED @1801ms org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1292] - starting org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1292] - STARTED @1801ms org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1293] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@ab7a938 for org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1293] - Started o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1293] - STARTED @1801ms o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1293] - STARTED @1802ms org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1293] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1293] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1293] - starting o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1293] - starting o.s.j.s.ServletContextHandler@45c8d09f{/static,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1293] - starting org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1293] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-5974109 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1293] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1294] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1294] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1294] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1294] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-5974109=org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1295] - starting org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1295] - STARTED @1804ms org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1295] - starting org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1295] - STARTED @1804ms org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1295] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@4648ce9 for org.spark_project.jetty.servlet.DefaultServlet-5974109
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1301] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-core_2.11-2.0.0.jar!/org/apache/spark/ui/static
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1302] - Started o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1302] - STARTED @1810ms o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1302] - STARTED @1811ms org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1302] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1302] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1303] - starting o.s.j.s.ServletContextHandler@502f1f4c{/,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1303] - starting o.s.j.s.ServletContextHandler@502f1f4c{/,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1303] - starting org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1303] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1303] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1303] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1303] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1303] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1303] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1303] - starting org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1304] - STARTED @1812ms org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1304] - starting org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1304] - STARTED @1813ms org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1304] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@305f031 for org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1304] - Started o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1306] - STARTED @1815ms o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1306] - STARTED @1815ms org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1306] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1306] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1306] - starting o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1306] - starting o.s.j.s.ServletContextHandler@4fbda97b{/api,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1307] - starting org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1307] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-f73dcd6 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1307] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1307] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1307] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1307] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1307] - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-f73dcd6=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.doStart(ServletHandler.java:165):1307] - Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1308] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1308] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1308] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-f73dcd6 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1309] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1309] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1309] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1309] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1309] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1309] - servletNameMap={org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false, org.glassfish.jersey.servlet.ServletContainer-f73dcd6=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1309] - starting org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1309] - STARTED @1818ms org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1309] - starting org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1310] - STARTED @1818ms org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1310] - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1310] - STARTED @1818ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1310] - Started o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1310] - STARTED @1819ms o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1310] - STARTED @1819ms org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1310] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1310] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1310] - starting o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1310] - starting o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1311] - starting org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1311] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1311] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1311] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1311] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1311] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1311] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1311] - starting org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1311] - STARTED @1820ms org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1311] - starting org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1311] - STARTED @1820ms org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1312] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1536602f for org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1312] - Started o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1312] - STARTED @1820ms o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1312] - STARTED @1820ms org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1312] - STARTED @1821ms org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1312] - starting ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1313] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1313] - starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1313] - STARTED @1822ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1313] - starting HttpConnectionFactory@1de5f0ef{HTTP/1.1}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1313] - STARTED @1822ms HttpConnectionFactory@1de5f0ef{HTTP/1.1}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1314] - starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1318] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=-1 selected=-1
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1319] - STARTED @1828ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=0 selected=0
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1320] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=-1 selected=-1
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1321] - STARTED @1830ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=0 selected=0
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1321] - STARTED @1830ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af
[DEBUG]2016-12-29 17:16:32  [SparkUI-36-selector-ServerConnectorManager@16f7b4af/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1322] - Starting Thread[SparkUI-36-selector-ServerConnectorManager@16f7b4af/1,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=0 selected=0
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1323] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040} added {acceptor-0@36b0fcd5,POJO}
[DEBUG]2016-12-29 17:16:32  [SparkUI-35-selector-ServerConnectorManager@16f7b4af/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1322] - Starting Thread[SparkUI-35-selector-ServerConnectorManager@16f7b4af/0,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=0 selected=0
[DEBUG]2016-12-29 17:16:32  [SparkUI-35-selector-ServerConnectorManager@16f7b4af/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1323] - Selector loop waiting on select
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1323] - Started ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1323] - STARTED @1832ms ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1324] - Started @1832ms
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1324] - STARTED @1832ms org.spark_project.jetty.server.Server@2dbf4cbd
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1324] - Successfully started service 'SparkUI' on port 4040.
[DEBUG]2016-12-29 17:16:32  [SparkUI-36-selector-ServerConnectorManager@16f7b4af/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1323] - Selector loop waiting on select
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1326] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1428] - Starting executor ID driver on host localhost
[DEBUG]2016-12-29 17:16:32  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):1449] - Shuffle server started on port :50033
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1450] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50033.
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1450] - Server created on 172.18.10.41:50033
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1451] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 50033)
[INFO ]2016-12-29 17:16:32  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1453] - Registering block manager 172.18.10.41:50033 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 50033)
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1456] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 50033)
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1578] - o.s.j.s.ServletContextHandler@2899a8db{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1e8823d2,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1578] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1578] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-c1a4620,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1579] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}] added {o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1580] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1581] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1582] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1582] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1582] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1582] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1582] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1582] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1582] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1583] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1583] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1583] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1583] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1583] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1583] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1583] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1583] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1583] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1583] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-c1a4620=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1584] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1584] - STARTED @2092ms org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1584] - starting org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1584] - STARTED @2093ms org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1584] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5710768a for org.apache.spark.ui.JettyUtils$$anon$2-c1a4620
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1584] - Started o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1584] - STARTED @2093ms o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1602] - Use an existing SparkContext, some configuration may not take effect.
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1631] - o.s.j.s.ServletContextHandler@867ba60{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5ba745bc,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1631] - org.spark_project.jetty.servlet.ServletHandler@5ba745bc added {org.apache.spark.ui.JettyUtils$$anon$2-654b72c0@c8094042==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1631] - org.spark_project.jetty.servlet.ServletHandler@5ba745bc added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-654b72c0,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1631] - o.s.j.s.ServletContextHandler@55b5e331{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6034e75d,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1631] - org.spark_project.jetty.servlet.ServletHandler@6034e75d added {org.apache.spark.ui.JettyUtils$$anon$2-15fc442@c6e74dc4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1632] - org.spark_project.jetty.servlet.ServletHandler@6034e75d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-15fc442,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1632] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@867ba60{/SQL,null,null}] added {o.s.j.s.ServletContextHandler@867ba60{/SQL,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1633] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1633] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1633] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1633] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1634] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - SQL->[{o.s.j.s.ServletContextHandler@867ba60{/SQL,null,null},[o.s.j.s.ServletContextHandler@867ba60{/SQL,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1635] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1636] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1636] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1636] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1636] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1637] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1637] - starting o.s.j.s.ServletContextHandler@867ba60{/SQL,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1637] - starting o.s.j.s.ServletContextHandler@867ba60{/SQL,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1638] - starting org.spark_project.jetty.servlet.ServletHandler@5ba745bc
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1638] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-654b72c0 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1638] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1638] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1638] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1639] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-654b72c0@c8094042==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1639] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-654b72c0=org.apache.spark.ui.JettyUtils$$anon$2-654b72c0@c8094042==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1639] - starting org.spark_project.jetty.servlet.ServletHandler@5ba745bc
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1639] - STARTED @2148ms org.spark_project.jetty.servlet.ServletHandler@5ba745bc
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1639] - starting org.apache.spark.ui.JettyUtils$$anon$2-654b72c0@c8094042==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1640] - STARTED @2148ms org.apache.spark.ui.JettyUtils$$anon$2-654b72c0@c8094042==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1640] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@456abb66 for org.apache.spark.ui.JettyUtils$$anon$2-654b72c0
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1640] - Started o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1640] - STARTED @2149ms o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1642] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,null}] added {o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1643] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1644] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1644] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1645] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1645] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1645] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1645] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1645] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1645] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1645] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1646] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1646] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1646] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1648] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1648] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1649] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1649] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1649] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1649] - SQL->[{o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1649] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1650] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1650] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1650] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1650] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1651] - SQL/json->[{o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,null},[o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1651] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1651] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1651] - starting o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1651] - starting o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1651] - starting org.spark_project.jetty.servlet.ServletHandler@6034e75d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1651] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-15fc442 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1653] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1653] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1653] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1653] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-15fc442@c6e74dc4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1653] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-15fc442=org.apache.spark.ui.JettyUtils$$anon$2-15fc442@c6e74dc4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1653] - starting org.spark_project.jetty.servlet.ServletHandler@6034e75d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1658] - STARTED @2167ms org.spark_project.jetty.servlet.ServletHandler@6034e75d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1658] - starting org.apache.spark.ui.JettyUtils$$anon$2-15fc442@c6e74dc4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1659] - STARTED @2167ms org.apache.spark.ui.JettyUtils$$anon$2-15fc442@c6e74dc4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1659] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7da10b5b for org.apache.spark.ui.JettyUtils$$anon$2-15fc442
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1659] - Started o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1659] - STARTED @2168ms o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1660] - o.s.j.s.ServletContextHandler@31be6b49{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2e16b08d,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1660] - org.spark_project.jetty.servlet.ServletHandler@2e16b08d added {org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7@b2da8238==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1660] - org.spark_project.jetty.servlet.ServletHandler@2e16b08d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1661] - o.s.j.s.ServletContextHandler@70d8de{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@42561fba,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1661] - org.spark_project.jetty.servlet.ServletHandler@42561fba added {org.apache.spark.ui.JettyUtils$$anon$2-595f4da5@35ad9566==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1661] - org.spark_project.jetty.servlet.ServletHandler@42561fba added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-595f4da5,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1661] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,null}] added {o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1662] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1662] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1663] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - SQL->[{o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1664] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1665] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1665] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1665] - SQL/json->[{o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1665] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1665] - SQL/execution->[{o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,null},[o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1665] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1665] - starting o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1665] - starting o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1665] - starting org.spark_project.jetty.servlet.ServletHandler@2e16b08d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1666] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1666] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1666] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1666] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1666] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7@b2da8238==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1666] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7=org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7@b2da8238==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1666] - starting org.spark_project.jetty.servlet.ServletHandler@2e16b08d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1666] - STARTED @2175ms org.spark_project.jetty.servlet.ServletHandler@2e16b08d
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1666] - starting org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7@b2da8238==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1667] - STARTED @2175ms org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7@b2da8238==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1667] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@408613cc for org.apache.spark.ui.JettyUtils$$anon$2-5b989dc7
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1667] - Started o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1667] - STARTED @2176ms o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1667] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,null}] added {o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1667] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1667] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1667] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,null},[o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1668] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1669] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1669] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1669] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1669] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1669] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1669] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1669] - SQL->[{o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - SQL/json->[{o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - SQL/execution->[{o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1670] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1670] - starting o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1671] - starting o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1671] - starting org.spark_project.jetty.servlet.ServletHandler@42561fba
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1671] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-595f4da5 from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1671] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1671] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1671] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1671] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-595f4da5@35ad9566==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1671] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-595f4da5=org.apache.spark.ui.JettyUtils$$anon$2-595f4da5@35ad9566==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1671] - starting org.spark_project.jetty.servlet.ServletHandler@42561fba
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1672] - STARTED @2180ms org.spark_project.jetty.servlet.ServletHandler@42561fba
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1672] - starting org.apache.spark.ui.JettyUtils$$anon$2-595f4da5@35ad9566==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1672] - STARTED @2181ms org.apache.spark.ui.JettyUtils$$anon$2-595f4da5@35ad9566==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1672] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@11ce2e22 for org.apache.spark.ui.JettyUtils$$anon$2-595f4da5
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1672] - Started o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1672] - STARTED @2181ms o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1673] - o.s.j.s.ServletContextHandler@3af9aa66{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@771158fb,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1673] - org.spark_project.jetty.servlet.ServletHandler@771158fb added {org.spark_project.jetty.servlet.DefaultServlet-91c4a3f@d703d2dc==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1673] - org.spark_project.jetty.servlet.ServletHandler@771158fb added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-91c4a3f,POJO}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1674] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,null}] added {o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1674] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1674] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1674] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1674] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1674] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@70d8de{/SQL/execution/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1675] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - SQL->[{o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@867ba60{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - static/sql->[{o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,null},[o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,null}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1676] - SQL/json->[{o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@55b5e331{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1677] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1677] - SQL/execution->[{o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@31be6b49{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1677] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1677] - starting o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,null}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1677] - starting o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,STARTING}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1677] - starting org.spark_project.jetty.servlet.ServletHandler@771158fb
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1677] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-91c4a3f from default=false
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1677] - filterNameMap={}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1677] - pathFilters=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1677] - servletFilterMap=null
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1678] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-91c4a3f@d703d2dc==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1678] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-91c4a3f=org.spark_project.jetty.servlet.DefaultServlet-91c4a3f@d703d2dc==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1678] - starting org.spark_project.jetty.servlet.ServletHandler@771158fb
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1678] - STARTED @2187ms org.spark_project.jetty.servlet.ServletHandler@771158fb
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1678] - starting org.spark_project.jetty.servlet.DefaultServlet-91c4a3f@d703d2dc==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1678] - STARTED @2187ms org.spark_project.jetty.servlet.DefaultServlet-91c4a3f@d703d2dc==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1678] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@150d80c4 for org.spark_project.jetty.servlet.DefaultServlet-91c4a3f
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1679] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-sql_2.11-2.0.0.jar!/org/apache/spark/sql/execution/ui/static
[INFO ]2016-12-29 17:16:32  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1679] - Started o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,AVAILABLE}
[DEBUG]2016-12-29 17:16:32  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1679] - STARTED @2188ms o.s.j.s.ServletContextHandler@3af9aa66{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:16:32  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1690] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:16:32  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1703] - 服务启动成功，监听端口：10080
[DEBUG]2016-12-29 17:16:36  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):5392] - -Dio.netty.leakDetectionLevel: simple
[DEBUG]2016-12-29 17:16:36  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):5406] - -Dio.netty.recycler.maxCapacity.default: 262144
[DEBUG]2016-12-29 17:16:36  [nioEventLoopGroup-3-1:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):5416] - uri:/antifraud
[INFO ]2016-12-29 17:16:36  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):5419] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:16:36  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):5471] - Rdd服务
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7283] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#6: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#6: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#0, name#1, sex#2]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#0, name#1, sex#2]
        
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7305] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#7: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#7: org.apache.spark.sql.Row
 +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7639] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7703] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[INFO ]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7818] - Code generated in 155.618547 ms
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7825] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7842] -  + declared fields: 4
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7842] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7843] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7843] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7843] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7843] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7844] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7844] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7845] -  + inner classes: 1
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7845] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7846] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:38  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7846] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7848] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7853] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7854] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7855] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7878] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7879] -  + declared fields: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -  + inner classes: 1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7880] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7881] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7882] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7882] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7883] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7895] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7895] -  + declared fields: 1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -  + inner classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7899] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -  + declared fields: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + inner classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7902] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7902] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7902] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7902] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7903] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7918] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7919] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7920] - Parents of final stage: List()
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7922] - Missing parents: List()
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7924] - submitStage(ResultStage 0)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7926] - missing: List()
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7928] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7928] - submitMissingTasks(ResultStage 0)
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8035] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8037] - Put block broadcast_0 locally took  53 ms
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8038] - Putting block broadcast_0 without replication took  54 ms
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8061] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:16:39  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8063] - Added broadcast_0_piece0 in memory on 172.18.10.41:50033 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8064] - Updated info of block broadcast_0_piece0
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8064] - Told master about block broadcast_0_piece0
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8065] - Put block broadcast_0_piece0 locally took  6 ms
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8065] - Putting block broadcast_0_piece0 without replication took  6 ms
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8066] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8070] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8072] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8073] - Adding task set 0.0 with 1 tasks
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8077] - Epoch for TaskSet 0.0: 0
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8079] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:16:39  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8090] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:16:39  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8091] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[INFO ]2016-12-29 17:16:39  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8111] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8117] - Running task 0.0 in stage 0.0 (TID 0)
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8127] - Task 0's epoch is 0
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8130] - Getting local block broadcast_0
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8131] - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8213] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8215] - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8241] - Code generated in 28.193116 ms
[INFO ]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8246] - closed connection
[INFO ]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8256] - Finished task 0.0 in stage 0.0 (TID 0). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:16:39  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8258] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:16:39  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8259] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:16:39  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8262] - Finished task 0.0 in stage 0.0 (TID 0) in 168 ms on localhost (1/1)
[INFO ]2016-12-29 17:16:39  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8263] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8265] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.184 s
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8361] - After removal of stage 0, remaining stages = 0
[INFO ]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8362] - Job 0 finished: count at RddServiceImpl.java:85, took 0.458238 s
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8365] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -  + declared fields: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -  + inner classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8366] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8367] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8367] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8367] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8367] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):8377] - uri:/antifraud
[INFO ]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):8377] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):8378] - Rdd服务
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8401] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#14: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#14: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#8, name#9, sex#10]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#8, name#9, sex#10]
        
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8405] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#15: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#15: org.apache.spark.sql.Row
 +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8412] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8413] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8415] -  + declared fields: 4
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8415] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8415] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8415] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -  + inner classes: 1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8416] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8417] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8418] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8419] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8419] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8421] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8422] -  + declared fields: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8422] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8422] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8422] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -  + inner classes: 1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8424] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8424] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8424] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8425] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + declared fields: 1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + inner classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8427] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8429] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8429] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8429] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -  + declared fields: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8431] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8431] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8431] -  + inner classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8431] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8431] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8431] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8432] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8432] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8432] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8432] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8436] - Got job 1 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8437] - Final stage: ResultStage 1 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8437] - Parents of final stage: List()
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8438] - Missing parents: List()
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8439] - submitStage(ResultStage 1)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8439] - missing: List()
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8439] - Submitting ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8439] - submitMissingTasks(ResultStage 1)
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8448] - Block broadcast_1 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8450] - Put block broadcast_1 locally took  4 ms
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8450] - Putting block broadcast_1 without replication took  4 ms
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8451] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:16:39  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8452] - Added broadcast_1_piece0 in memory on 172.18.10.41:50033 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8454] - Updated info of block broadcast_1_piece0
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8454] - Told master about block broadcast_1_piece0
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8455] - Put block broadcast_1_piece0 locally took  3 ms
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8455] - Putting block broadcast_1_piece0 without replication took  4 ms
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8455] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8455] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8455] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8455] - Adding task set 1.0 with 1 tasks
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8455] - Epoch for TaskSet 1.0: 0
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8456] - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:16:39  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8456] - parentName: , name: TaskSet_1, runningTasks: 0
[INFO ]2016-12-29 17:16:39  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8458] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8458] - Running task 0.0 in stage 1.0 (TID 1)
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8460] - Task 1's epoch is 0
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8460] - Getting local block broadcast_1
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8460] - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8476] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8477] - closed connection
[INFO ]2016-12-29 17:16:39  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8479] - Finished task 0.0 in stage 1.0 (TID 1). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:16:39  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8480] - parentName: , name: TaskSet_1, runningTasks: 0
[DEBUG]2016-12-29 17:16:39  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8480] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:16:39  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8481] - Finished task 0.0 in stage 1.0 (TID 1) in 25 ms on localhost (1/1)
[INFO ]2016-12-29 17:16:39  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8481] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8482] - ResultStage 1 (count at RddServiceImpl.java:85) finished in 0.026 s
[DEBUG]2016-12-29 17:16:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8482] - After removal of stage 1, remaining stages = 0
[INFO ]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8483] - Job 1 finished: count at RddServiceImpl.java:85, took 0.050339 s
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8484] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -  + declared fields: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -  + declared methods: 2
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -  + inner classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -  + outer classes: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -  + outer objects: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:16:39  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):68359] - uri:/antifraud
[INFO ]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):68360] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):68360] - Rdd服务
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68463] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#22: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#16.toString, name#17.toString, sex#18.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#22: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#16, name#17, sex#18]                                                                                                                                                                                                                                                                                           +- LocalRelation <empty>, [userid#16, name#17, sex#18]
        
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68467] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#23: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#16.toString, name#17.toString, sex#18.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#23: org.apache.spark.sql.Row
 +- Relation[userid#16,name#17,sex#18] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                  +- Relation[userid#16,name#17,sex#18] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68474] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68474] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68476] -  + declared fields: 4
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68476] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68476] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68476] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68476] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68477] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68477] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68477] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68477] -  + inner classes: 1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68477] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68477] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68477] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68478] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68479] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68479] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68479] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68481] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68482] -  + declared fields: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68482] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68482] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68482] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68482] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68483] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68483] -  + inner classes: 1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68483] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68483] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68483] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68483] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68484] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68484] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68484] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68485] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -  + declared fields: 1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -  + inner classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68486] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68487] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68487] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68487] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68487] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -  + declared fields: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -  + inner classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68488] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68489] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68489] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68489] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68490] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68490] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68490] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68490] - Got job 2 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68491] - Final stage: ResultStage 2 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68491] - Parents of final stage: List()
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68491] - Missing parents: List()
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68491] - submitStage(ResultStage 2)
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68491] - missing: List()
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68491] - Submitting ResultStage 2 (MapPartitionsRDD[11] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68491] - submitMissingTasks(ResultStage 2)
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68495] - Block broadcast_2 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68495] - Put block broadcast_2 locally took  1 ms
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68496] - Putting block broadcast_2 without replication took  2 ms
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68497] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:17:39  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68498] - Added broadcast_2_piece0 in memory on 172.18.10.41:50033 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68498] - Updated info of block broadcast_2_piece0
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68498] - Told master about block broadcast_2_piece0
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68498] - Put block broadcast_2_piece0 locally took  1 ms
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68498] - Putting block broadcast_2_piece0 without replication took  1 ms
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68499] - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68499] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68499] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68499] - Adding task set 2.0 with 1 tasks
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68499] - Epoch for TaskSet 2.0: 0
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68499] - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:17:39  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68500] - parentName: , name: TaskSet_2, runningTasks: 0
[INFO ]2016-12-29 17:17:39  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68500] - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:17:39  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68501] - Running task 0.0 in stage 2.0 (TID 2)
[DEBUG]2016-12-29 17:17:39  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68502] - Task 2's epoch is 0
[DEBUG]2016-12-29 17:17:39  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68503] - Getting local block broadcast_2
[DEBUG]2016-12-29 17:17:39  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68503] - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:17:39  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68532] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:17:39  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68533] - closed connection
[INFO ]2016-12-29 17:17:39  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68534] - Finished task 0.0 in stage 2.0 (TID 2). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:17:39  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68534] - parentName: , name: TaskSet_2, runningTasks: 0
[DEBUG]2016-12-29 17:17:39  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68535] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:17:39  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68535] - Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on localhost (1/1)
[INFO ]2016-12-29 17:17:39  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68535] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68536] - ResultStage 2 (count at RddServiceImpl.java:85) finished in 0.037 s
[DEBUG]2016-12-29 17:17:39  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68536] - After removal of stage 2, remaining stages = 0
[INFO ]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):68537] - Job 2 finished: count at RddServiceImpl.java:85, took 0.046753 s
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68537] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -  + declared fields: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -  + inner classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68538] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68539] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68539] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68539] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:39  [nioEventLoopGroup-3-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):68539] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):76700] - uri:/antifraud
[INFO ]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):76700] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):76700] - Rdd服务
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76776] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#30: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#24.toString, name#25.toString, sex#26.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#30: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#24, name#25, sex#26]                                                                                                                                                                                                                                                                                           +- LocalRelation <empty>, [userid#24, name#25, sex#26]
        
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76779] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#31: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#24.toString, name#25.toString, sex#26.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#31: org.apache.spark.sql.Row
 +- Relation[userid#24,name#25,sex#26] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                  +- Relation[userid#24,name#25,sex#26] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76783] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76784] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76785] -  + declared fields: 4
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -  + inner classes: 1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76786] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76787] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76788] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76788] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76788] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76789] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76790] -  + declared fields: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76790] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76790] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76790] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76790] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76791] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76791] -  + inner classes: 1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76791] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76791] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76791] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76791] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76792] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76792] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76792] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76792] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -  + declared fields: 1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -  + inner classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76793] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76794] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76794] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76794] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76794] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76794] -  + declared fields: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76795] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76798] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76798] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76798] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76799] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76799] -  + inner classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76799] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76799] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76799] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76800] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76800] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76800] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76800] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76801] - Got job 3 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76801] - Final stage: ResultStage 3 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76801] - Parents of final stage: List()
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76801] - Missing parents: List()
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76802] - submitStage(ResultStage 3)
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76802] - missing: List()
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76802] - Submitting ResultStage 3 (MapPartitionsRDD[15] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76802] - submitMissingTasks(ResultStage 3)
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76806] - Block broadcast_3 stored as values in memory (estimated size 11.2 KB, free 905.9 MB)
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76807] - Put block broadcast_3 locally took  2 ms
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76807] - Putting block broadcast_3 without replication took  2 ms
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76809] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KB, free 905.9 MB)
[INFO ]2016-12-29 17:17:47  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76809] - Added broadcast_3_piece0 in memory on 172.18.10.41:50033 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76810] - Updated info of block broadcast_3_piece0
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76810] - Told master about block broadcast_3_piece0
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76810] - Put block broadcast_3_piece0 locally took  1 ms
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76810] - Putting block broadcast_3_piece0 without replication took  1 ms
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76810] - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76810] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76810] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76810] - Adding task set 3.0 with 1 tasks
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76811] - Epoch for TaskSet 3.0: 0
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76811] - Valid locality levels for TaskSet 3.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:17:47  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76811] - parentName: , name: TaskSet_3, runningTasks: 0
[INFO ]2016-12-29 17:17:47  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76812] - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:17:47  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76812] - Running task 0.0 in stage 3.0 (TID 3)
[DEBUG]2016-12-29 17:17:47  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76813] - Task 3's epoch is 0
[DEBUG]2016-12-29 17:17:47  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76813] - Getting local block broadcast_3
[DEBUG]2016-12-29 17:17:47  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76813] - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:17:47  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76829] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:17:47  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76830] - closed connection
[INFO ]2016-12-29 17:17:47  [Executor task launch worker-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76832] - Finished task 0.0 in stage 3.0 (TID 3). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:17:47  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76832] - parentName: , name: TaskSet_3, runningTasks: 0
[DEBUG]2016-12-29 17:17:47  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76833] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:17:47  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76833] - Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (1/1)
[INFO ]2016-12-29 17:17:47  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76833] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76834] - ResultStage 3 (count at RddServiceImpl.java:85) finished in 0.022 s
[DEBUG]2016-12-29 17:17:47  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76834] - After removal of stage 3, remaining stages = 0
[INFO ]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):76834] - Job 3 finished: count at RddServiceImpl.java:85, took 0.034117 s
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76835] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76835] -  + declared fields: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76835] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76835] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -  + declared methods: 2
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -  + inner classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -  + outer classes: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -  + outer objects: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76836] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76837] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:17:47  [nioEventLoopGroup-3-4:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):76837] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[INFO ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):61] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):69] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):69] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:232):70] - UgiMetrics, User and group related metrics
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.authentication.util.KerberosName.<clinit>(KerberosName.java:88):229] - Kerberos krb5 configuration not found, setting default realm to empty
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:301):232] -  Creating new Groups object
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:46):233] - Trying to load the custom-built native-hadoop library...
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:50):235] - Loaded the native-hadoop library
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:50):236] - Using JniBasedUnixGroupsMapping for Group resolution
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:45):236] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.Groups.<init>(Groups.java:112):286] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.login(UserGroupInformation.java:221):291] - hadoop login
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:156):292] - hadoop login commit
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:186):296] - using local user:NTUserPrincipal: pujjr
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:192):296] - Using user: "NTUserPrincipal: pujjr" with name pujjr
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:202):298] - User entry: "pujjr"
[DEBUG]2016-12-29 17:18:56  [main:org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:826):298] - UGI loginUser:pujjr (auth:SIMPLE)
[WARN ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):305] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):306] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):306] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):328] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):328] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):329] - Changing view acls groups to: 
[INFO ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):329] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):330] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[DEBUG]2016-12-29 17:18:56  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):338] - Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):404] - Using SLF4J as the default logging framework
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):407] - java.nio.Buffer.address: available
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):407] - sun.misc.Unsafe.theUnsafe: available
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):408] - sun.misc.Unsafe.copyMemory: available
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):408] - java.nio.Bits.unaligned: true
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):409] - Platform: Windows
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):410] - Java version: 8
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):410] - -Dio.netty.noUnsafe: false
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):410] - sun.misc.Unsafe: available
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):410] - -Dio.netty.noJavassist: false
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):486] - Javassist: available
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):486] - -Dio.netty.tmpdir: C:\Users\pujjr\AppData\Local\Temp (java.io.tmpdir)
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):486] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):486] - -Dio.netty.noPreferDirect: false
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):488] - Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):491] - Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):499] - -Dio.netty.eventLoopThreads: 8
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):512] - -Dio.netty.noKeySetOptimization: false
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):512] - -Dio.netty.selectorAutoRebuildThreshold: 512
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):543] - -Dio.netty.allocator.numHeapArenas: 8
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):543] - -Dio.netty.allocator.numDirectArenas: 8
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):543] - -Dio.netty.allocator.pageSize: 8192
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):543] - -Dio.netty.allocator.maxOrder: 11
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):544] - -Dio.netty.allocator.chunkSize: 16777216
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):544] - -Dio.netty.allocator.tinyCacheSize: 512
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):544] - -Dio.netty.allocator.smallCacheSize: 256
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):544] - -Dio.netty.allocator.normalCacheSize: 64
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):544] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):544] - -Dio.netty.allocator.cacheTrimInterval: 8192
[DEBUG]2016-12-29 17:18:56  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):575] - -Dio.netty.initialSeedUniquifier: 0x923ec09e27127fd3 (took 6 ms)
[DEBUG]2016-12-29 17:18:57  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):595] - -Dio.netty.allocator.type: unpooled
[DEBUG]2016-12-29 17:18:57  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):596] - -Dio.netty.threadLocalDirectBufferSize: 65536
[DEBUG]2016-12-29 17:18:57  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:86):649] - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
[DEBUG]2016-12-29 17:18:57  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):650] - \proc\sys\net\core\somaxconn: 200 (non-existent)
[DEBUG]2016-12-29 17:18:57  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):657] - Shuffle server started on port :50083
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):661] - Successfully started service 'sparkDriver' on port 50083.
[DEBUG]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):662] - Using serializer: class org.apache.spark.serializer.JavaSerializer
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):678] - Registering MapOutputTracker
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):693] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):774] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-028273d4-e756-49af-a08b-fdaa92b7a4b5
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):791] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):855] - Registering OutputCommitCoordinator
[DEBUG]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):881] - Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:176):933] - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):935] - Logging initialized @1436ms
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):944] - o.s.j.s.ServletContextHandler@4044fb95{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@aa549e5,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):947] - org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):948] - org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-72758afa,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):949] - o.s.j.s.ServletContextHandler@40cb698e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3382f8ae,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):949] - org.spark_project.jetty.servlet.ServletHandler@3382f8ae added {org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):950] - org.spark_project.jetty.servlet.ServletHandler@3382f8ae added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-60641ec8,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):951] - o.s.j.s.ServletContextHandler@75390459{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7756c3cd,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):951] - org.spark_project.jetty.servlet.ServletHandler@7756c3cd added {org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):952] - org.spark_project.jetty.servlet.ServletHandler@7756c3cd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2313052e,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):952] - o.s.j.s.ServletContextHandler@2bd2b28e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@16746061,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):952] - org.spark_project.jetty.servlet.ServletHandler@16746061 added {org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):952] - org.spark_project.jetty.servlet.ServletHandler@16746061 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):953] - o.s.j.s.ServletContextHandler@52045dbe{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@674658f7,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):953] - org.spark_project.jetty.servlet.ServletHandler@674658f7 added {org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):953] - org.spark_project.jetty.servlet.ServletHandler@674658f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):953] - o.s.j.s.ServletContextHandler@565b064f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@26425897,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):953] - org.spark_project.jetty.servlet.ServletHandler@26425897 added {org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):954] - org.spark_project.jetty.servlet.ServletHandler@26425897 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-73163d48,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):954] - o.s.j.s.ServletContextHandler@56a4479a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62163b39,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):954] - org.spark_project.jetty.servlet.ServletHandler@62163b39 added {org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):954] - org.spark_project.jetty.servlet.ServletHandler@62163b39 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):954] - o.s.j.s.ServletContextHandler@62f4ff3b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1698fc68,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):955] - org.spark_project.jetty.servlet.ServletHandler@1698fc68 added {org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):955] - org.spark_project.jetty.servlet.ServletHandler@1698fc68 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-4504d271,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):955] - o.s.j.s.ServletContextHandler@65b3a85a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@34997338,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):955] - org.spark_project.jetty.servlet.ServletHandler@34997338 added {org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):955] - org.spark_project.jetty.servlet.ServletHandler@34997338 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-57eda880,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):956] - o.s.j.s.ServletContextHandler@2b5825fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53d1b9b3,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):956] - org.spark_project.jetty.servlet.ServletHandler@53d1b9b3 added {org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):956] - org.spark_project.jetty.servlet.ServletHandler@53d1b9b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2cae1042,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):959] - o.s.j.s.ServletContextHandler@788fcafb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4febb875,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):959] - org.spark_project.jetty.servlet.ServletHandler@4febb875 added {org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):959] - org.spark_project.jetty.servlet.ServletHandler@4febb875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-25e2a451,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):959] - o.s.j.s.ServletContextHandler@1698ee84{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c626be,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):959] - org.spark_project.jetty.servlet.ServletHandler@10c626be added {org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):960] - org.spark_project.jetty.servlet.ServletHandler@10c626be added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):960] - o.s.j.s.ServletContextHandler@63b1d4fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@42e3ede4,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):960] - org.spark_project.jetty.servlet.ServletHandler@42e3ede4 added {org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):960] - org.spark_project.jetty.servlet.ServletHandler@42e3ede4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):960] - o.s.j.s.ServletContextHandler@75459c75{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@183e8023,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):961] - org.spark_project.jetty.servlet.ServletHandler@183e8023 added {org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):961] - org.spark_project.jetty.servlet.ServletHandler@183e8023 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-45efc20d,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):962] - o.s.j.s.ServletContextHandler@30bcf3c1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2a3c96e3,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):962] - org.spark_project.jetty.servlet.ServletHandler@2a3c96e3 added {org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):962] - org.spark_project.jetty.servlet.ServletHandler@2a3c96e3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-15cafec7,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):963] - o.s.j.s.ServletContextHandler@5b444398{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@cb191ca,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):963] - org.spark_project.jetty.servlet.ServletHandler@cb191ca added {org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):963] - org.spark_project.jetty.servlet.ServletHandler@cb191ca added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-42f48531,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):966] - o.s.j.s.ServletContextHandler@6821ea29{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@338494fa,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):966] - org.spark_project.jetty.servlet.ServletHandler@338494fa added {org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):966] - org.spark_project.jetty.servlet.ServletHandler@338494fa added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):966] - o.s.j.s.ServletContextHandler@758c83d8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@129b4fe2,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):966] - org.spark_project.jetty.servlet.ServletHandler@129b4fe2 added {org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):966] - org.spark_project.jetty.servlet.ServletHandler@129b4fe2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):967] - o.s.j.s.ServletContextHandler@10993713{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58359ebd,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):967] - org.spark_project.jetty.servlet.ServletHandler@58359ebd added {org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):967] - org.spark_project.jetty.servlet.ServletHandler@58359ebd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):967] - o.s.j.s.ServletContextHandler@72cf2de5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2bb7bd00,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):968] - org.spark_project.jetty.servlet.ServletHandler@2bb7bd00 added {org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):968] - org.spark_project.jetty.servlet.ServletHandler@2bb7bd00 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):968] - o.s.j.s.ServletContextHandler@45c8d09f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53812a9b,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):975] - org.spark_project.jetty.servlet.ServletHandler@53812a9b added {org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):975] - org.spark_project.jetty.servlet.ServletHandler@53812a9b added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-5974109,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):976] - o.s.j.s.ServletContextHandler@502f1f4c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6f8f9349,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):976] - org.spark_project.jetty.servlet.ServletHandler@6f8f9349 added {org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):976] - org.spark_project.jetty.servlet.ServletHandler@6f8f9349 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):977] - o.s.j.s.ServletContextHandler@4fbda97b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@75f5fd58,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):980] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):980] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-f73dcd6,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):981] - o.s.j.s.ServletContextHandler@30d4b288{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):981] - org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a added {org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):981] - org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):998] - org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c mime types IncludeExclude@207ea13{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4bff1903,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62dae540}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):999] - org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c added {o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):999] - org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16 mime types IncludeExclude@654d8173{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@56c9bbd8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@630cb4a4}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):999] - org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16 added {o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):999] - org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc mime types IncludeExclude@f79a760{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@14f5da2c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@12dae582}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc added {o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1000] - org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29 mime types IncludeExclude@5b057c8c{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1eb6749b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@652a7737}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29 added {o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1000] - org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d mime types IncludeExclude@2bef51f2{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@650eab8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@30f5a68a}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1005] - org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d added {o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1005] - org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956 mime types IncludeExclude@4f2c9ba6{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4e28bdd1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@53f48368}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1005] - org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956 added {o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1006] - org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9 mime types IncludeExclude@f0e995e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4c37b5b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@73db4768}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1006] - org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9 added {o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1007] - org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed mime types IncludeExclude@3c435123{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@50fe837a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3a62c01e}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1007] - org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed added {o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1007] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663 mime types IncludeExclude@5ce33a58{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@78a287ed,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@546ccad7}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1008] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663 added {o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1008] - org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287 mime types IncludeExclude@1623134f{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7a527389,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@485a3466}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1009] - org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287 added {o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1009] - org.spark_project.jetty.servlets.gzip.GzipHandler@25748410 mime types IncludeExclude@2b43529a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4264b240,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b04476e}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1009] - org.spark_project.jetty.servlets.gzip.GzipHandler@25748410 added {o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1009] - org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a mime types IncludeExclude@6bb75258{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@c260bdc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@75e01201}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1010] - org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a added {o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1010] - org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b mime types IncludeExclude@76f7d241{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4a335fa8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3f363cf5}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1010] - org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b added {o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1010] - org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1 mime types IncludeExclude@4baf352a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1bb1fde8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@15eebbff}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1010] - org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1 added {o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1011] - org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11 mime types IncludeExclude@30990c1b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2453f95d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@44828f6b}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1013] - org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11 added {o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1013] - org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d mime types IncludeExclude@553f1d75{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6e1d8f9e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3e34ace1}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1013] - org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d added {o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1014] - org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067 mime types IncludeExclude@4f071df8{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4de41af9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@56ace400}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1014] - org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067 added {o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1014] - org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea mime types IncludeExclude@305f7627{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5d018107,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6cbcf243}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1014] - org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea added {o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1014] - org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25 mime types IncludeExclude@62435e70{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@339bf286,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@38be305c}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1018] - org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25 added {o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1018] - org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad mime types IncludeExclude@5ed731d0{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3234f74e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7bc10d84}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1018] - org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad added {o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1019] - org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372 mime types IncludeExclude@40e10ff8{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@557a1e2d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@26a4842b}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1019] - org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372 added {o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1019] - org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe mime types IncludeExclude@366ef90e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@33e01298,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@31e75d13}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1019] - org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe added {o.s.j.s.ServletContextHandler@502f1f4c{/,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1019] - org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86 mime types IncludeExclude@4b3c354a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@78fb9a67,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@73ff4fae}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86 added {o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1020] - org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c mime types IncludeExclude@b968a76{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2f9a01c1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2611b9a3}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c added {o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1026] - org.spark_project.jetty.server.Server@2dbf4cbd added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1034] - HttpConnectionFactory@1de5f0ef{HTTP/1.1} added {HttpConfiguration@376a312c{32768/8192,8192/8192,https://:0,[]},POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1036] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@2dbf4cbd,UNMANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1036] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1037] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1037] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@7c56e013,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1037] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {HttpConnectionFactory@1de5f0ef{HTTP/1.1},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1039] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af,MANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1040] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c] added {org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1040] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1040] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc] added {org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1040] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29] added {org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1040] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1040] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956] added {org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1040] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9] added {org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1041] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed] added {org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1041] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1042] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1042] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410] added {org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1042] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1042] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1044] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1] added {org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1044] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11] added {org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1044] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1044] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067] added {org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1044] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea] added {org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1047] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25] added {org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1047] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad] added {org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1048] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372] added {org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1048] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1048] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86] added {org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1048] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c] added {org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1049] - org.spark_project.jetty.server.Server@2dbf4cbd added {ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040},AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - org.spark_project.jetty.server.Server@2dbf4cbd added {org.spark_project.jetty.server.handler.ErrorHandler@6a66a204,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - org.spark_project.jetty.server.Server@2dbf4cbd added {org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c],AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1051] - starting org.spark_project.jetty.server.Server@2dbf4cbd
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1058] - jetty-9.2.z-SNAPSHOT
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1068] - starting org.spark_project.jetty.server.Server@2dbf4cbd
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1068] - starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1069] - STARTED @1570ms SparkUI{STARTED,8<=8<=200,i=6,q=0}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1069] - starting org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1069] - starting org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1069] - STARTED @1571ms org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1070] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1071] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1071] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1071] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1071] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1071] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1071] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1071] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1072] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1075] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1075] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1075] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1076] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1076] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1076] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1076] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1077] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1077] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1077] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1077] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1077] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1077] - starting o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1078] - starting o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1079] - starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1080] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-72758afa from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1080] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1081] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1081] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1081] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1081] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-72758afa=org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1081] - starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1082] - STARTED @1583ms org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1082] - starting org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1083] - STARTED @1584ms org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1084] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@6d0b5baf for org.apache.spark.ui.JettyUtils$$anon$2-72758afa
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1084] - Started o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1084] - STARTED @1586ms o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1084] - STARTED @1586ms org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1084] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1084] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1084] - starting o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1085] - starting o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1085] - starting org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1085] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1085] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1085] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1085] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1085] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1085] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-60641ec8=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1085] - starting org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1086] - STARTED @1587ms org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1086] - starting org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1086] - STARTED @1587ms org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1086] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@2a3591c5 for org.apache.spark.ui.JettyUtils$$anon$2-60641ec8
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1086] - Started o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1086] - STARTED @1588ms o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1086] - STARTED @1588ms org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1086] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1086] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1087] - starting o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1087] - starting o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1087] - starting org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1087] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2313052e from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1087] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1087] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1087] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1087] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1087] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2313052e=org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1088] - starting org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1088] - STARTED @1589ms org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1088] - starting org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1088] - STARTED @1589ms org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1088] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@346a361 for org.apache.spark.ui.JettyUtils$$anon$2-2313052e
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1088] - Started o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1088] - STARTED @1590ms o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1088] - STARTED @1590ms org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1088] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1088] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1089] - starting o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1089] - starting o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1089] - starting org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1089] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1089] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1089] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1089] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1089] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1090] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1090] - starting org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1090] - STARTED @1591ms org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1090] - starting org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1090] - STARTED @1592ms org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1090] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@186978a6 for org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1091] - Started o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1091] - STARTED @1592ms o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1091] - STARTED @1592ms org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1091] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1091] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1091] - starting o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1091] - starting o.s.j.s.ServletContextHandler@52045dbe{/stages,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1091] - starting org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1091] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1091] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1092] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1092] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1092] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1092] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1092] - starting org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1092] - STARTED @1594ms org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1092] - starting org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1092] - STARTED @1594ms org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1093] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@482d776b for org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1093] - Started o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1093] - STARTED @1594ms o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1093] - STARTED @1594ms org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1093] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1093] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1093] - starting o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1093] - starting o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1093] - starting org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1093] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-73163d48 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1094] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1094] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1094] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1094] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1094] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-73163d48=org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1094] - starting org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1094] - STARTED @1596ms org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1094] - starting org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1094] - STARTED @1596ms org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1095] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@132ddbab for org.apache.spark.ui.JettyUtils$$anon$2-73163d48
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1095] - Started o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1095] - STARTED @1596ms o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1095] - STARTED @1596ms org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1095] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1095] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1095] - starting o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1095] - starting o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1095] - starting org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1095] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1096] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1096] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1096] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1096] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1096] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1096] - starting org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1096] - STARTED @1598ms org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1097] - starting org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1097] - STARTED @1598ms org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1097] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@acb0951 for org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1097] - Started o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1097] - STARTED @1598ms o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1097] - STARTED @1598ms org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1097] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1097] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1097] - starting o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1097] - starting o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1097] - starting org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1098] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-4504d271 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1098] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1098] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1098] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1098] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1098] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-4504d271=org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1098] - starting org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1098] - STARTED @1600ms org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1099] - starting org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1099] - STARTED @1600ms org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1099] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@267f474e for org.apache.spark.ui.JettyUtils$$anon$2-4504d271
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1099] - Started o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1099] - STARTED @1600ms o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1099] - STARTED @1600ms org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1099] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1099] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1099] - starting o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1099] - starting o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1100] - starting org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1100] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-57eda880 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1100] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1100] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1100] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1100] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1100] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-57eda880=org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1100] - starting org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1100] - STARTED @1602ms org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1100] - starting org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1101] - STARTED @1602ms org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1101] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@28276e50 for org.apache.spark.ui.JettyUtils$$anon$2-57eda880
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1101] - Started o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1101] - STARTED @1602ms o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1101] - STARTED @1602ms org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1101] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1101] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1101] - starting o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1101] - starting o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1101] - starting org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1101] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1101] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1102] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1102] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1102] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1102] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2cae1042=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1102] - starting org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1103] - STARTED @1604ms org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1103] - starting org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1104] - STARTED @1605ms org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1104] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3efe7086 for org.apache.spark.ui.JettyUtils$$anon$2-2cae1042
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1104] - Started o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1104] - STARTED @1605ms o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1104] - STARTED @1605ms org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1104] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1104] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1105] - starting o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1105] - starting o.s.j.s.ServletContextHandler@788fcafb{/storage,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1105] - starting org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1105] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1105] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1105] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1105] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1106] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1106] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-25e2a451=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1110] - starting org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1110] - STARTED @1612ms org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1111] - starting org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1111] - STARTED @1612ms org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1111] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@741b3bc3 for org.apache.spark.ui.JettyUtils$$anon$2-25e2a451
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1111] - Started o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1111] - STARTED @1612ms o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1111] - STARTED @1613ms org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1111] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1111] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1111] - starting o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1111] - starting o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1112] - starting org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1112] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1112] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1112] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1112] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1112] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1112] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1112] - starting org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1112] - STARTED @1614ms org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1112] - starting org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1112] - STARTED @1614ms org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1113] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@63648ee9 for org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1113] - Started o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1113] - STARTED @1614ms o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1113] - STARTED @1614ms org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1113] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1113] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1113] - starting o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1114] - starting o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1114] - starting org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1114] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1114] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1114] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1114] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1114] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1114] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1115] - starting org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1115] - STARTED @1616ms org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1115] - starting org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1115] - STARTED @1616ms org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1115] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@45be7cd5 for org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1115] - Started o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1115] - STARTED @1617ms o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1115] - STARTED @1617ms org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1115] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1115] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1115] - starting o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1116] - starting o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1116] - starting org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1116] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1116] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1116] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1116] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1116] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1116] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-45efc20d=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1116] - starting org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1117] - STARTED @1618ms org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1117] - starting org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1117] - STARTED @1618ms org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1117] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3185fa6b for org.apache.spark.ui.JettyUtils$$anon$2-45efc20d
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1117] - Started o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1117] - STARTED @1618ms o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1117] - STARTED @1619ms org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1117] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1117] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1117] - starting o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1122] - starting o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1123] - starting org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1123] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1123] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1139] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1139] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1140] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1140] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-15cafec7=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1140] - starting org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1140] - STARTED @1641ms org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1140] - starting org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1140] - STARTED @1642ms org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1140] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5b58ed3c for org.apache.spark.ui.JettyUtils$$anon$2-15cafec7
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1140] - Started o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1140] - STARTED @1642ms o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1140] - STARTED @1642ms org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1141] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1141] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1141] - starting o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1141] - starting o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1141] - starting org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1141] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-42f48531 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1141] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1141] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1141] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1161] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1161] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-42f48531=org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1161] - starting org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1161] - STARTED @1662ms org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1161] - starting org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1161] - STARTED @1663ms org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1161] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3a320ade for org.apache.spark.ui.JettyUtils$$anon$2-42f48531
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1161] - Started o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1663ms o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1663ms org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1162] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1162] - starting o.s.j.s.ServletContextHandler@6821ea29{/executors,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1162] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1162] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1162] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1162] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1162] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1163] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1163] - starting org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1163] - STARTED @1664ms org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1163] - starting org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1163] - STARTED @1664ms org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1167] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7813cb11 for org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1167] - Started o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1167] - STARTED @1668ms o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1167] - STARTED @1668ms org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1167] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1167] - starting o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1168] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1168] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1168] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1168] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1168] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1168] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1168] - starting org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1168] - STARTED @1670ms org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1168] - starting org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1168] - STARTED @1670ms org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1169] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@21005f6c for org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1169] - Started o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1169] - STARTED @1670ms o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1169] - STARTED @1670ms org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1169] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1169] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1169] - starting o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1169] - starting o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1169] - starting org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1169] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1169] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1169] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1170] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1170] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1170] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1170] - starting org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1170] - STARTED @1672ms org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1170] - starting org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1170] - STARTED @1672ms org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1170] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@545de5a4 for org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1170] - Started o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1171] - STARTED @1672ms o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1171] - STARTED @1672ms org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1171] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1171] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1171] - starting o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1171] - starting o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1171] - starting org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1171] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1171] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1171] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1171] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1171] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1172] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1172] - starting org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1673ms org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1172] - starting org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1673ms org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1172] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@ab7a938 for org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1172] - Started o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1674ms o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1674ms org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1172] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1172] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1172] - starting o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1173] - starting o.s.j.s.ServletContextHandler@45c8d09f{/static,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1173] - starting org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1173] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-5974109 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1173] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1173] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1173] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1173] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1173] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-5974109=org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1173] - starting org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1675ms org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1174] - starting org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1675ms org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1174] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@4648ce9 for org.spark_project.jetty.servlet.DefaultServlet-5974109
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1179] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-core_2.11-2.0.0.jar!/org/apache/spark/ui/static
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1179] - Started o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1179] - STARTED @1681ms o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1179] - STARTED @1681ms org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1179] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1179] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1180] - starting o.s.j.s.ServletContextHandler@502f1f4c{/,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1180] - starting o.s.j.s.ServletContextHandler@502f1f4c{/,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1180] - starting org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1180] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1180] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1180] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1180] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1180] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1181] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1181] - starting org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1181] - STARTED @1682ms org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1181] - starting org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1181] - STARTED @1682ms org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1181] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@305f031 for org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1181] - Started o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1181] - STARTED @1683ms o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1181] - STARTED @1683ms org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1181] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1181] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1182] - starting o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1182] - starting o.s.j.s.ServletContextHandler@4fbda97b{/api,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1182] - starting org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1183] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-f73dcd6 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1183] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1183] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1184] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1184] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1184] - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-f73dcd6=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.doStart(ServletHandler.java:165):1184] - Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1185] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1185] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1185] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-f73dcd6 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1185] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1185] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1185] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1185] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1185] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1185] - servletNameMap={org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false, org.glassfish.jersey.servlet.ServletContainer-f73dcd6=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1185] - starting org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1186] - STARTED @1687ms org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1187] - starting org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1689ms org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1188] - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1689ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1188] - Started o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1689ms o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1690ms org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1188] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1188] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1188] - starting o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1188] - starting o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1189] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1189] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1189] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1189] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1189] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1189] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1189] - starting org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1189] - STARTED @1691ms org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1691ms org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1190] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1536602f for org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1190] - Started o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1691ms o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1691ms org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1691ms org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1197] - starting ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1198] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1199] - starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1199] - STARTED @1701ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1199] - starting HttpConnectionFactory@1de5f0ef{HTTP/1.1}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1199] - STARTED @1701ms HttpConnectionFactory@1de5f0ef{HTTP/1.1}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1199] - starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1202] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=-1 selected=-1
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1204] - STARTED @1705ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=0 selected=0
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1205] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=-1 selected=-1
[DEBUG]2016-12-29 17:18:57  [SparkUI-35-selector-ServerConnectorManager@16f7b4af/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1206] - Starting Thread[SparkUI-35-selector-ServerConnectorManager@16f7b4af/0,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=0 selected=0
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1206] - STARTED @1708ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=0 selected=0
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1206] - STARTED @1708ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af
[DEBUG]2016-12-29 17:18:57  [SparkUI-35-selector-ServerConnectorManager@16f7b4af/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1206] - Selector loop waiting on select
[DEBUG]2016-12-29 17:18:57  [SparkUI-37-selector-ServerConnectorManager@16f7b4af/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1207] - Starting Thread[SparkUI-37-selector-ServerConnectorManager@16f7b4af/1,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=0 selected=0
[DEBUG]2016-12-29 17:18:57  [SparkUI-37-selector-ServerConnectorManager@16f7b4af/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1207] - Selector loop waiting on select
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1207] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040} added {acceptor-0@36b0fcd5,POJO}
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1207] - Started ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1207] - STARTED @1709ms ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1211] - Started @1713ms
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1211] - STARTED @1713ms org.spark_project.jetty.server.Server@2dbf4cbd
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1211] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1213] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1304] - Starting executor ID driver on host localhost
[DEBUG]2016-12-29 17:18:57  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):1325] - Shuffle server started on port :50092
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1325] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50092.
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1326] - Server created on 172.18.10.41:50092
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1326] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 50092)
[INFO ]2016-12-29 17:18:57  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1328] - Registering block manager 172.18.10.41:50092 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 50092)
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1331] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 50092)
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1439] - o.s.j.s.ServletContextHandler@2899a8db{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1e8823d2,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1439] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1439] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-c1a4620,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1441] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}] added {o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1441] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1441] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1442] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1443] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1443] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1448] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1448] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1449] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1450] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1450] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1450] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1450] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1450] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1450] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1451] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1451] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1451] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-c1a4620=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1451] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1451] - STARTED @1953ms org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1452] - starting org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1452] - STARTED @1953ms org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1452] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5710768a for org.apache.spark.ui.JettyUtils$$anon$2-c1a4620
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1452] - Started o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1452] - STARTED @1953ms o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1466] - Use an existing SparkContext, some configuration may not take effect.
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1490] - o.s.j.s.ServletContextHandler@6034e75d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@15fc442,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1490] - org.spark_project.jetty.servlet.ServletHandler@15fc442 added {org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1491] - org.spark_project.jetty.servlet.ServletHandler@15fc442 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1491] - o.s.j.s.ServletContextHandler@456abb66{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2a3a299,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1491] - org.spark_project.jetty.servlet.ServletHandler@2a3a299 added {org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1491] - org.spark_project.jetty.servlet.ServletHandler@2a3a299 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1491] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null}] added {o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1491] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1492] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1493] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1494] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1494] - starting o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1495] - starting o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1495] - starting org.spark_project.jetty.servlet.ServletHandler@15fc442
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1496] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1496] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1496] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1496] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1496] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1496] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb=org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1496] - starting org.spark_project.jetty.servlet.ServletHandler@15fc442
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1497] - STARTED @1998ms org.spark_project.jetty.servlet.ServletHandler@15fc442
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1497] - starting org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1497] - STARTED @1998ms org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1497] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@31be6b49 for org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1497] - Started o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1497] - STARTED @1999ms o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1499] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null}] added {o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1500] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1501] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1501] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1501] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1501] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1502] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1502] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1502] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1502] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1502] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1502] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1502] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1503] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1504] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1507] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1507] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1507] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1507] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1508] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1508] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1508] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1508] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1508] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1508] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1509] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1509] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1509] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1509] - starting o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1510] - starting o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1510] - starting org.spark_project.jetty.servlet.ServletHandler@2a3a299
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1510] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1511] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1511] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1511] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1511] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1511] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b=org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1511] - starting org.spark_project.jetty.servlet.ServletHandler@2a3a299
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1511] - STARTED @2013ms org.spark_project.jetty.servlet.ServletHandler@2a3a299
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1512] - starting org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1512] - STARTED @2013ms org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1512] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5b989dc7 for org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1512] - Started o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1512] - STARTED @2014ms o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1513] - o.s.j.s.ServletContextHandler@42561fba{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@595f4da5,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1513] - org.spark_project.jetty.servlet.ServletHandler@595f4da5 added {org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1514] - org.spark_project.jetty.servlet.ServletHandler@595f4da5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-46b695ec,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1515] - o.s.j.s.ServletContextHandler@408613cc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@325f7fa9,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1515] - org.spark_project.jetty.servlet.ServletHandler@325f7fa9 added {org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1515] - org.spark_project.jetty.servlet.ServletHandler@325f7fa9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1515] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null}] added {o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1516] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1516] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1516] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1516] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1517] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - SQL/execution->[{o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null},[o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1519] - starting o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1519] - starting o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1519] - starting org.spark_project.jetty.servlet.ServletHandler@595f4da5
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1519] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-46b695ec from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1520] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1520] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1520] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1520] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1520] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-46b695ec=org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1520] - starting org.spark_project.jetty.servlet.ServletHandler@595f4da5
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1520] - STARTED @2022ms org.spark_project.jetty.servlet.ServletHandler@595f4da5
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1520] - starting org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1520] - STARTED @2022ms org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1521] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@13cda7c9 for org.apache.spark.ui.JettyUtils$$anon$2-46b695ec
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1521] - Started o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1521] - STARTED @2022ms o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1521] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null}] added {o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null},[o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1524] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1524] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1524] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1524] - SQL/execution->[{o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1524] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1524] - starting o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1524] - starting o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1524] - starting org.spark_project.jetty.servlet.ServletHandler@325f7fa9
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1524] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1524] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1525] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1525] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1525] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1525] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22=org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1525] - starting org.spark_project.jetty.servlet.ServletHandler@325f7fa9
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1526] - STARTED @2027ms org.spark_project.jetty.servlet.ServletHandler@325f7fa9
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1526] - starting org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1526] - STARTED @2027ms org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1526] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3af9aa66 for org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1526] - Started o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1526] - STARTED @2028ms o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1527] - o.s.j.s.ServletContextHandler@150d80c4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6826c41e,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1527] - org.spark_project.jetty.servlet.ServletHandler@6826c41e added {org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1527] - org.spark_project.jetty.servlet.ServletHandler@6826c41e added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-3003697,POJO}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1527] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null}] added {o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1528] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1530] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1531] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - static/sql->[{o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null},[o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - SQL/execution->[{o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1532] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1533] - starting o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1533] - starting o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,STARTING}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1533] - starting org.spark_project.jetty.servlet.ServletHandler@6826c41e
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1533] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-3003697 from default=false
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1533] - filterNameMap={}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1533] - pathFilters=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1533] - servletFilterMap=null
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1533] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1533] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-3003697=org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1533] - starting org.spark_project.jetty.servlet.ServletHandler@6826c41e
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1534] - STARTED @2035ms org.spark_project.jetty.servlet.ServletHandler@6826c41e
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1534] - starting org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1534] - STARTED @2035ms org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1534] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@1d269ed7 for org.spark_project.jetty.servlet.DefaultServlet-3003697
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1534] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-sql_2.11-2.0.0.jar!/org/apache/spark/sql/execution/ui/static
[INFO ]2016-12-29 17:18:57  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1534] - Started o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,AVAILABLE}
[DEBUG]2016-12-29 17:18:57  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1534] - STARTED @2036ms o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:18:57  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1546] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:18:57  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1559] - 服务启动成功，监听端口：10080
[DEBUG]2016-12-29 17:19:00  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):4258] - -Dio.netty.leakDetectionLevel: simple
[DEBUG]2016-12-29 17:19:00  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):4276] - -Dio.netty.recycler.maxCapacity.default: 262144
[DEBUG]2016-12-29 17:19:00  [nioEventLoopGroup-3-1:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):4284] - uri:/antifraud
[INFO ]2016-12-29 17:19:00  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):4287] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:19:00  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):4341] - Rdd服务
[DEBUG]2016-12-29 17:19:02  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6188] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#6: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#6: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#0, name#1, sex#2]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#0, name#1, sex#2]
        
[DEBUG]2016-12-29 17:19:02  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6210] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#7: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#7: org.apache.spark.sql.Row
 +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:19:02  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6512] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:19:02  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6572] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[INFO ]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6686] - Code generated in 151.861767 ms
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6692] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6709] -  + declared fields: 4
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6710] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6710] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6711] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6711] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6711] -  + declared methods: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6712] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6712] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6712] -  + inner classes: 1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6713] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6714] -  + outer classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6715] -  + outer objects: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6717] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6722] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6723] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6724] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6746] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6748] -  + declared fields: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6748] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -  + declared methods: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -  + inner classes: 1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -  + outer classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6749] -  + outer objects: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6750] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6751] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6751] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6751] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6761] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6761] -  + declared fields: 1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6761] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6761] -  + declared methods: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6762] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6762] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6762] -  + inner classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6762] -  + outer classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6762] -  + outer objects: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6762] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6763] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6763] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6763] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6764] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + declared fields: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + declared methods: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + inner classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + outer classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6767] -  + outer objects: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6767] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6768] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6768] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6768] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6769] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6782] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6783] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6784] - Parents of final stage: List()
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6785] - Missing parents: List()
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6787] - submitStage(ResultStage 0)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6789] - missing: List()
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6791] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6791] - submitMissingTasks(ResultStage 0)
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6903] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6905] - Put block broadcast_0 locally took  58 ms
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6907] - Putting block broadcast_0 without replication took  60 ms
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6930] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:19:03  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6932] - Added broadcast_0_piece0 in memory on 172.18.10.41:50092 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6933] - Updated info of block broadcast_0_piece0
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6933] - Told master about block broadcast_0_piece0
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6934] - Put block broadcast_0_piece0 locally took  5 ms
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6934] - Putting block broadcast_0_piece0 without replication took  5 ms
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6935] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6938] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6939] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6939] - Adding task set 0.0 with 1 tasks
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6943] - Epoch for TaskSet 0.0: 0
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6945] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:19:03  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6955] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:19:03  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6955] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[INFO ]2016-12-29 17:19:03  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6973] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6979] - Running task 0.0 in stage 0.0 (TID 0)
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6988] - Task 0's epoch is 0
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6990] - Getting local block broadcast_0
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6991] - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7033] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7041] - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7056] - Code generated in 22.4847 ms
[INFO ]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7060] - closed connection
[INFO ]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7073] - Finished task 0.0 in stage 0.0 (TID 0). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:19:03  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7074] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:19:03  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7076] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:19:03  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7079] - Finished task 0.0 in stage 0.0 (TID 0) in 121 ms on localhost (1/1)
[INFO ]2016-12-29 17:19:03  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7080] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7083] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.135 s
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7176] - After removal of stage 0, remaining stages = 0
[INFO ]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7177] - Job 0 finished: count at RddServiceImpl.java:85, took 0.408071 s
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7197] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7198] -  + declared fields: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7198] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7198] -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7198] -  + declared methods: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7198] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7198] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7198] -  + inner classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7199] -  + outer classes: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7199] -      org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7199] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7199] -  + outer objects: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7199] -      <function0>
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7200] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7200] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7201] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7202] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7202] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7203] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7203] -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7204] -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7204] - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7205] -  + declared fields: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7205] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -  + declared methods: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -  + inner classes: 1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -  + outer classes: 1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -  + outer objects: 1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7206] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7207] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7207] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7207] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7207] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7207] -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7207] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7209] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -  + declared fields: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -  + declared methods: 2
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -  + inner classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -  + outer classes: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -  + outer objects: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7210] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7211] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7211] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7211] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7212] - Starting job: collect at RddServiceImpl.java:86
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7214] - Got job 1 (collect at RddServiceImpl.java:86) with 1 output partitions
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7214] - Final stage: ResultStage 1 (collect at RddServiceImpl.java:86)
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7214] - Parents of final stage: List()
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7214] - Missing parents: List()
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7215] - submitStage(ResultStage 1)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7215] - missing: List()
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7215] - Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7215] - submitMissingTasks(ResultStage 1)
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7217] - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7217] - Put block broadcast_1 locally took  1 ms
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7218] - Putting block broadcast_1 without replication took  2 ms
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7219] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:19:03  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7220] - Added broadcast_1_piece0 in memory on 172.18.10.41:50092 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7221] - Updated info of block broadcast_1_piece0
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7221] - Told master about block broadcast_1_piece0
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7221] - Put block broadcast_1_piece0 locally took  2 ms
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7221] - Putting block broadcast_1_piece0 without replication took  2 ms
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7221] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7222] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7222] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7222] - Adding task set 1.0 with 1 tasks
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7222] - Epoch for TaskSet 1.0: 0
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7222] - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:19:03  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7222] - parentName: , name: TaskSet_1, runningTasks: 0
[INFO ]2016-12-29 17:19:03  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7223] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5168 bytes)
[INFO ]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7223] - Running task 0.0 in stage 1.0 (TID 1)
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7225] - Task 1's epoch is 0
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7225] - Getting local block broadcast_1
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7225] - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7257] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7257] - closed connection
[INFO ]2016-12-29 17:19:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7259] - Finished task 0.0 in stage 1.0 (TID 1). 2526 bytes result sent to driver
[DEBUG]2016-12-29 17:19:03  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7260] - parentName: , name: TaskSet_1, runningTasks: 0
[DEBUG]2016-12-29 17:19:03  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7260] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:19:03  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7261] - Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on localhost (1/1)
[INFO ]2016-12-29 17:19:03  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7262] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7262] - ResultStage 1 (collect at RddServiceImpl.java:86) finished in 0.040 s
[DEBUG]2016-12-29 17:19:03  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7262] - After removal of stage 1, remaining stages = 0
[INFO ]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7262] - Job 1 finished: collect at RddServiceImpl.java:86, took 0.049790 s
[INFO ]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:95):7263] - 666
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.SenderServiceImpl.doSend(SenderServiceImpl.java:38):7290] - send to client：{"name":"唐亮","sex":"男"}
[DEBUG]2016-12-29 17:19:03  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):7293] - java.nio.ByteBuffer.cleaner(): available
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):57] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):65] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):65] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:232):66] - UgiMetrics, User and group related metrics
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.authentication.util.KerberosName.<clinit>(KerberosName.java:88):222] - Kerberos krb5 configuration not found, setting default realm to empty
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:301):224] -  Creating new Groups object
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:46):226] - Trying to load the custom-built native-hadoop library...
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:50):228] - Loaded the native-hadoop library
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:50):228] - Using JniBasedUnixGroupsMapping for Group resolution
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:45):229] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.Groups.<init>(Groups.java:112):279] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.login(UserGroupInformation.java:221):284] - hadoop login
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:156):285] - hadoop login commit
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:186):288] - using local user:NTUserPrincipal: pujjr
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:192):288] - Using user: "NTUserPrincipal: pujjr" with name pujjr
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:202):289] - User entry: "pujjr"
[DEBUG]2016-12-29 17:19:55  [main:org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:826):290] - UGI loginUser:pujjr (auth:SIMPLE)
[WARN ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):297] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):298] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):298] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):320] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):320] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):321] - Changing view acls groups to: 
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):322] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):323] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[DEBUG]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):332] - Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):414] - Using SLF4J as the default logging framework
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):419] - java.nio.Buffer.address: available
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):420] - sun.misc.Unsafe.theUnsafe: available
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):421] - sun.misc.Unsafe.copyMemory: available
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):421] - java.nio.Bits.unaligned: true
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):422] - Platform: Windows
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):423] - Java version: 8
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):423] - -Dio.netty.noUnsafe: false
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):423] - sun.misc.Unsafe: available
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):424] - -Dio.netty.noJavassist: false
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):510] - Javassist: available
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):510] - -Dio.netty.tmpdir: C:\Users\pujjr\AppData\Local\Temp (java.io.tmpdir)
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):511] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):511] - -Dio.netty.noPreferDirect: false
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):513] - Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):518] - Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):526] - -Dio.netty.eventLoopThreads: 8
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):539] - -Dio.netty.noKeySetOptimization: false
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):539] - -Dio.netty.selectorAutoRebuildThreshold: 512
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):568] - -Dio.netty.allocator.numHeapArenas: 8
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):568] - -Dio.netty.allocator.numDirectArenas: 8
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):568] - -Dio.netty.allocator.pageSize: 8192
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):568] - -Dio.netty.allocator.maxOrder: 11
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):568] - -Dio.netty.allocator.chunkSize: 16777216
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):568] - -Dio.netty.allocator.tinyCacheSize: 512
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.smallCacheSize: 256
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.normalCacheSize: 64
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.cacheTrimInterval: 8192
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):598] - -Dio.netty.initialSeedUniquifier: 0xec8acb46bdecc3c1 (took 5 ms)
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):618] - -Dio.netty.allocator.type: unpooled
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):619] - -Dio.netty.threadLocalDirectBufferSize: 65536
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:86):671] - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
[DEBUG]2016-12-29 17:19:55  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):671] - \proc\sys\net\core\somaxconn: 200 (non-existent)
[DEBUG]2016-12-29 17:19:55  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):680] - Shuffle server started on port :50133
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):684] - Successfully started service 'sparkDriver' on port 50133.
[DEBUG]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):685] - Using serializer: class org.apache.spark.serializer.JavaSerializer
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):704] - Registering MapOutputTracker
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):720] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):804] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-3a59cb04-2850-4146-a0ba-5c60a6dc62fd
[INFO ]2016-12-29 17:19:55  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):820] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):887] - Registering OutputCommitCoordinator
[DEBUG]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):908] - Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:176):965] - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):968] - Logging initialized @1463ms
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):979] - o.s.j.s.ServletContextHandler@665df3c6{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@68b6f0d6,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):982] - org.spark_project.jetty.servlet.ServletHandler@68b6f0d6 added {org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):983] - org.spark_project.jetty.servlet.ServletHandler@68b6f0d6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):984] - o.s.j.s.ServletContextHandler@29df4d43{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5dd91bca,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):985] - org.spark_project.jetty.servlet.ServletHandler@5dd91bca added {org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):986] - org.spark_project.jetty.servlet.ServletHandler@5dd91bca added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-40cb698e,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):987] - o.s.j.s.ServletContextHandler@a5bd950{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d18aa28,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):987] - org.spark_project.jetty.servlet.ServletHandler@4d18aa28 added {org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):988] - org.spark_project.jetty.servlet.ServletHandler@4d18aa28 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-75390459,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):988] - o.s.j.s.ServletContextHandler@7756c3cd{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2313052e,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):988] - org.spark_project.jetty.servlet.ServletHandler@2313052e added {org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):988] - org.spark_project.jetty.servlet.ServletHandler@2313052e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):988] - o.s.j.s.ServletContextHandler@57fd91c9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6cfcd46d,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - org.spark_project.jetty.servlet.ServletHandler@6cfcd46d added {org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - org.spark_project.jetty.servlet.ServletHandler@6cfcd46d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-52045dbe,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - o.s.j.s.ServletContextHandler@674658f7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5c8eee0f,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - org.spark_project.jetty.servlet.ServletHandler@5c8eee0f added {org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - org.spark_project.jetty.servlet.ServletHandler@5c8eee0f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-565b064f,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - o.s.j.s.ServletContextHandler@73163d48{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58c34bb3,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - org.spark_project.jetty.servlet.ServletHandler@58c34bb3 added {org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - org.spark_project.jetty.servlet.ServletHandler@58c34bb3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-56a4479a,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - o.s.j.s.ServletContextHandler@62163b39{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@20a8a64e,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - org.spark_project.jetty.servlet.ServletHandler@20a8a64e added {org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - org.spark_project.jetty.servlet.ServletHandler@20a8a64e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - o.s.j.s.ServletContextHandler@4504d271{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@207b8649,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - org.spark_project.jetty.servlet.ServletHandler@207b8649 added {org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - org.spark_project.jetty.servlet.ServletHandler@207b8649 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - o.s.j.s.ServletContextHandler@34997338{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@57eda880,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - org.spark_project.jetty.servlet.ServletHandler@57eda880 added {org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - org.spark_project.jetty.servlet.ServletHandler@57eda880 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):995] - o.s.j.s.ServletContextHandler@7e928e2f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@f667fe,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):995] - org.spark_project.jetty.servlet.ServletHandler@f667fe added {org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):996] - org.spark_project.jetty.servlet.ServletHandler@f667fe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-788fcafb,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):996] - o.s.j.s.ServletContextHandler@4febb875{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@25e2a451,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):996] - org.spark_project.jetty.servlet.ServletHandler@25e2a451 added {org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):996] - org.spark_project.jetty.servlet.ServletHandler@25e2a451 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-1698ee84,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - o.s.j.s.ServletContextHandler@2fc0cc3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@328cf0e1,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - org.spark_project.jetty.servlet.ServletHandler@328cf0e1 added {org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - org.spark_project.jetty.servlet.ServletHandler@328cf0e1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - o.s.j.s.ServletContextHandler@42e3ede4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@201b6b6f,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - org.spark_project.jetty.servlet.ServletHandler@201b6b6f added {org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):998] - org.spark_project.jetty.servlet.ServletHandler@201b6b6f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-75459c75,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):999] - o.s.j.s.ServletContextHandler@67ab1c47{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@b78a709,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - org.spark_project.jetty.servlet.ServletHandler@b78a709 added {org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - org.spark_project.jetty.servlet.ServletHandler@b78a709 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - o.s.j.s.ServletContextHandler@2a3c96e3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@15cafec7,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - org.spark_project.jetty.servlet.ServletHandler@15cafec7 added {org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - org.spark_project.jetty.servlet.ServletHandler@15cafec7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5b444398,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1003] - o.s.j.s.ServletContextHandler@1f2f9244{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4c4d27c8,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1003] - org.spark_project.jetty.servlet.ServletHandler@4c4d27c8 added {org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1004] - org.spark_project.jetty.servlet.ServletHandler@4c4d27c8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-6821ea29,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1004] - o.s.j.s.ServletContextHandler@338494fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@505a9d7c,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1004] - org.spark_project.jetty.servlet.ServletHandler@505a9d7c added {org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1004] - org.spark_project.jetty.servlet.ServletHandler@505a9d7c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-758c83d8,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1005] - o.s.j.s.ServletContextHandler@5af3a0f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@19ae6bb,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1005] - org.spark_project.jetty.servlet.ServletHandler@19ae6bb added {org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1005] - org.spark_project.jetty.servlet.ServletHandler@19ae6bb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-10993713,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1005] - o.s.j.s.ServletContextHandler@58359ebd{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@24b6b8f6,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1005] - org.spark_project.jetty.servlet.ServletHandler@24b6b8f6 added {org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1006] - org.spark_project.jetty.servlet.ServletHandler@24b6b8f6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1006] - o.s.j.s.ServletContextHandler@5f031ebd{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4ee37ca3,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1014] - org.spark_project.jetty.servlet.ServletHandler@4ee37ca3 added {org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1014] - org.spark_project.jetty.servlet.ServletHandler@4ee37ca3 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-662f5666,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1015] - o.s.j.s.ServletContextHandler@27305e6{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1ef3efa8,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1015] - org.spark_project.jetty.servlet.ServletHandler@1ef3efa8 added {org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1015] - org.spark_project.jetty.servlet.ServletHandler@1ef3efa8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1016] - o.s.j.s.ServletContextHandler@7446d8d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1019] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1019] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-dcfda20,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - o.s.j.s.ServletContextHandler@40499e4f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@51cd7ffc,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - org.spark_project.jetty.servlet.ServletHandler@51cd7ffc added {org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - org.spark_project.jetty.servlet.ServletHandler@51cd7ffc added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-30d4b288,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1043] - org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212 mime types IncludeExclude@1b065145{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@45cff11c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@207ea13}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1043] - org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212 added {o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1045] - org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903 mime types IncludeExclude@62dae540{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5827af16,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@654d8173}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1045] - org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903 added {o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1046] - org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8 mime types IncludeExclude@630cb4a4{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@636e8cc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@f79a760}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1046] - org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8 added {o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1046] - org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582 mime types IncludeExclude@239b0f9d{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@619bfe29,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b057c8c}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582 added {o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b mime types IncludeExclude@652a7737{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b7ea70d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2bef51f2}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b added {o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8 mime types IncludeExclude@30f5a68a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1e1d3956,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4f2c9ba6}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8 added {o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1048] - org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1 mime types IncludeExclude@53f48368{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@24d4d7c9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@f0e995e}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1048] - org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1 added {o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1049] - org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45 mime types IncludeExclude@a8c1f44{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@150ab4ed,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3c435123}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1049] - org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45 added {o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1049] - org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a mime types IncludeExclude@3a62c01e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7a8fa663,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5ce33a58}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1050] - org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a added {o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1050] - org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed mime types IncludeExclude@546ccad7{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5357c287,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1623134f}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1050] - org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed added {o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1050] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389 mime types IncludeExclude@485a3466{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@25748410,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2b43529a}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1050] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389 added {o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1051] - org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240 mime types IncludeExclude@5b04476e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5ad10c1a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6bb75258}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240 added {o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1054] - org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc mime types IncludeExclude@75e01201{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2783717b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@76f7d241}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc added {o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1054] - org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8 mime types IncludeExclude@3f363cf5{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3829ac1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4baf352a}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8 added {o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1055] - org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8 mime types IncludeExclude@15eebbff{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@22d6f11,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@30990c1b}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1055] - org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8 added {o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1056] - org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d mime types IncludeExclude@44828f6b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2dbe250d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@553f1d75}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1056] - org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d added {o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1059] - org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e mime types IncludeExclude@3e34ace1{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62fe6067,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4f071df8}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1060] - org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e added {o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1061] - org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9 mime types IncludeExclude@56ace400{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@47404bea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@305f7627}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1062] - org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9 added {o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1063] - org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107 mime types IncludeExclude@6cbcf243{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@29e6eb25,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62435e70}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1064] - org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107 added {o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1067] - org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286 mime types IncludeExclude@38be305c{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@269f4bad,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5ed731d0}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1068] - org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286 added {o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1069] - org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e mime types IncludeExclude@7bc10d84{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@275fe372,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@40e10ff8}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1069] - org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e added {o.s.j.s.ServletContextHandler@5f031ebd{/static,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1069] - org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d mime types IncludeExclude@26a4842b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7e38a7fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@366ef90e}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1070] - org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d added {o.s.j.s.ServletContextHandler@27305e6{/,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1070] - org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298 mime types IncludeExclude@31e75d13{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@a5b0b86,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4b3c354a}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1070] - org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298 added {o.s.j.s.ServletContextHandler@7446d8d5{/api,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1070] - org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67 mime types IncludeExclude@73ff4fae{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@21aa6d6c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@b968a76}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1071] - org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67 added {o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,null},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1079] - org.spark_project.jetty.server.Server@5b408dc3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1089] - HttpConnectionFactory@50eca7c6{HTTP/1.1} added {HttpConfiguration@58e6d4b8{32768/8192,8192/8192,https://:0,[]},POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1093] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@5b408dc3,UNMANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1094] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1094] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5ef0d29e,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1094] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@34a97744,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1094] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {HttpConnectionFactory@50eca7c6{HTTP/1.1},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1097] - ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@2cac4385,MANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1098] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1099] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1099] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1099] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582] added {org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1099] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b] added {org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1099] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1099] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1100] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45] added {org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1100] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a] added {org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1100] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed] added {org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1101] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1101] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1101] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc] added {org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1101] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e] added {org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286] added {org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e] added {org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1103] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1103] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298] added {org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1103] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67] added {org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1104] - org.spark_project.jetty.server.Server@5b408dc3 added {ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040},AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1105] - org.spark_project.jetty.server.Server@5b408dc3 added {org.spark_project.jetty.server.handler.ErrorHandler@4e517165,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1105] - org.spark_project.jetty.server.Server@5b408dc3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67],AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1106] - starting org.spark_project.jetty.server.Server@5b408dc3
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1108] - jetty-9.2.z-SNAPSHOT
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1117] - starting org.spark_project.jetty.server.Server@5b408dc3
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1118] - starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1118] - STARTED @1613ms SparkUI{STARTED,8<=8<=200,i=8,q=0}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1119] - starting org.spark_project.jetty.server.handler.ErrorHandler@4e517165
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1119] - starting org.spark_project.jetty.server.handler.ErrorHandler@4e517165
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1119] - STARTED @1614ms org.spark_project.jetty.server.handler.ErrorHandler@4e517165
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1119] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1120] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1120] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1120] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1120] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1120] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1121] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1122] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1123] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1123] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1123] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1123] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1123] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1123] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1123] - starting o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1124] - starting o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1124] - starting org.spark_project.jetty.servlet.ServletHandler@68b6f0d6
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1125] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1126] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1126] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1126] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1126] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1127] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4=org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1127] - starting org.spark_project.jetty.servlet.ServletHandler@68b6f0d6
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1127] - STARTED @1622ms org.spark_project.jetty.servlet.ServletHandler@68b6f0d6
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1127] - starting org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1128] - STARTED @1623ms org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1129] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3a94964 for org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1129] - Started o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1129] - STARTED @1624ms o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1130] - STARTED @1624ms org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1130] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1130] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1130] - starting o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1130] - starting o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1130] - starting org.spark_project.jetty.servlet.ServletHandler@5dd91bca
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1130] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-40cb698e from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1130] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1130] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1130] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1130] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1131] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-40cb698e=org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1131] - starting org.spark_project.jetty.servlet.ServletHandler@5dd91bca
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1131] - STARTED @1626ms org.spark_project.jetty.servlet.ServletHandler@5dd91bca
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1131] - starting org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1131] - STARTED @1626ms org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1131] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@6d0b5baf for org.apache.spark.ui.JettyUtils$$anon$2-40cb698e
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1131] - Started o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1131] - STARTED @1626ms o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1131] - STARTED @1626ms org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1132] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1132] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1132] - starting o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1132] - starting o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1132] - starting org.spark_project.jetty.servlet.ServletHandler@4d18aa28
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1132] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-75390459 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1132] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1132] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1132] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1133] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1133] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-75390459=org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1133] - starting org.spark_project.jetty.servlet.ServletHandler@4d18aa28
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1133] - STARTED @1628ms org.spark_project.jetty.servlet.ServletHandler@4d18aa28
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1133] - starting org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1133] - STARTED @1628ms org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1133] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@2a3591c5 for org.apache.spark.ui.JettyUtils$$anon$2-75390459
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1133] - Started o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1133] - STARTED @1628ms o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1134] - STARTED @1628ms org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1134] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1134] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1134] - starting o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1134] - starting o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1134] - starting org.spark_project.jetty.servlet.ServletHandler@2313052e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1134] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1134] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1134] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1134] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1135] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1135] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e=org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1135] - starting org.spark_project.jetty.servlet.ServletHandler@2313052e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1135] - STARTED @1630ms org.spark_project.jetty.servlet.ServletHandler@2313052e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1135] - starting org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1136] - STARTED @1630ms org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1136] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@107ed6fc for org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1136] - Started o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1136] - STARTED @1631ms o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1136] - STARTED @1631ms org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1136] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1136] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1136] - starting o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1136] - starting o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1136] - starting org.spark_project.jetty.servlet.ServletHandler@6cfcd46d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1136] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-52045dbe from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1136] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1137] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1137] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1137] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1137] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-52045dbe=org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1137] - starting org.spark_project.jetty.servlet.ServletHandler@6cfcd46d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1137] - STARTED @1632ms org.spark_project.jetty.servlet.ServletHandler@6cfcd46d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1137] - starting org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1137] - STARTED @1632ms org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1137] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@186978a6 for org.apache.spark.ui.JettyUtils$$anon$2-52045dbe
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1137] - Started o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1138] - STARTED @1632ms o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1138] - STARTED @1632ms org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1138] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1138] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1138] - starting o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1138] - starting o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1138] - starting org.spark_project.jetty.servlet.ServletHandler@5c8eee0f
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1138] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-565b064f from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1138] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1138] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1138] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1139] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1139] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-565b064f=org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1139] - starting org.spark_project.jetty.servlet.ServletHandler@5c8eee0f
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1139] - STARTED @1634ms org.spark_project.jetty.servlet.ServletHandler@5c8eee0f
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1139] - starting org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1139] - STARTED @1634ms org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1139] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@482d776b for org.apache.spark.ui.JettyUtils$$anon$2-565b064f
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1139] - Started o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1139] - STARTED @1634ms o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1139] - STARTED @1634ms org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1140] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1140] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1140] - starting o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1140] - starting o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1140] - starting org.spark_project.jetty.servlet.ServletHandler@58c34bb3
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1140] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-56a4479a from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1140] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1140] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1140] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1141] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1141] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-56a4479a=org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1141] - starting org.spark_project.jetty.servlet.ServletHandler@58c34bb3
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1141] - STARTED @1636ms org.spark_project.jetty.servlet.ServletHandler@58c34bb3
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1141] - starting org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1141] - STARTED @1636ms org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1141] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@132ddbab for org.apache.spark.ui.JettyUtils$$anon$2-56a4479a
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1141] - Started o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1141] - STARTED @1636ms o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1141] - STARTED @1636ms org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1141] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1142] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1142] - starting o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1142] - starting o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1142] - starting org.spark_project.jetty.servlet.ServletHandler@20a8a64e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1142] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1142] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1142] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1142] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1142] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1142] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b=org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1143] - starting org.spark_project.jetty.servlet.ServletHandler@20a8a64e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1143] - STARTED @1637ms org.spark_project.jetty.servlet.ServletHandler@20a8a64e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1143] - starting org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1143] - STARTED @1638ms org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1143] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@acb0951 for org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1143] - Started o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1143] - STARTED @1638ms o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1143] - STARTED @1638ms org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1143] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1143] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1143] - starting o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1144] - starting o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1144] - starting org.spark_project.jetty.servlet.ServletHandler@207b8649
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1144] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1144] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1144] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1144] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1144] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1144] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a=org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1144] - starting org.spark_project.jetty.servlet.ServletHandler@207b8649
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1144] - STARTED @1639ms org.spark_project.jetty.servlet.ServletHandler@207b8649
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1144] - starting org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1145] - STARTED @1639ms org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1145] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@267f474e for org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1145] - Started o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1145] - STARTED @1640ms o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1145] - STARTED @1640ms org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1145] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1145] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1145] - starting o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1145] - starting o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1145] - starting org.spark_project.jetty.servlet.ServletHandler@57eda880
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1145] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1146] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1146] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1146] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1146] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1146] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa=org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1146] - starting org.spark_project.jetty.servlet.ServletHandler@57eda880
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1146] - STARTED @1641ms org.spark_project.jetty.servlet.ServletHandler@57eda880
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1147] - starting org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1147] - STARTED @1642ms org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1147] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@28276e50 for org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1147] - Started o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1147] - STARTED @1642ms o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1147] - STARTED @1642ms org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1147] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1147] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1148] - starting o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1148] - starting o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1148] - starting org.spark_project.jetty.servlet.ServletHandler@f667fe
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1148] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-788fcafb from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1148] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1148] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1148] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1148] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1148] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-788fcafb=org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1149] - starting org.spark_project.jetty.servlet.ServletHandler@f667fe
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1149] - STARTED @1643ms org.spark_project.jetty.servlet.ServletHandler@f667fe
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1149] - starting org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1149] - STARTED @1644ms org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1149] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3efe7086 for org.apache.spark.ui.JettyUtils$$anon$2-788fcafb
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1149] - Started o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1150] - STARTED @1644ms o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1150] - STARTED @1644ms org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1150] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1150] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1150] - starting o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1150] - starting o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1150] - starting org.spark_project.jetty.servlet.ServletHandler@25e2a451
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1150] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-1698ee84 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1150] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1150] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1150] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1151] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1151] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-1698ee84=org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1151] - starting org.spark_project.jetty.servlet.ServletHandler@25e2a451
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1151] - STARTED @1646ms org.spark_project.jetty.servlet.ServletHandler@25e2a451
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1151] - starting org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1151] - STARTED @1646ms org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1151] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@741b3bc3 for org.apache.spark.ui.JettyUtils$$anon$2-1698ee84
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1151] - Started o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1151] - STARTED @1646ms o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1151] - STARTED @1646ms org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1152] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1152] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1152] - starting o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1152] - starting o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1152] - starting org.spark_project.jetty.servlet.ServletHandler@328cf0e1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1152] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1152] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1152] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1152] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1152] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1152] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa=org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1153] - starting org.spark_project.jetty.servlet.ServletHandler@328cf0e1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1153] - STARTED @1647ms org.spark_project.jetty.servlet.ServletHandler@328cf0e1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1153] - starting org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1153] - STARTED @1648ms org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1153] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@63648ee9 for org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1153] - Started o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1153] - STARTED @1648ms o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1153] - STARTED @1648ms org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1153] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1153] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1154] - starting o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1154] - starting o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1154] - starting org.spark_project.jetty.servlet.ServletHandler@201b6b6f
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1154] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-75459c75 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1154] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1154] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1154] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1154] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1154] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-75459c75=org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1154] - starting org.spark_project.jetty.servlet.ServletHandler@201b6b6f
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1154] - STARTED @1649ms org.spark_project.jetty.servlet.ServletHandler@201b6b6f
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1155] - starting org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1155] - STARTED @1649ms org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1155] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@45be7cd5 for org.apache.spark.ui.JettyUtils$$anon$2-75459c75
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1155] - Started o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1155] - STARTED @1650ms o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1155] - STARTED @1650ms org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1155] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1155] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1155] - starting o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1159] - starting o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1159] - starting org.spark_project.jetty.servlet.ServletHandler@b78a709
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1159] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1159] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1159] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1160] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1160] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1160] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1=org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1160] - starting org.spark_project.jetty.servlet.ServletHandler@b78a709
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1160] - STARTED @1655ms org.spark_project.jetty.servlet.ServletHandler@b78a709
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1161] - starting org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1161] - STARTED @1656ms org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1162] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3185fa6b for org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1162] - Started o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1657ms o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1657ms org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1162] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1162] - starting o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting org.spark_project.jetty.servlet.ServletHandler@15cafec7
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1163] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5b444398 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1163] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1163] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1163] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1164] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1164] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5b444398=org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1164] - starting org.spark_project.jetty.servlet.ServletHandler@15cafec7
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1164] - STARTED @1659ms org.spark_project.jetty.servlet.ServletHandler@15cafec7
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1164] - starting org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1164] - STARTED @1659ms org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1164] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5b58ed3c for org.apache.spark.ui.JettyUtils$$anon$2-5b444398
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1164] - Started o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1164] - STARTED @1659ms o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1165] - STARTED @1659ms org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1165] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1165] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1165] - starting o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1165] - starting o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1165] - starting org.spark_project.jetty.servlet.ServletHandler@4c4d27c8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1165] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-6821ea29 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1165] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1165] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1165] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1165] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1166] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-6821ea29=org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1166] - starting org.spark_project.jetty.servlet.ServletHandler@4c4d27c8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1166] - STARTED @1661ms org.spark_project.jetty.servlet.ServletHandler@4c4d27c8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1166] - starting org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1166] - STARTED @1661ms org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1166] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3a320ade for org.apache.spark.ui.JettyUtils$$anon$2-6821ea29
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1166] - Started o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1166] - STARTED @1661ms o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1166] - STARTED @1661ms org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1166] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1166] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1167] - starting o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting org.spark_project.jetty.servlet.ServletHandler@505a9d7c
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1167] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-758c83d8 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1167] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1171] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1171] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1172] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1172] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-758c83d8=org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1172] - starting org.spark_project.jetty.servlet.ServletHandler@505a9d7c
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1667ms org.spark_project.jetty.servlet.ServletHandler@505a9d7c
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1172] - starting org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1667ms org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1172] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7813cb11 for org.apache.spark.ui.JettyUtils$$anon$2-758c83d8
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1173] - Started o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1173] - STARTED @1667ms o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1173] - STARTED @1668ms org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1173] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1173] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1173] - starting o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1173] - starting o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1173] - starting org.spark_project.jetty.servlet.ServletHandler@19ae6bb
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1173] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-10993713 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1173] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1174] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1174] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1174] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1174] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-10993713=org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1174] - starting org.spark_project.jetty.servlet.ServletHandler@19ae6bb
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1669ms org.spark_project.jetty.servlet.ServletHandler@19ae6bb
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1174] - starting org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1669ms org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1174] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@21005f6c for org.apache.spark.ui.JettyUtils$$anon$2-10993713
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1174] - Started o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1175] - STARTED @1669ms o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1175] - STARTED @1669ms org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1175] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1175] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1175] - starting o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1175] - starting o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1175] - starting org.spark_project.jetty.servlet.ServletHandler@24b6b8f6
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1175] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1175] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1175] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1175] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1176] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1176] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5=org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1176] - starting org.spark_project.jetty.servlet.ServletHandler@24b6b8f6
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1671ms org.spark_project.jetty.servlet.ServletHandler@24b6b8f6
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1176] - starting org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1671ms org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1176] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@545de5a4 for org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1176] - Started o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1671ms o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1671ms org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1176] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1176] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1177] - starting o.s.j.s.ServletContextHandler@5f031ebd{/static,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1177] - starting o.s.j.s.ServletContextHandler@5f031ebd{/static,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1177] - starting org.spark_project.jetty.servlet.ServletHandler@4ee37ca3
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1177] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-662f5666 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1177] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1177] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1178] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1178] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1178] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-662f5666=org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1178] - starting org.spark_project.jetty.servlet.ServletHandler@4ee37ca3
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1673ms org.spark_project.jetty.servlet.ServletHandler@4ee37ca3
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1178] - starting org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1673ms org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1179] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@ab7a938 for org.spark_project.jetty.servlet.DefaultServlet-662f5666
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1185] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-core_2.11-2.0.0.jar!/org/apache/spark/ui/static
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1186] - Started o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1186] - STARTED @1680ms o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1186] - STARTED @1681ms org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1186] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1186] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1186] - starting o.s.j.s.ServletContextHandler@27305e6{/,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1186] - starting o.s.j.s.ServletContextHandler@27305e6{/,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1186] - starting org.spark_project.jetty.servlet.ServletHandler@1ef3efa8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1186] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1187] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1187] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1187] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1188] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1188] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c=org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1188] - starting org.spark_project.jetty.servlet.ServletHandler@1ef3efa8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1683ms org.spark_project.jetty.servlet.ServletHandler@1ef3efa8
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1188] - starting org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1683ms org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1188] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@68759011 for org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1189] - Started o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1189] - STARTED @1683ms o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1189] - STARTED @1684ms org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1189] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting o.s.j.s.ServletContextHandler@7446d8d5{/api,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1189] - starting o.s.j.s.ServletContextHandler@7446d8d5{/api,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1189] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-dcfda20 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1189] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1189] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1189] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1190] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1190] - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-dcfda20=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.doStart(ServletHandler.java:165):1190] - Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1191] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1191] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1191] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-dcfda20 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1191] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1191] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1191] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1191] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1191] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1191] - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-dcfda20=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1192] - starting org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1686ms org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1192] - starting org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1687ms org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1192] - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1687ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1192] - Started o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1687ms o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1193] - STARTED @1687ms org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1193] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1193] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1193] - starting o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1193] - starting o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1193] - starting org.spark_project.jetty.servlet.ServletHandler@51cd7ffc
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1193] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-30d4b288 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1193] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1193] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1193] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1193] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1194] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-30d4b288=org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1194] - starting org.spark_project.jetty.servlet.ServletHandler@51cd7ffc
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1194] - STARTED @1689ms org.spark_project.jetty.servlet.ServletHandler@51cd7ffc
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1195] - starting org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1689ms org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1195] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@43b4fe19 for org.apache.spark.ui.JettyUtils$$anon$3-30d4b288
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1195] - Started o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1690ms o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1690ms org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1690ms org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1195] - starting ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1196] - ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1196] - starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5ef0d29e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1197] - STARTED @1692ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5ef0d29e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1197] - starting HttpConnectionFactory@50eca7c6{HTTP/1.1}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1197] - STARTED @1692ms HttpConnectionFactory@50eca7c6{HTTP/1.1}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1197] - starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@2cac4385
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1201] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@2c1b9e4b keys=-1 selected=-1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1202] - STARTED @1697ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@2c1b9e4b keys=0 selected=0
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1203] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@3c0fae6c keys=-1 selected=-1
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1204] - STARTED @1699ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@3c0fae6c keys=0 selected=0
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1205] - STARTED @1699ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@2cac4385
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1208] - ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040} added {acceptor-0@fd0e5b6,POJO}
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1208] - Started ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1208] - STARTED @1703ms ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1208] - Started @1703ms
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1208] - STARTED @1703ms org.spark_project.jetty.server.Server@5b408dc3
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1209] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1211] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[DEBUG]2016-12-29 17:19:56  [SparkUI-35-selector-ServerConnectorManager@2cac4385/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1237] - Starting Thread[SparkUI-35-selector-ServerConnectorManager@2cac4385/0,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@2c1b9e4b keys=0 selected=0
[DEBUG]2016-12-29 17:19:56  [SparkUI-35-selector-ServerConnectorManager@2cac4385/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1238] - Selector loop waiting on select
[DEBUG]2016-12-29 17:19:56  [SparkUI-37-selector-ServerConnectorManager@2cac4385/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1237] - Starting Thread[SparkUI-37-selector-ServerConnectorManager@2cac4385/1,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@3c0fae6c keys=0 selected=0
[DEBUG]2016-12-29 17:19:56  [SparkUI-37-selector-ServerConnectorManager@2cac4385/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1238] - Selector loop waiting on select
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1305] - Starting executor ID driver on host localhost
[DEBUG]2016-12-29 17:19:56  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):1330] - Shuffle server started on port :50142
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1330] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50142.
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1331] - Server created on 172.18.10.41:50142
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1332] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 50142)
[INFO ]2016-12-29 17:19:56  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1334] - Registering block manager 172.18.10.41:50142 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 50142)
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1338] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 50142)
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1452] - o.s.j.s.ServletContextHandler@2899a8db{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1e8823d2,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1452] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1452] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-c1a4620,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1454] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}] added {o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1454] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1454] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1454] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1454] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1455] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1455] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1455] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1456] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1456] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1457] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1458] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1458] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1458] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1458] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1458] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1458] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1459] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1459] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1459] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1459] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1459] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1460] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1460] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1460] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1460] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1460] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-c1a4620=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1460] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1460] - STARTED @1955ms org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1460] - starting org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1460] - STARTED @1955ms org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1460] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5710768a for org.apache.spark.ui.JettyUtils$$anon$2-c1a4620
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1461] - Started o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1461] - STARTED @1955ms o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1485] - Use an existing SparkContext, some configuration may not take effect.
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1516] - o.s.j.s.ServletContextHandler@6034e75d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@15fc442,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1517] - org.spark_project.jetty.servlet.ServletHandler@15fc442 added {org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1517] - org.spark_project.jetty.servlet.ServletHandler@15fc442 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1517] - o.s.j.s.ServletContextHandler@456abb66{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2a3a299,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1517] - org.spark_project.jetty.servlet.ServletHandler@2a3a299 added {org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1518] - org.spark_project.jetty.servlet.ServletHandler@2a3a299 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1518] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null}] added {o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1518] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1519] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1523] - starting o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1523] - starting o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1523] - starting org.spark_project.jetty.servlet.ServletHandler@15fc442
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1523] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1523] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1523] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1523] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1524] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1524] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb=org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1524] - starting org.spark_project.jetty.servlet.ServletHandler@15fc442
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1524] - STARTED @2019ms org.spark_project.jetty.servlet.ServletHandler@15fc442
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1524] - starting org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1524] - STARTED @2019ms org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb@aed10479==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1524] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@31be6b49 for org.apache.spark.ui.JettyUtils$$anon$2-3f3c7bdb
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1524] - Started o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1524] - STARTED @2019ms o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1525] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null}] added {o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1527] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1528] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1528] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1529] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1530] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1530] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1530] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1533] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1533] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1533] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1533] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1533] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1534] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1535] - starting o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1535] - starting o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1535] - starting org.spark_project.jetty.servlet.ServletHandler@2a3a299
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1535] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1535] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1535] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1535] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1535] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1536] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b=org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1536] - starting org.spark_project.jetty.servlet.ServletHandler@2a3a299
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1536] - STARTED @2031ms org.spark_project.jetty.servlet.ServletHandler@2a3a299
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1536] - starting org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1536] - STARTED @2031ms org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b@30446289==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1536] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5b989dc7 for org.apache.spark.ui.JettyUtils$$anon$2-7da10b5b
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1536] - Started o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1537] - STARTED @2031ms o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1537] - o.s.j.s.ServletContextHandler@42561fba{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@595f4da5,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1537] - org.spark_project.jetty.servlet.ServletHandler@595f4da5 added {org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1537] - org.spark_project.jetty.servlet.ServletHandler@595f4da5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-46b695ec,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1537] - o.s.j.s.ServletContextHandler@408613cc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@325f7fa9,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1537] - org.spark_project.jetty.servlet.ServletHandler@325f7fa9 added {org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1537] - org.spark_project.jetty.servlet.ServletHandler@325f7fa9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1538] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null}] added {o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1538] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1539] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1540] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1541] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1541] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1541] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1541] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1541] - SQL/execution->[{o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null},[o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1541] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1541] - starting o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1541] - starting o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1541] - starting org.spark_project.jetty.servlet.ServletHandler@595f4da5
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1541] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-46b695ec from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1541] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1542] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1542] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1542] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1542] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-46b695ec=org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1542] - starting org.spark_project.jetty.servlet.ServletHandler@595f4da5
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1542] - STARTED @2037ms org.spark_project.jetty.servlet.ServletHandler@595f4da5
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1542] - starting org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1542] - STARTED @2037ms org.apache.spark.ui.JettyUtils$$anon$2-46b695ec@7940f89d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1542] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@13cda7c9 for org.apache.spark.ui.JettyUtils$$anon$2-46b695ec
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1542] - Started o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1543] - STARTED @2037ms o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1543] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null}] added {o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1543] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null},[o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1544] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1545] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - SQL/execution->[{o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1546] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1546] - starting o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1547] - starting o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1547] - starting org.spark_project.jetty.servlet.ServletHandler@325f7fa9
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1547] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1547] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1547] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1547] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1547] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1547] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22=org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1547] - starting org.spark_project.jetty.servlet.ServletHandler@325f7fa9
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1548] - STARTED @2042ms org.spark_project.jetty.servlet.ServletHandler@325f7fa9
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1548] - starting org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1548] - STARTED @2043ms org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22@3d66f242==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1548] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3af9aa66 for org.apache.spark.ui.JettyUtils$$anon$2-11ce2e22
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1548] - Started o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1548] - STARTED @2043ms o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1549] - o.s.j.s.ServletContextHandler@150d80c4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6826c41e,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1549] - org.spark_project.jetty.servlet.ServletHandler@6826c41e added {org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1549] - org.spark_project.jetty.servlet.ServletHandler@6826c41e added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-3003697,POJO}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1549] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null}] added {o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@408613cc{/SQL/execution/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - SQL->[{o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@6034e75d{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - static/sql->[{o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null},[o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - SQL/json->[{o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@456abb66{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - SQL/execution->[{o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@42561fba{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1554] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1554] - starting o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,null}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1554] - starting o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,STARTING}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1555] - starting org.spark_project.jetty.servlet.ServletHandler@6826c41e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1555] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-3003697 from default=false
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1555] - filterNameMap={}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1555] - pathFilters=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1555] - servletFilterMap=null
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1555] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1555] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-3003697=org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1555] - starting org.spark_project.jetty.servlet.ServletHandler@6826c41e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1555] - STARTED @2050ms org.spark_project.jetty.servlet.ServletHandler@6826c41e
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1555] - starting org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1556] - STARTED @2050ms org.spark_project.jetty.servlet.DefaultServlet-3003697@9519d2c5==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1556] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@1d269ed7 for org.spark_project.jetty.servlet.DefaultServlet-3003697
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1556] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-sql_2.11-2.0.0.jar!/org/apache/spark/sql/execution/ui/static
[INFO ]2016-12-29 17:19:56  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1556] - Started o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,AVAILABLE}
[DEBUG]2016-12-29 17:19:56  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1556] - STARTED @2051ms o.s.j.s.ServletContextHandler@150d80c4{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:19:56  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1566] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:19:56  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1578] - 服务启动成功，监听端口：10080
[DEBUG]2016-12-29 17:20:02  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):6924] - -Dio.netty.leakDetectionLevel: simple
[DEBUG]2016-12-29 17:20:02  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):6935] - -Dio.netty.recycler.maxCapacity.default: 262144
[DEBUG]2016-12-29 17:20:02  [nioEventLoopGroup-3-1:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):6943] - uri:/antifraud
[INFO ]2016-12-29 17:20:02  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):6946] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:20:02  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):6995] - Rdd服务
[DEBUG]2016-12-29 17:20:03  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8844] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#6: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#6: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#0, name#1, sex#2]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#0, name#1, sex#2]
        
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8867] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#7: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#7: org.apache.spark.sql.Row
 +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9195] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9257] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[INFO ]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9376] - Code generated in 156.574304 ms
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9382] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9399] -  + declared fields: 4
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9400] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9401] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9401] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9401] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9401] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9402] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9402] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9403] -  + inner classes: 1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9404] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9404] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9405] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9407] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9413] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9414] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9415] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9440] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9442] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9442] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9442] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9442] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9442] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9442] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9442] -  + inner classes: 1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9443] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9443] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9443] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9443] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9444] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9444] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9444] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9455] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9456] -  + declared fields: 1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9456] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9456] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9456] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9456] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9456] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9457] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9457] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9457] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9458] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9458] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9458] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9459] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9483] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9483] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9484] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9484] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9484] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9484] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9484] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9484] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9484] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9485] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9485] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9485] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9485] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:20:04  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9487] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9501] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9502] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9502] - Parents of final stage: List()
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9504] - Missing parents: List()
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9506] - submitStage(ResultStage 0)
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9507] - missing: List()
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9509] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9509] - submitMissingTasks(ResultStage 0)
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9613] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9615] - Put block broadcast_0 locally took  52 ms
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9616] - Putting block broadcast_0 without replication took  53 ms
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9640] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:20:04  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9642] - Added broadcast_0_piece0 in memory on 172.18.10.41:50142 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9642] - Updated info of block broadcast_0_piece0
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9643] - Told master about block broadcast_0_piece0
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9644] - Put block broadcast_0_piece0 locally took  6 ms
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9644] - Putting block broadcast_0_piece0 without replication took  6 ms
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9645] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9648] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9649] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9650] - Adding task set 0.0 with 1 tasks
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9654] - Epoch for TaskSet 0.0: 0
[DEBUG]2016-12-29 17:20:04  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9656] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:20:04  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9665] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:20:04  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9665] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[INFO ]2016-12-29 17:20:04  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9685] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9691] - Running task 0.0 in stage 0.0 (TID 0)
[DEBUG]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9701] - Task 0's epoch is 0
[DEBUG]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9704] - Getting local block broadcast_0
[DEBUG]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9705] - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9746] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[DEBUG]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9755] - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9771] - Code generated in 24.024548 ms
[INFO ]2016-12-29 17:20:04  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9776] - closed connection
[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9885] - Finished task 0.0 in stage 0.0 (TID 0). 1254 bytes result sent to driver
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9887] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9888] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:20:05  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9891] - Finished task 0.0 in stage 0.0 (TID 0) in 221 ms on localhost (1/1)
[INFO ]2016-12-29 17:20:05  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9891] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9894] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.235 s
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9897] - After removal of stage 0, remaining stages = 0
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9898] - Job 0 finished: count at RddServiceImpl.java:85, took 0.411271 s
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9900] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9901] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9901] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9901] -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9901] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9901] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9902] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9902] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9902] -  + outer classes: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9902] -      org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9902] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9902] -  + outer objects: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9903] -      <function0>
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9903] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9903] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9904] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9905] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9905] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9906] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9906] -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9907] -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9908] - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9908] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -  + inner classes: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -  + outer classes: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -  + outer objects: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9909] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9910] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9910] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9910] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9910] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9910] -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9910] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9913] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9913] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9914] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9915] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9915] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9915] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9916] - Starting job: collect at RddServiceImpl.java:86
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9919] - Got job 1 (collect at RddServiceImpl.java:86) with 1 output partitions
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9919] - Final stage: ResultStage 1 (collect at RddServiceImpl.java:86)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9919] - Parents of final stage: List()
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9920] - Missing parents: List()
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9920] - submitStage(ResultStage 1)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9920] - missing: List()
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9920] - Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9920] - submitMissingTasks(ResultStage 1)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9926] - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9928] - Put block broadcast_1 locally took  3 ms
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9928] - Putting block broadcast_1 without replication took  3 ms
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9929] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:20:05  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9934] - Added broadcast_1_piece0 in memory on 172.18.10.41:50142 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9934] - Updated info of block broadcast_1_piece0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9934] - Told master about block broadcast_1_piece0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9934] - Put block broadcast_1_piece0 locally took  5 ms
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9934] - Putting block broadcast_1_piece0 without replication took  5 ms
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9935] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9935] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9935] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9935] - Adding task set 1.0 with 1 tasks
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9935] - Epoch for TaskSet 1.0: 0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9935] - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9936] - parentName: , name: TaskSet_1, runningTasks: 0
[INFO ]2016-12-29 17:20:05  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9936] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5168 bytes)
[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9937] - Running task 0.0 in stage 1.0 (TID 1)
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9939] - Task 1's epoch is 0
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9939] - Getting local block broadcast_1
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9939] - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9952] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9953] - closed connection
[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9955] - Finished task 0.0 in stage 1.0 (TID 1). 2526 bytes result sent to driver
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9956] - parentName: , name: TaskSet_1, runningTasks: 0
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9956] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:20:05  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9957] - Finished task 0.0 in stage 1.0 (TID 1) in 21 ms on localhost (1/1)
[INFO ]2016-12-29 17:20:05  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9958] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9958] - ResultStage 1 (collect at RddServiceImpl.java:86) finished in 0.023 s
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9958] - After removal of stage 1, remaining stages = 0
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):9958] - Job 1 finished: collect at RddServiceImpl.java:86, took 0.041934 s
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9960] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9961] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9962] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9962] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9962] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9962] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):9971] - uri:/antifraud
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):9972] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):9972] - Rdd服务
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9987] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#14: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#14: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#8, name#9, sex#10]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#8, name#9, sex#10]
        
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9991] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#15: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#15: org.apache.spark.sql.Row
 +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9997] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9997] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9999] -  + declared fields: 4
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):9999] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -  + inner classes: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10000] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10001] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10002] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10002] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10003] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10004] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10005] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -  + inner classes: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10006] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10007] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10007] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10007] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10008] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -  + declared fields: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10009] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10010] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10010] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10010] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10010] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10011] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10012] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10012] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10012] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10012] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10013] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10013] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10013] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10013] - Got job 2 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10014] - Final stage: ResultStage 2 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10014] - Parents of final stage: List()
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10014] - Missing parents: List()
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10014] - submitStage(ResultStage 2)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10014] - missing: List()
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10014] - Submitting ResultStage 2 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10014] - submitMissingTasks(ResultStage 2)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10017] - Block broadcast_2 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10018] - Put block broadcast_2 locally took  1 ms
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10018] - Putting block broadcast_2 without replication took  1 ms
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10019] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:20:05  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10020] - Added broadcast_2_piece0 in memory on 172.18.10.41:50142 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10021] - Updated info of block broadcast_2_piece0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10021] - Told master about block broadcast_2_piece0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10021] - Put block broadcast_2_piece0 locally took  2 ms
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10021] - Putting block broadcast_2_piece0 without replication took  2 ms
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10021] - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10022] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10022] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10022] - Adding task set 2.0 with 1 tasks
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10022] - Epoch for TaskSet 2.0: 0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10022] - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10023] - parentName: , name: TaskSet_2, runningTasks: 0
[INFO ]2016-12-29 17:20:05  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10023] - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10024] - Running task 0.0 in stage 2.0 (TID 2)
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10025] - Task 2's epoch is 0
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10025] - Getting local block broadcast_2
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10025] - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10042] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10043] - closed connection
[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10044] - Finished task 0.0 in stage 2.0 (TID 2). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10046] - parentName: , name: TaskSet_2, runningTasks: 0
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10047] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:20:05  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10047] - Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on localhost (1/1)
[INFO ]2016-12-29 17:20:05  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10047] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10048] - ResultStage 2 (count at RddServiceImpl.java:85) finished in 0.026 s
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10048] - After removal of stage 2, remaining stages = 0
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10048] - Job 2 finished: count at RddServiceImpl.java:85, took 0.035489 s
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10050] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10050] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10050] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10050] -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -  + outer classes: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -      org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -  + outer objects: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -      <function0>
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10051] -      MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10052] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10052] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10053] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10053] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10053] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10053] -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10053] -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10053] - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10054] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10054] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10054] -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -  + inner classes: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -  + outer classes: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -  + outer objects: 1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10055] -      MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10056] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10056] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10056] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10056] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10056] -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10056] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10057] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10057] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10058] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10059] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10059] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10059] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10059] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10060] - Starting job: collect at RddServiceImpl.java:86
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10060] - Got job 3 (collect at RddServiceImpl.java:86) with 1 output partitions
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10060] - Final stage: ResultStage 3 (collect at RddServiceImpl.java:86)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10060] - Parents of final stage: List()
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10061] - Missing parents: List()
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10061] - submitStage(ResultStage 3)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10061] - missing: List()
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10061] - Submitting ResultStage 3 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10061] - submitMissingTasks(ResultStage 3)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10065] - Block broadcast_3 stored as values in memory (estimated size 11.3 KB, free 905.9 MB)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10069] - Put block broadcast_3 locally took  5 ms
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10069] - Putting block broadcast_3 without replication took  5 ms
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10072] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KB, free 905.9 MB)
[INFO ]2016-12-29 17:20:05  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10072] - Added broadcast_3_piece0 in memory on 172.18.10.41:50142 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10073] - Updated info of block broadcast_3_piece0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10073] - Told master about block broadcast_3_piece0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10073] - Put block broadcast_3_piece0 locally took  2 ms
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10074] - Putting block broadcast_3_piece0 without replication took  3 ms
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10075] - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10075] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10076] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10076] - Adding task set 3.0 with 1 tasks
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10076] - Epoch for TaskSet 3.0: 0
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10076] - Valid locality levels for TaskSet 3.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10076] - parentName: , name: TaskSet_3, runningTasks: 0
[INFO ]2016-12-29 17:20:05  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10078] - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5169 bytes)
[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10078] - Running task 0.0 in stage 3.0 (TID 3)
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10079] - Task 3's epoch is 0
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10079] - Getting local block broadcast_3
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10079] - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10093] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10093] - closed connection
[INFO ]2016-12-29 17:20:05  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10094] - Finished task 0.0 in stage 3.0 (TID 3). 2439 bytes result sent to driver
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10095] - parentName: , name: TaskSet_3, runningTasks: 0
[DEBUG]2016-12-29 17:20:05  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10096] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:20:05  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10097] - Finished task 0.0 in stage 3.0 (TID 3) in 21 ms on localhost (1/1)
[INFO ]2016-12-29 17:20:05  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10097] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10097] - ResultStage 3 (collect at RddServiceImpl.java:86) finished in 0.021 s
[DEBUG]2016-12-29 17:20:05  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10097] - After removal of stage 3, remaining stages = 0
[INFO ]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):10098] - Job 3 finished: collect at RddServiceImpl.java:86, took 0.037822 s
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10098] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -  + declared fields: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -  + declared methods: 2
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -  + inner classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -  + outer classes: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -  + outer objects: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10099] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10100] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10100] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:20:05  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):10100] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[INFO ]2016-12-29 17:23:05  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[DEBUG]2016-12-29 17:23:05  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):61] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:23:05  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):69] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:23:05  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):70] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
[DEBUG]2016-12-29 17:23:05  [main:org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:232):71] - UgiMetrics, User and group related metrics
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.authentication.util.KerberosName.<clinit>(KerberosName.java:88):230] - Kerberos krb5 configuration not found, setting default realm to empty
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:301):232] -  Creating new Groups object
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:46):234] - Trying to load the custom-built native-hadoop library...
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:50):236] - Loaded the native-hadoop library
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:50):237] - Using JniBasedUnixGroupsMapping for Group resolution
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:45):237] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.Groups.<init>(Groups.java:112):294] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.login(UserGroupInformation.java:221):300] - hadoop login
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:156):301] - hadoop login commit
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:186):305] - using local user:NTUserPrincipal: pujjr
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:192):305] - Using user: "NTUserPrincipal: pujjr" with name pujjr
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:202):307] - User entry: "pujjr"
[DEBUG]2016-12-29 17:23:06  [main:org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:826):307] - UGI loginUser:pujjr (auth:SIMPLE)
[WARN ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):317] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):319] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):319] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):344] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):344] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):345] - Changing view acls groups to: 
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):345] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):346] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[DEBUG]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):356] - Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):429] - Using SLF4J as the default logging framework
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):432] - java.nio.Buffer.address: available
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):432] - sun.misc.Unsafe.theUnsafe: available
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):433] - sun.misc.Unsafe.copyMemory: available
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):433] - java.nio.Bits.unaligned: true
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):434] - Platform: Windows
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):435] - Java version: 8
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):435] - -Dio.netty.noUnsafe: false
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):435] - sun.misc.Unsafe: available
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):435] - -Dio.netty.noJavassist: false
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):512] - Javassist: available
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):512] - -Dio.netty.tmpdir: C:\Users\pujjr\AppData\Local\Temp (java.io.tmpdir)
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):512] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):512] - -Dio.netty.noPreferDirect: false
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):514] - Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):517] - Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):524] - -Dio.netty.eventLoopThreads: 8
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):539] - -Dio.netty.noKeySetOptimization: false
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):539] - -Dio.netty.selectorAutoRebuildThreshold: 512
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.numHeapArenas: 8
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.numDirectArenas: 8
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.pageSize: 8192
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.maxOrder: 11
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):569] - -Dio.netty.allocator.chunkSize: 16777216
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):570] - -Dio.netty.allocator.tinyCacheSize: 512
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):570] - -Dio.netty.allocator.smallCacheSize: 256
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):570] - -Dio.netty.allocator.normalCacheSize: 64
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):570] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):570] - -Dio.netty.allocator.cacheTrimInterval: 8192
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):599] - -Dio.netty.initialSeedUniquifier: 0xd4bb8c398cd236f2 (took 5 ms)
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):622] - -Dio.netty.allocator.type: unpooled
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):622] - -Dio.netty.threadLocalDirectBufferSize: 65536
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:86):676] - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
[DEBUG]2016-12-29 17:23:06  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):677] - \proc\sys\net\core\somaxconn: 200 (non-existent)
[DEBUG]2016-12-29 17:23:06  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):686] - Shuffle server started on port :50189
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):690] - Successfully started service 'sparkDriver' on port 50189.
[DEBUG]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):691] - Using serializer: class org.apache.spark.serializer.JavaSerializer
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):706] - Registering MapOutputTracker
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):734] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):821] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-b44062dc-49d6-4bd2-a730-e5e31f0f6794
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):837] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):904] - Registering OutputCommitCoordinator
[DEBUG]2016-12-29 17:23:06  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):914] - Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:176):969] - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
[INFO ]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):971] - Logging initialized @1484ms
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):981] - o.s.j.s.ServletContextHandler@665df3c6{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@68b6f0d6,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):984] - org.spark_project.jetty.servlet.ServletHandler@68b6f0d6 added {org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):985] - org.spark_project.jetty.servlet.ServletHandler@68b6f0d6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):986] - o.s.j.s.ServletContextHandler@29df4d43{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5dd91bca,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):987] - org.spark_project.jetty.servlet.ServletHandler@5dd91bca added {org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):987] - org.spark_project.jetty.servlet.ServletHandler@5dd91bca added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-40cb698e,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - o.s.j.s.ServletContextHandler@a5bd950{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d18aa28,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - org.spark_project.jetty.servlet.ServletHandler@4d18aa28 added {org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - org.spark_project.jetty.servlet.ServletHandler@4d18aa28 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-75390459,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):989] - o.s.j.s.ServletContextHandler@7756c3cd{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2313052e,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - org.spark_project.jetty.servlet.ServletHandler@2313052e added {org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - org.spark_project.jetty.servlet.ServletHandler@2313052e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - o.s.j.s.ServletContextHandler@57fd91c9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6cfcd46d,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):990] - org.spark_project.jetty.servlet.ServletHandler@6cfcd46d added {org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - org.spark_project.jetty.servlet.ServletHandler@6cfcd46d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-52045dbe,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - o.s.j.s.ServletContextHandler@674658f7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5c8eee0f,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - org.spark_project.jetty.servlet.ServletHandler@5c8eee0f added {org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - org.spark_project.jetty.servlet.ServletHandler@5c8eee0f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-565b064f,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):991] - o.s.j.s.ServletContextHandler@73163d48{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58c34bb3,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - org.spark_project.jetty.servlet.ServletHandler@58c34bb3 added {org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - org.spark_project.jetty.servlet.ServletHandler@58c34bb3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-56a4479a,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - o.s.j.s.ServletContextHandler@62163b39{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@20a8a64e,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - org.spark_project.jetty.servlet.ServletHandler@20a8a64e added {org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):992] - org.spark_project.jetty.servlet.ServletHandler@20a8a64e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):993] - o.s.j.s.ServletContextHandler@4504d271{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@207b8649,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):993] - org.spark_project.jetty.servlet.ServletHandler@207b8649 added {org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):993] - org.spark_project.jetty.servlet.ServletHandler@207b8649 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):993] - o.s.j.s.ServletContextHandler@34997338{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@57eda880,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):994] - org.spark_project.jetty.servlet.ServletHandler@57eda880 added {org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):994] - org.spark_project.jetty.servlet.ServletHandler@57eda880 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - o.s.j.s.ServletContextHandler@7e928e2f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@f667fe,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - org.spark_project.jetty.servlet.ServletHandler@f667fe added {org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - org.spark_project.jetty.servlet.ServletHandler@f667fe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-788fcafb,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):997] - o.s.j.s.ServletContextHandler@4febb875{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@25e2a451,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):998] - org.spark_project.jetty.servlet.ServletHandler@25e2a451 added {org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):998] - org.spark_project.jetty.servlet.ServletHandler@25e2a451 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-1698ee84,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):998] - o.s.j.s.ServletContextHandler@2fc0cc3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@328cf0e1,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):998] - org.spark_project.jetty.servlet.ServletHandler@328cf0e1 added {org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):998] - org.spark_project.jetty.servlet.ServletHandler@328cf0e1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):999] - o.s.j.s.ServletContextHandler@42e3ede4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@201b6b6f,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):999] - org.spark_project.jetty.servlet.ServletHandler@201b6b6f added {org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):999] - org.spark_project.jetty.servlet.ServletHandler@201b6b6f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-75459c75,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1000] - o.s.j.s.ServletContextHandler@67ab1c47{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@b78a709,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1001] - org.spark_project.jetty.servlet.ServletHandler@b78a709 added {org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1001] - org.spark_project.jetty.servlet.ServletHandler@b78a709 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1002] - o.s.j.s.ServletContextHandler@2a3c96e3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@15cafec7,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1002] - org.spark_project.jetty.servlet.ServletHandler@15cafec7 added {org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1002] - org.spark_project.jetty.servlet.ServletHandler@15cafec7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5b444398,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1006] - o.s.j.s.ServletContextHandler@1f2f9244{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4c4d27c8,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1006] - org.spark_project.jetty.servlet.ServletHandler@4c4d27c8 added {org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1007] - org.spark_project.jetty.servlet.ServletHandler@4c4d27c8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-6821ea29,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1008] - o.s.j.s.ServletContextHandler@338494fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@505a9d7c,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1008] - org.spark_project.jetty.servlet.ServletHandler@505a9d7c added {org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1008] - org.spark_project.jetty.servlet.ServletHandler@505a9d7c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-758c83d8,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1009] - o.s.j.s.ServletContextHandler@5af3a0f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@19ae6bb,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1009] - org.spark_project.jetty.servlet.ServletHandler@19ae6bb added {org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1009] - org.spark_project.jetty.servlet.ServletHandler@19ae6bb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-10993713,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1009] - o.s.j.s.ServletContextHandler@58359ebd{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@24b6b8f6,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1009] - org.spark_project.jetty.servlet.ServletHandler@24b6b8f6 added {org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1010] - org.spark_project.jetty.servlet.ServletHandler@24b6b8f6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1010] - o.s.j.s.ServletContextHandler@5f031ebd{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4ee37ca3,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1018] - org.spark_project.jetty.servlet.ServletHandler@4ee37ca3 added {org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1019] - org.spark_project.jetty.servlet.ServletHandler@4ee37ca3 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-662f5666,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - o.s.j.s.ServletContextHandler@27305e6{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1ef3efa8,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - org.spark_project.jetty.servlet.ServletHandler@1ef3efa8 added {org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1020] - org.spark_project.jetty.servlet.ServletHandler@1ef3efa8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1021] - o.s.j.s.ServletContextHandler@7446d8d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1024] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1025] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-dcfda20,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1025] - o.s.j.s.ServletContextHandler@40499e4f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@51cd7ffc,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1025] - org.spark_project.jetty.servlet.ServletHandler@51cd7ffc added {org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1026] - org.spark_project.jetty.servlet.ServletHandler@51cd7ffc added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-30d4b288,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1044] - org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212 mime types IncludeExclude@1b065145{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@45cff11c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@207ea13}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1045] - org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212 added {o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1045] - org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903 mime types IncludeExclude@62dae540{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5827af16,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@654d8173}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1046] - org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903 added {o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1046] - org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8 mime types IncludeExclude@630cb4a4{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@636e8cc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@f79a760}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1046] - org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8 added {o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582 mime types IncludeExclude@239b0f9d{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@619bfe29,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b057c8c}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582 added {o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1047] - org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b mime types IncludeExclude@652a7737{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b7ea70d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2bef51f2}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1050] - org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b added {o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1051] - org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8 mime types IncludeExclude@30f5a68a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1e1d3956,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4f2c9ba6}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8 added {o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1052] - org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1 mime types IncludeExclude@53f48368{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@24d4d7c9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@f0e995e}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1052] - org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1 added {o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1052] - org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45 mime types IncludeExclude@a8c1f44{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@150ab4ed,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3c435123}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1053] - org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45 added {o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1053] - org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a mime types IncludeExclude@3a62c01e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7a8fa663,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5ce33a58}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1053] - org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a added {o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1053] - org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed mime types IncludeExclude@546ccad7{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5357c287,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1623134f}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed added {o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1054] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389 mime types IncludeExclude@485a3466{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@25748410,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2b43529a}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1055] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389 added {o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1055] - org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240 mime types IncludeExclude@5b04476e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5ad10c1a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6bb75258}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1056] - org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240 added {o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1058] - org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc mime types IncludeExclude@75e01201{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2783717b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@76f7d241}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1058] - org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc added {o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1058] - org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8 mime types IncludeExclude@3f363cf5{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3829ac1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4baf352a}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1059] - org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8 added {o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1059] - org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8 mime types IncludeExclude@15eebbff{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@22d6f11,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@30990c1b}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1059] - org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8 added {o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1059] - org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d mime types IncludeExclude@44828f6b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2dbe250d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@553f1d75}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1060] - org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d added {o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1060] - org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e mime types IncludeExclude@3e34ace1{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62fe6067,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4f071df8}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1060] - org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e added {o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1060] - org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9 mime types IncludeExclude@56ace400{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@47404bea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@305f7627}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1060] - org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9 added {o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1061] - org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107 mime types IncludeExclude@6cbcf243{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@29e6eb25,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62435e70}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1061] - org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107 added {o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1061] - org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286 mime types IncludeExclude@38be305c{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@269f4bad,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5ed731d0}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1062] - org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286 added {o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1062] - org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e mime types IncludeExclude@7bc10d84{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@275fe372,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@40e10ff8}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1062] - org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e added {o.s.j.s.ServletContextHandler@5f031ebd{/static,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1062] - org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d mime types IncludeExclude@26a4842b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7e38a7fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@366ef90e}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1062] - org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d added {o.s.j.s.ServletContextHandler@27305e6{/,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1062] - org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298 mime types IncludeExclude@31e75d13{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@a5b0b86,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4b3c354a}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1063] - org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298 added {o.s.j.s.ServletContextHandler@7446d8d5{/api,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1063] - org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67 mime types IncludeExclude@73ff4fae{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@21aa6d6c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@b968a76}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1063] - org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67 added {o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,null},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1070] - org.spark_project.jetty.server.Server@5b408dc3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1079] - HttpConnectionFactory@50eca7c6{HTTP/1.1} added {HttpConfiguration@58e6d4b8{32768/8192,8192/8192,https://:0,[]},POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1083] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@5b408dc3,UNMANAGED}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1083] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1084] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5ef0d29e,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1084] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@34a97744,POJO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1085] - ServerConnector@2c3dec30{null}{0.0.0.0:0} added {HttpConnectionFactory@50eca7c6{HTTP/1.1},AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1087] - ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@2cac4385,MANAGED}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1089] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1089] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1089] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1089] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582] added {org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1090] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b] added {org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1090] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1090] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1090] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45] added {org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1090] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a] added {org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1091] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed] added {org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1091] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1092] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1092] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc] added {org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1092] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1092] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8] added {org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1092] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1092] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e] added {org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,AUTO}
[DEBUG]2016-12-29 17:23:06  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1092] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9] added {org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1093] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1093] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286] added {org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1093] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e] added {org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1093] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1093] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298] added {org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1093] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67] added {org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1094] - org.spark_project.jetty.server.Server@5b408dc3 added {ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040},AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1096] - org.spark_project.jetty.server.Server@5b408dc3 added {org.spark_project.jetty.server.handler.ErrorHandler@4e517165,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1096] - org.spark_project.jetty.server.Server@5b408dc3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67],AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1096] - starting org.spark_project.jetty.server.Server@5b408dc3
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1099] - jetty-9.2.z-SNAPSHOT
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1107] - starting org.spark_project.jetty.server.Server@5b408dc3
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1108] - starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1108] - STARTED @1621ms SparkUI{STARTED,8<=8<=200,i=8,q=0}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1109] - starting org.spark_project.jetty.server.handler.ErrorHandler@4e517165
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1109] - starting org.spark_project.jetty.server.handler.ErrorHandler@4e517165
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1109] - STARTED @1621ms org.spark_project.jetty.server.handler.ErrorHandler@4e517165
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1109] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1110] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1110] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1110] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1111] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1112] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1112] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1112] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1112] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1112] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1113] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1113] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1113] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1113] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1114] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1114] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1114] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1114] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1114] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1114] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1114] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1114] - starting o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1116] - starting o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1116] - starting org.spark_project.jetty.servlet.ServletHandler@68b6f0d6
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1117] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1118] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1118] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1118] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1118] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1118] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4=org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1118] - starting org.spark_project.jetty.servlet.ServletHandler@68b6f0d6
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1118] - STARTED @1631ms org.spark_project.jetty.servlet.ServletHandler@68b6f0d6
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1118] - starting org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1120] - STARTED @1632ms org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4@4704963f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1121] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3a94964 for org.apache.spark.ui.JettyUtils$$anon$2-2a8d39c4
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1121] - Started o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1121] - STARTED @1633ms o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1121] - STARTED @1633ms org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1121] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1121] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1121] - starting o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1121] - starting o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1121] - starting org.spark_project.jetty.servlet.ServletHandler@5dd91bca
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1122] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-40cb698e from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1122] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1122] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1122] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1122] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1122] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-40cb698e=org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1122] - starting org.spark_project.jetty.servlet.ServletHandler@5dd91bca
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1122] - STARTED @1635ms org.spark_project.jetty.servlet.ServletHandler@5dd91bca
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1123] - starting org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1123] - STARTED @1635ms org.apache.spark.ui.JettyUtils$$anon$2-40cb698e@3ffb2458==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1123] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@6d0b5baf for org.apache.spark.ui.JettyUtils$$anon$2-40cb698e
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1123] - Started o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1123] - STARTED @1635ms o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1123] - STARTED @1635ms org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1123] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1123] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1123] - starting o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1124] - starting o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1124] - starting org.spark_project.jetty.servlet.ServletHandler@4d18aa28
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1124] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-75390459 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1124] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1124] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1124] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1124] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1124] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-75390459=org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1124] - starting org.spark_project.jetty.servlet.ServletHandler@4d18aa28
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1124] - STARTED @1637ms org.spark_project.jetty.servlet.ServletHandler@4d18aa28
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1125] - starting org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1125] - STARTED @1637ms org.apache.spark.ui.JettyUtils$$anon$2-75390459@2bf0a439==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1125] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@2a3591c5 for org.apache.spark.ui.JettyUtils$$anon$2-75390459
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1125] - Started o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1125] - STARTED @1637ms o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1125] - STARTED @1637ms org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1125] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1125] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1125] - starting o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1126] - starting o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1126] - starting org.spark_project.jetty.servlet.ServletHandler@2313052e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1126] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1126] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1126] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1126] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1126] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1126] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e=org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1126] - starting org.spark_project.jetty.servlet.ServletHandler@2313052e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1127] - STARTED @1639ms org.spark_project.jetty.servlet.ServletHandler@2313052e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1127] - starting org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1127] - STARTED @1639ms org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e@c454b3c8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1127] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@107ed6fc for org.apache.spark.ui.JettyUtils$$anon$2-2bd2b28e
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1127] - Started o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1127] - STARTED @1640ms o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1128] - STARTED @1640ms org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1128] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1128] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1128] - starting o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1129] - starting o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1129] - starting org.spark_project.jetty.servlet.ServletHandler@6cfcd46d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1129] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-52045dbe from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1129] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1129] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1129] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1129] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1129] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-52045dbe=org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1129] - starting org.spark_project.jetty.servlet.ServletHandler@6cfcd46d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1129] - STARTED @1642ms org.spark_project.jetty.servlet.ServletHandler@6cfcd46d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1130] - starting org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1130] - STARTED @1642ms org.apache.spark.ui.JettyUtils$$anon$2-52045dbe@b8199900==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1130] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@186978a6 for org.apache.spark.ui.JettyUtils$$anon$2-52045dbe
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1130] - Started o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1130] - STARTED @1642ms o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1130] - STARTED @1642ms org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1130] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1130] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1130] - starting o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1130] - starting o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1131] - starting org.spark_project.jetty.servlet.ServletHandler@5c8eee0f
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1131] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-565b064f from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1131] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1131] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1131] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1131] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1131] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-565b064f=org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1131] - starting org.spark_project.jetty.servlet.ServletHandler@5c8eee0f
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1131] - STARTED @1644ms org.spark_project.jetty.servlet.ServletHandler@5c8eee0f
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1132] - starting org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1132] - STARTED @1644ms org.apache.spark.ui.JettyUtils$$anon$2-565b064f@96c00233==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1132] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@482d776b for org.apache.spark.ui.JettyUtils$$anon$2-565b064f
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1132] - Started o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1132] - STARTED @1644ms o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1132] - STARTED @1644ms org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1132] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1132] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1132] - starting o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1132] - starting o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1132] - starting org.spark_project.jetty.servlet.ServletHandler@58c34bb3
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1133] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-56a4479a from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1133] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1133] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1133] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1133] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1133] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-56a4479a=org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1133] - starting org.spark_project.jetty.servlet.ServletHandler@58c34bb3
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1133] - STARTED @1646ms org.spark_project.jetty.servlet.ServletHandler@58c34bb3
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1134] - starting org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1134] - STARTED @1646ms org.apache.spark.ui.JettyUtils$$anon$2-56a4479a@df4eda2c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1134] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@132ddbab for org.apache.spark.ui.JettyUtils$$anon$2-56a4479a
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1134] - Started o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1134] - STARTED @1646ms o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1134] - STARTED @1646ms org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1134] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1134] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1134] - starting o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1134] - starting o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1135] - starting org.spark_project.jetty.servlet.ServletHandler@20a8a64e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1135] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1135] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1135] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1135] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1135] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1135] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b=org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1135] - starting org.spark_project.jetty.servlet.ServletHandler@20a8a64e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1135] - STARTED @1648ms org.spark_project.jetty.servlet.ServletHandler@20a8a64e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1136] - starting org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1136] - STARTED @1648ms org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b@7c36bf66==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1136] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@acb0951 for org.apache.spark.ui.JettyUtils$$anon$2-62f4ff3b
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1136] - Started o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1136] - STARTED @1648ms o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1136] - STARTED @1648ms org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1136] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1136] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1136] - starting o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1136] - starting o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1136] - starting org.spark_project.jetty.servlet.ServletHandler@207b8649
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1137] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1137] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1137] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1137] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1137] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1137] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a=org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1137] - starting org.spark_project.jetty.servlet.ServletHandler@207b8649
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1137] - STARTED @1649ms org.spark_project.jetty.servlet.ServletHandler@207b8649
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1137] - starting org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1137] - STARTED @1650ms org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a@140504e0==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1138] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@267f474e for org.apache.spark.ui.JettyUtils$$anon$2-65b3a85a
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1138] - Started o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1138] - STARTED @1650ms o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1138] - STARTED @1650ms org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1138] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1138] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1138] - starting o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1138] - starting o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1138] - starting org.spark_project.jetty.servlet.ServletHandler@57eda880
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1138] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1138] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1138] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1139] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1139] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1139] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa=org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1139] - starting org.spark_project.jetty.servlet.ServletHandler@57eda880
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1139] - STARTED @1651ms org.spark_project.jetty.servlet.ServletHandler@57eda880
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1139] - starting org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1139] - STARTED @1651ms org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa@745fba9e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1139] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@28276e50 for org.apache.spark.ui.JettyUtils$$anon$2-2b5825fa
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1139] - Started o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1140] - STARTED @1652ms o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1140] - STARTED @1652ms org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1140] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1140] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1140] - starting o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1140] - starting o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1140] - starting org.spark_project.jetty.servlet.ServletHandler@f667fe
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1140] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-788fcafb from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1140] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1140] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1140] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1141] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1141] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-788fcafb=org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1141] - starting org.spark_project.jetty.servlet.ServletHandler@f667fe
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1145] - STARTED @1657ms org.spark_project.jetty.servlet.ServletHandler@f667fe
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1145] - starting org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1145] - STARTED @1658ms org.apache.spark.ui.JettyUtils$$anon$2-788fcafb@d5bd90b6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1146] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3efe7086 for org.apache.spark.ui.JettyUtils$$anon$2-788fcafb
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1146] - Started o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1146] - STARTED @1658ms o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1146] - STARTED @1658ms org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1146] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1146] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1146] - starting o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1146] - starting o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1146] - starting org.spark_project.jetty.servlet.ServletHandler@25e2a451
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1147] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-1698ee84 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1147] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1147] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1147] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1147] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1147] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-1698ee84=org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1147] - starting org.spark_project.jetty.servlet.ServletHandler@25e2a451
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1147] - STARTED @1660ms org.spark_project.jetty.servlet.ServletHandler@25e2a451
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1148] - starting org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1148] - STARTED @1660ms org.apache.spark.ui.JettyUtils$$anon$2-1698ee84@fbd79e6d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1148] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@741b3bc3 for org.apache.spark.ui.JettyUtils$$anon$2-1698ee84
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1148] - Started o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1148] - STARTED @1660ms o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1148] - STARTED @1660ms org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1148] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1148] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1148] - starting o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1148] - starting o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1153] - starting org.spark_project.jetty.servlet.ServletHandler@328cf0e1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1154] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1154] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1154] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1154] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1155] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1155] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa=org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1155] - starting org.spark_project.jetty.servlet.ServletHandler@328cf0e1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1155] - STARTED @1668ms org.spark_project.jetty.servlet.ServletHandler@328cf0e1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1155] - starting org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1156] - STARTED @1668ms org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa@aa1db364==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1156] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@63648ee9 for org.apache.spark.ui.JettyUtils$$anon$2-63b1d4fa
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1156] - Started o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1156] - STARTED @1668ms o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1156] - STARTED @1668ms org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1156] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1156] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1156] - starting o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1157] - starting o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1157] - starting org.spark_project.jetty.servlet.ServletHandler@201b6b6f
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1157] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-75459c75 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1158] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1158] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1158] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1158] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1158] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-75459c75=org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1158] - starting org.spark_project.jetty.servlet.ServletHandler@201b6b6f
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1158] - STARTED @1670ms org.spark_project.jetty.servlet.ServletHandler@201b6b6f
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1159] - starting org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1159] - STARTED @1671ms org.apache.spark.ui.JettyUtils$$anon$2-75459c75@2d71e6d4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1159] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@45be7cd5 for org.apache.spark.ui.JettyUtils$$anon$2-75459c75
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1159] - Started o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1159] - STARTED @1672ms o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1160] - STARTED @1672ms org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1160] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1160] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1160] - starting o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1160] - starting o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1160] - starting org.spark_project.jetty.servlet.ServletHandler@b78a709
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1161] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1162] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1162] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1162] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1162] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1162] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1=org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1162] - starting org.spark_project.jetty.servlet.ServletHandler@b78a709
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1674ms org.spark_project.jetty.servlet.ServletHandler@b78a709
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1675ms org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1@d688f6a6==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1163] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3185fa6b for org.apache.spark.ui.JettyUtils$$anon$2-30bcf3c1
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1163] - Started o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1163] - STARTED @1675ms o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1163] - STARTED @1675ms org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1163] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1163] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1163] - starting o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1163] - starting o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1163] - starting org.spark_project.jetty.servlet.ServletHandler@15cafec7
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1163] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5b444398 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1164] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1165] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1165] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1166] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1166] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5b444398=org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1166] - starting org.spark_project.jetty.servlet.ServletHandler@15cafec7
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1166] - STARTED @1678ms org.spark_project.jetty.servlet.ServletHandler@15cafec7
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1166] - starting org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1166] - STARTED @1678ms org.apache.spark.ui.JettyUtils$$anon$2-5b444398@aa16e638==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1166] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5b58ed3c for org.apache.spark.ui.JettyUtils$$anon$2-5b444398
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1166] - Started o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1166] - STARTED @1679ms o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1167] - STARTED @1679ms org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1167] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1167] - starting o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1167] - starting org.spark_project.jetty.servlet.ServletHandler@4c4d27c8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1167] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-6821ea29 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1167] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1167] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1167] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1168] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1168] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-6821ea29=org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1168] - starting org.spark_project.jetty.servlet.ServletHandler@4c4d27c8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1168] - STARTED @1680ms org.spark_project.jetty.servlet.ServletHandler@4c4d27c8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1168] - starting org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1168] - STARTED @1680ms org.apache.spark.ui.JettyUtils$$anon$2-6821ea29@60b554b1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1168] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3a320ade for org.apache.spark.ui.JettyUtils$$anon$2-6821ea29
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1168] - Started o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1168] - STARTED @1681ms o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1168] - STARTED @1681ms org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1169] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1169] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1169] - starting o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1169] - starting o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1169] - starting org.spark_project.jetty.servlet.ServletHandler@505a9d7c
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1169] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-758c83d8 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1169] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1169] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1169] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1169] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1169] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-758c83d8=org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1170] - starting org.spark_project.jetty.servlet.ServletHandler@505a9d7c
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1170] - STARTED @1682ms org.spark_project.jetty.servlet.ServletHandler@505a9d7c
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1170] - starting org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1170] - STARTED @1682ms org.apache.spark.ui.JettyUtils$$anon$2-758c83d8@36cc5f65==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1170] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7813cb11 for org.apache.spark.ui.JettyUtils$$anon$2-758c83d8
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1170] - Started o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1170] - STARTED @1683ms o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1170] - STARTED @1683ms org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1170] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1171] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1171] - starting o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1171] - starting o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1171] - starting org.spark_project.jetty.servlet.ServletHandler@19ae6bb
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1171] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-10993713 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1171] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1171] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1171] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1171] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1172] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-10993713=org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1172] - starting org.spark_project.jetty.servlet.ServletHandler@19ae6bb
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1684ms org.spark_project.jetty.servlet.ServletHandler@19ae6bb
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1172] - starting org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1684ms org.apache.spark.ui.JettyUtils$$anon$2-10993713@be68ea52==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1172] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@21005f6c for org.apache.spark.ui.JettyUtils$$anon$2-10993713
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1172] - Started o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1685ms o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1685ms org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1173] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1173] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1173] - starting o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1173] - starting o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1173] - starting org.spark_project.jetty.servlet.ServletHandler@24b6b8f6
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1173] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1173] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1173] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1173] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1173] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1173] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5=org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1173] - starting org.spark_project.jetty.servlet.ServletHandler@24b6b8f6
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1686ms org.spark_project.jetty.servlet.ServletHandler@24b6b8f6
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1174] - starting org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1686ms org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5@e1a254ad==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1176] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@545de5a4 for org.apache.spark.ui.JettyUtils$$anon$2-72cf2de5
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1176] - Started o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1688ms o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1688ms org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1176] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1176] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1176] - starting o.s.j.s.ServletContextHandler@5f031ebd{/static,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1176] - starting o.s.j.s.ServletContextHandler@5f031ebd{/static,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1176] - starting org.spark_project.jetty.servlet.ServletHandler@4ee37ca3
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1176] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-662f5666 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1177] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1177] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1177] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1177] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1177] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-662f5666=org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1178] - starting org.spark_project.jetty.servlet.ServletHandler@4ee37ca3
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1690ms org.spark_project.jetty.servlet.ServletHandler@4ee37ca3
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1178] - starting org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1690ms org.spark_project.jetty.servlet.DefaultServlet-662f5666@89615064==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1178] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@ab7a938 for org.spark_project.jetty.servlet.DefaultServlet-662f5666
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1184] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-core_2.11-2.0.0.jar!/org/apache/spark/ui/static
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1184] - Started o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1185] - STARTED @1697ms o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1185] - STARTED @1697ms org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1185] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1185] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1185] - starting o.s.j.s.ServletContextHandler@27305e6{/,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1186] - starting o.s.j.s.ServletContextHandler@27305e6{/,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1186] - starting org.spark_project.jetty.servlet.ServletHandler@1ef3efa8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1186] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1186] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1186] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1186] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1186] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1186] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c=org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1188] - starting org.spark_project.jetty.servlet.ServletHandler@1ef3efa8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1700ms org.spark_project.jetty.servlet.ServletHandler@1ef3efa8
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1188] - starting org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1701ms org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c@48bf0c7f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1188] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@68759011 for org.apache.spark.ui.JettyUtils$$anon$3-502f1f4c
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1189] - Started o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1189] - STARTED @1701ms o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1189] - STARTED @1701ms org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1189] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting o.s.j.s.ServletContextHandler@7446d8d5{/api,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1189] - starting o.s.j.s.ServletContextHandler@7446d8d5{/api,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1189] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-dcfda20 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1189] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1189] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1190] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1190] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1190] - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-dcfda20=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.doStart(ServletHandler.java:165):1190] - Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1191] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1191] - org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216,POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1191] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-dcfda20 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1192] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1192] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1192] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1192] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1192] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1192] - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-dcfda20=org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1192] - starting org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1705ms org.spark_project.jetty.servlet.ServletHandler@5c3b6c6e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1192] - starting org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1193] - STARTED @1705ms org.glassfish.jersey.servlet.ServletContainer-dcfda20@cb05d974==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1193] - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1193] - STARTED @1705ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1d1f7216@78da34ac==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1193] - Started o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1193] - STARTED @1705ms o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1193] - STARTED @1705ms org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1193] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1194] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1194] - starting o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1194] - starting o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1194] - starting org.spark_project.jetty.servlet.ServletHandler@51cd7ffc
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1195] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-30d4b288 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1195] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1195] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1195] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1195] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1195] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-30d4b288=org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1195] - starting org.spark_project.jetty.servlet.ServletHandler@51cd7ffc
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1708ms org.spark_project.jetty.servlet.ServletHandler@51cd7ffc
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1196] - starting org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1196] - STARTED @1708ms org.apache.spark.ui.JettyUtils$$anon$3-30d4b288@cba3ede9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1196] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@43b4fe19 for org.apache.spark.ui.JettyUtils$$anon$3-30d4b288
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1196] - Started o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1196] - STARTED @1708ms o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1196] - STARTED @1708ms org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1196] - STARTED @1709ms org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1197] - starting ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1197] - ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1197] - starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5ef0d29e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1198] - STARTED @1710ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5ef0d29e
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1198] - starting HttpConnectionFactory@50eca7c6{HTTP/1.1}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1198] - STARTED @1710ms HttpConnectionFactory@50eca7c6{HTTP/1.1}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1198] - starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@2cac4385
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1201] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@2c1b9e4b keys=-1 selected=-1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1203] - STARTED @1715ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@2c1b9e4b keys=0 selected=0
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1203] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@3c0fae6c keys=-1 selected=-1
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1205] - STARTED @1717ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@3c0fae6c keys=0 selected=0
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1205] - STARTED @1718ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@2cac4385
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1206] - ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040} added {acceptor-0@fd0e5b6,POJO}
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1207] - Started ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1207] - STARTED @1719ms ServerConnector@2c3dec30{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1207] - Started @1719ms
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1207] - STARTED @1719ms org.spark_project.jetty.server.Server@5b408dc3
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1207] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1209] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[DEBUG]2016-12-29 17:23:07  [SparkUI-35-selector-ServerConnectorManager@2cac4385/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1215] - Starting Thread[SparkUI-35-selector-ServerConnectorManager@2cac4385/0,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@2c1b9e4b keys=0 selected=0
[DEBUG]2016-12-29 17:23:07  [SparkUI-35-selector-ServerConnectorManager@2cac4385/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1216] - Selector loop waiting on select
[DEBUG]2016-12-29 17:23:07  [SparkUI-36-selector-ServerConnectorManager@2cac4385/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1229] - Starting Thread[SparkUI-36-selector-ServerConnectorManager@2cac4385/1,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@3c0fae6c keys=0 selected=0
[DEBUG]2016-12-29 17:23:07  [SparkUI-36-selector-ServerConnectorManager@2cac4385/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1229] - Selector loop waiting on select
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1313] - Starting executor ID driver on host localhost
[DEBUG]2016-12-29 17:23:07  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):1338] - Shuffle server started on port :50198
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1338] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50198.
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1339] - Server created on 172.18.10.41:50198
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1340] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 50198)
[INFO ]2016-12-29 17:23:07  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1343] - Registering block manager 172.18.10.41:50198 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 50198)
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1346] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 50198)
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1482] - o.s.j.s.ServletContextHandler@2899a8db{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1e8823d2,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1482] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1483] - org.spark_project.jetty.servlet.ServletHandler@1e8823d2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-c1a4620,POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1484] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}] added {o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1484] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1484] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1484] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1485] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1485] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1485] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1485] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1485] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1486] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1487] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1487] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1487] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1487] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1487] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1488] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1488] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1488] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1488] - starting o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1488] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1488] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1488] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1488] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1488] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1488] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1489] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-c1a4620=org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1489] - starting org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1489] - STARTED @2001ms org.spark_project.jetty.servlet.ServletHandler@1e8823d2
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1489] - starting org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1489] - STARTED @2001ms org.apache.spark.ui.JettyUtils$$anon$2-c1a4620@14afb246==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1489] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5710768a for org.apache.spark.ui.JettyUtils$$anon$2-c1a4620
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1489] - Started o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1489] - STARTED @2002ms o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1506] - Use an existing SparkContext, some configuration may not take effect.
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1537] - o.s.j.s.ServletContextHandler@654b72c0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@55b5e331,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1538] - org.spark_project.jetty.servlet.ServletHandler@55b5e331 added {org.apache.spark.ui.JettyUtils$$anon$2-6034e75d@bb61fca9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1540] - org.spark_project.jetty.servlet.ServletHandler@55b5e331 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-6034e75d,POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1540] - o.s.j.s.ServletContextHandler@15fc442{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3f3c7bdb,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1541] - org.spark_project.jetty.servlet.ServletHandler@3f3c7bdb added {org.apache.spark.ui.JettyUtils$$anon$2-456abb66@fbb6baf9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1541] - org.spark_project.jetty.servlet.ServletHandler@3f3c7bdb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-456abb66,POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1541] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,null}] added {o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1541] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1542] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1542] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1542] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1542] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1550] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1550] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1550] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1551] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1552] - SQL->[{o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,null},[o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1553] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1571] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1571] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1571] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1571] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1571] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1572] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1572] - starting o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1572] - starting o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1572] - starting org.spark_project.jetty.servlet.ServletHandler@55b5e331
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1572] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-6034e75d from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1572] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1572] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1572] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1572] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-6034e75d@bb61fca9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1573] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-6034e75d=org.apache.spark.ui.JettyUtils$$anon$2-6034e75d@bb61fca9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1573] - starting org.spark_project.jetty.servlet.ServletHandler@55b5e331
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1573] - STARTED @2085ms org.spark_project.jetty.servlet.ServletHandler@55b5e331
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1573] - starting org.apache.spark.ui.JettyUtils$$anon$2-6034e75d@bb61fca9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1573] - STARTED @2085ms org.apache.spark.ui.JettyUtils$$anon$2-6034e75d@bb61fca9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1574] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7da10b5b for org.apache.spark.ui.JettyUtils$$anon$2-6034e75d
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1575] - Started o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1575] - STARTED @2087ms o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1575] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,null}] added {o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1575] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1575] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1576] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1576] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1576] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1576] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1576] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1590] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1590] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1590] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1590] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1591] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1591] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1591] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1591] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1591] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1591] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1591] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1592] - SQL->[{o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1592] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1592] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1592] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1601] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1601] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1602] - SQL/json->[{o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,null},[o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1602] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1602] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1602] - starting o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1603] - starting o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1603] - starting org.spark_project.jetty.servlet.ServletHandler@3f3c7bdb
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1603] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-456abb66 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1603] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1603] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1603] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1603] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-456abb66@fbb6baf9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1606] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-456abb66=org.apache.spark.ui.JettyUtils$$anon$2-456abb66@fbb6baf9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1606] - starting org.spark_project.jetty.servlet.ServletHandler@3f3c7bdb
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1607] - STARTED @2119ms org.spark_project.jetty.servlet.ServletHandler@3f3c7bdb
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1607] - starting org.apache.spark.ui.JettyUtils$$anon$2-456abb66@fbb6baf9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1607] - STARTED @2119ms org.apache.spark.ui.JettyUtils$$anon$2-456abb66@fbb6baf9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1607] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@31be6b49 for org.apache.spark.ui.JettyUtils$$anon$2-456abb66
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1607] - Started o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1607] - STARTED @2120ms o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1607] - o.s.j.s.ServletContextHandler@5b989dc7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@70d8de,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1608] - org.spark_project.jetty.servlet.ServletHandler@70d8de added {org.apache.spark.ui.JettyUtils$$anon$2-42561fba@58db0c40==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1608] - org.spark_project.jetty.servlet.ServletHandler@70d8de added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-42561fba,POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1608] - o.s.j.s.ServletContextHandler@595f4da5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@46b695ec,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1608] - org.spark_project.jetty.servlet.ServletHandler@46b695ec added {org.apache.spark.ui.JettyUtils$$anon$2-408613cc@f42c6049==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1608] - org.spark_project.jetty.servlet.ServletHandler@46b695ec added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-408613cc,POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1608] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,null}] added {o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - SQL->[{o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - SQL/json->[{o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - SQL/execution->[{o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,null},[o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1613] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1613] - starting o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1613] - starting o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1614] - starting org.spark_project.jetty.servlet.ServletHandler@70d8de
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1615] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-42561fba from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1615] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1615] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1615] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1615] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-42561fba@58db0c40==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1615] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-42561fba=org.apache.spark.ui.JettyUtils$$anon$2-42561fba@58db0c40==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1615] - starting org.spark_project.jetty.servlet.ServletHandler@70d8de
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1615] - STARTED @2128ms org.spark_project.jetty.servlet.ServletHandler@70d8de
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1615] - starting org.apache.spark.ui.JettyUtils$$anon$2-42561fba@58db0c40==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1616] - STARTED @2128ms org.apache.spark.ui.JettyUtils$$anon$2-42561fba@58db0c40==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1616] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@11ce2e22 for org.apache.spark.ui.JettyUtils$$anon$2-42561fba
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1616] - Started o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1616] - STARTED @2128ms o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1616] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,null}] added {o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,null},[o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - SQL->[{o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - SQL/json->[{o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - SQL/execution->[{o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1620] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1620] - starting o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1620] - starting o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1620] - starting org.spark_project.jetty.servlet.ServletHandler@46b695ec
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1620] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-408613cc from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1621] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1621] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1621] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1621] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-408613cc@f42c6049==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1621] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-408613cc=org.apache.spark.ui.JettyUtils$$anon$2-408613cc@f42c6049==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1621] - starting org.spark_project.jetty.servlet.ServletHandler@46b695ec
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1621] - STARTED @2134ms org.spark_project.jetty.servlet.ServletHandler@46b695ec
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1621] - starting org.apache.spark.ui.JettyUtils$$anon$2-408613cc@f42c6049==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1621] - STARTED @2134ms org.apache.spark.ui.JettyUtils$$anon$2-408613cc@f42c6049==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1622] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@13cda7c9 for org.apache.spark.ui.JettyUtils$$anon$2-408613cc
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1622] - Started o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1622] - STARTED @2134ms o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1623] - o.s.j.s.ServletContextHandler@91c4a3f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62d0ac62,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1623] - org.spark_project.jetty.servlet.ServletHandler@62d0ac62 added {org.spark_project.jetty.servlet.DefaultServlet-150d80c4@4990a090==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1623] - org.spark_project.jetty.servlet.ServletHandler@62d0ac62 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-150d80c4,POJO}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1624] - org.spark_project.jetty.server.handler.ContextHandlerCollection@58bf8650[org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212, org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903, org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8, org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582, org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b, org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8, org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1, org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45, org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a, org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389, org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240, org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc, org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8, org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8, org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d, org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e, org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9, org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107, org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286, org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e, org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d, org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298, org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67, o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,null}] added {o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1626] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@557a1e2d,[o.s.j.s.ServletContextHandler@27305e6{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1628] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@c260bdc,[o.s.j.s.ServletContextHandler@2fc0cc3{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1628] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a527389,[o.s.j.s.ServletContextHandler@7e928e2f{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1628] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4a335fa8,[o.s.j.s.ServletContextHandler@42e3ede4{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1629] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@595f4da5{/SQL/execution/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1629] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@33e01298,[o.s.j.s.ServletContextHandler@7446d8d5{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1629] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78a287ed,[o.s.j.s.ServletContextHandler@34997338{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1629] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@50fe837a,[o.s.j.s.ServletContextHandler@4504d271{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1629] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4bff1903,[o.s.j.s.ServletContextHandler@29df4d43{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1629] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3234f74e,[o.s.j.s.ServletContextHandler@5f031ebd{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1629] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4de41af9,[o.s.j.s.ServletContextHandler@338494fa{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1631] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@71b3bc45,[o.s.j.s.ServletContextHandler@62163b39{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1631] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@339bf286,[o.s.j.s.ServletContextHandler@58359ebd{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1632] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2453f95d,[o.s.j.s.ServletContextHandler@2a3c96e3{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1632] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@12dae582,[o.s.j.s.ServletContextHandler@7756c3cd{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1632] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4721d212,[o.s.j.s.ServletContextHandler@665df3c6{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1639] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@650eab8,[o.s.j.s.ServletContextHandler@674658f7{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1639] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4e28bdd1,[o.s.j.s.ServletContextHandler@73163d48{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1639] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@4264b240,[o.s.j.s.ServletContextHandler@4febb875{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1639] - SQL->[{o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@654b72c0{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1639] - static/sql->[{o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,null},[o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,null}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1639] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@78fb9a67,[o.s.j.s.ServletContextHandler@40499e4f{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1639] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1bb1fde8,[o.s.j.s.ServletContextHandler@67ab1c47{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1640] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@56c9bbd8,[o.s.j.s.ServletContextHandler@a5bd950{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1640] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1eb6749b,[o.s.j.s.ServletContextHandler@57fd91c9{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1640] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@6e1d8f9e,[o.s.j.s.ServletContextHandler@1f2f9244{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1640] - SQL/json->[{o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@15fc442{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1640] - metrics/json->[{o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1640] - SQL/execution->[{o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@5b989dc7{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1640] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5d018107,[o.s.j.s.ServletContextHandler@5af3a0f{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1640] - starting o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,null}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1640] - starting o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,STARTING}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1640] - starting org.spark_project.jetty.servlet.ServletHandler@62d0ac62
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1641] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-150d80c4 from default=false
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1641] - filterNameMap={}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1641] - pathFilters=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1641] - servletFilterMap=null
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1641] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-150d80c4@4990a090==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1641] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-150d80c4=org.spark_project.jetty.servlet.DefaultServlet-150d80c4@4990a090==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1641] - starting org.spark_project.jetty.servlet.ServletHandler@62d0ac62
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1641] - STARTED @2154ms org.spark_project.jetty.servlet.ServletHandler@62d0ac62
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1642] - starting org.spark_project.jetty.servlet.DefaultServlet-150d80c4@4990a090==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1642] - STARTED @2154ms org.spark_project.jetty.servlet.DefaultServlet-150d80c4@4990a090==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1642] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@3003697 for org.spark_project.jetty.servlet.DefaultServlet-150d80c4
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1642] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-sql_2.11-2.0.0.jar!/org/apache/spark/sql/execution/ui/static
[INFO ]2016-12-29 17:23:07  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1642] - Started o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,AVAILABLE}
[DEBUG]2016-12-29 17:23:07  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1643] - STARTED @2155ms o.s.j.s.ServletContextHandler@91c4a3f{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:23:07  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1657] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:23:07  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1671] - 服务启动成功，监听端口：10080
[DEBUG]2016-12-29 17:23:10  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):4356] - -Dio.netty.leakDetectionLevel: simple
[DEBUG]2016-12-29 17:23:10  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):4367] - -Dio.netty.recycler.maxCapacity.default: 262144
[DEBUG]2016-12-29 17:23:10  [nioEventLoopGroup-3-1:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):4376] - uri:/antifraud
[INFO ]2016-12-29 17:23:10  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):4379] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:23:10  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):4446] - Rdd服务
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6231] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#6: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#6: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#0, name#1, sex#2]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#0, name#1, sex#2]
        
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6256] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#7: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#7: org.apache.spark.sql.Row
 +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6534] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6595] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[INFO ]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6706] - Code generated in 149.615287 ms
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6712] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6728] -  + declared fields: 4
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6729] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6729] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6729] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6729] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6730] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6730] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6731] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6731] -  + inner classes: 1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6732] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6732] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6733] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6734] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6739] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6740] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6741] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6764] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6765] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6765] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6765] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6765] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + inner classes: 1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6766] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6767] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6767] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6767] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6777] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6777] -  + declared fields: 1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6777] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6777] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6778] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6780] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6781] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6782] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6782] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6782] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6782] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:23:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6783] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6797] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6797] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6798] - Parents of final stage: List()
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6799] - Missing parents: List()
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6801] - submitStage(ResultStage 0)
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6803] - missing: List()
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6806] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6806] - submitMissingTasks(ResultStage 0)
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6905] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6907] - Put block broadcast_0 locally took  51 ms
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6908] - Putting block broadcast_0 without replication took  52 ms
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6929] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:23:12  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6961] - Added broadcast_0_piece0 in memory on 172.18.10.41:50198 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6963] - Updated info of block broadcast_0_piece0
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6963] - Told master about block broadcast_0_piece0
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6964] - Put block broadcast_0_piece0 locally took  37 ms
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6964] - Putting block broadcast_0_piece0 without replication took  37 ms
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6965] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6968] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6969] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):6970] - Adding task set 0.0 with 1 tasks
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6976] - Epoch for TaskSet 0.0: 0
[DEBUG]2016-12-29 17:23:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6979] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:23:12  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6988] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:23:12  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):6988] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[INFO ]2016-12-29 17:23:12  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7019] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:23:12  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7028] - Running task 0.0 in stage 0.0 (TID 0)
[DEBUG]2016-12-29 17:23:12  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7037] - Task 0's epoch is 0
[DEBUG]2016-12-29 17:23:12  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7040] - Getting local block broadcast_0
[DEBUG]2016-12-29 17:23:12  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7042] - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:23:12  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7086] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[DEBUG]2016-12-29 17:23:12  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7088] - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7102] - Code generated in 15.959864 ms
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7106] - closed connection
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7201] - Finished task 0.0 in stage 0.0 (TID 0). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7202] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7204] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:23:13  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7209] - Finished task 0.0 in stage 0.0 (TID 0) in 217 ms on localhost (1/1)
[INFO ]2016-12-29 17:23:13  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7212] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7213] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.232 s
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7217] - After removal of stage 0, remaining stages = 0
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7218] - Job 0 finished: count at RddServiceImpl.java:85, took 0.434548 s
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7221] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7221] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7223] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7223] -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7223] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7223] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7223] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7223] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7223] -  + outer classes: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7224] -      org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7224] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7224] -  + outer objects: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7224] -      <function0>
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7224] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7225] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7227] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7228] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7228] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7228] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7229] -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7230] -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7230] - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7231] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7231] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7231] -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7231] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -  + inner classes: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -  + outer classes: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -  + outer objects: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7232] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7233] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7233] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7233] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7233] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7233] -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7233] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7235] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7236] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7237] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7237] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7237] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7237] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7239] - Starting job: collect at RddServiceImpl.java:86
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7243] - Got job 1 (collect at RddServiceImpl.java:86) with 1 output partitions
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7244] - Final stage: ResultStage 1 (collect at RddServiceImpl.java:86)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7244] - Parents of final stage: List()
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7244] - Missing parents: List()
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7244] - submitStage(ResultStage 1)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7244] - missing: List()
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7244] - Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7244] - submitMissingTasks(ResultStage 1)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7247] - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7247] - Put block broadcast_1 locally took  1 ms
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7247] - Putting block broadcast_1 without replication took  1 ms
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7249] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:23:13  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7250] - Added broadcast_1_piece0 in memory on 172.18.10.41:50198 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7250] - Updated info of block broadcast_1_piece0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7251] - Told master about block broadcast_1_piece0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7251] - Put block broadcast_1_piece0 locally took  3 ms
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7251] - Putting block broadcast_1_piece0 without replication took  3 ms
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7251] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7251] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7251] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7251] - Adding task set 1.0 with 1 tasks
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7252] - Epoch for TaskSet 1.0: 0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7252] - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7252] - parentName: , name: TaskSet_1, runningTasks: 0
[INFO ]2016-12-29 17:23:13  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7253] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5168 bytes)
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7254] - Running task 0.0 in stage 1.0 (TID 1)
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7255] - Task 1's epoch is 0
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7256] - Getting local block broadcast_1
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7256] - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7281] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7282] - closed connection
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7284] - Finished task 0.0 in stage 1.0 (TID 1). 2526 bytes result sent to driver
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7285] - parentName: , name: TaskSet_1, runningTasks: 0
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7285] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:23:13  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7286] - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (1/1)
[INFO ]2016-12-29 17:23:13  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7287] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7287] - ResultStage 1 (collect at RddServiceImpl.java:86) finished in 0.035 s
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7287] - After removal of stage 1, remaining stages = 0
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7288] - Job 1 finished: collect at RddServiceImpl.java:86, took 0.049365 s
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7291] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7292] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7293] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7293] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7293] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7293] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):7303] - uri:/antifraud
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):7304] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):7304] - Rdd服务
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7323] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#14: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#14: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#8, name#9, sex#10]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#8, name#9, sex#10]
        
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7327] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#15: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#15: org.apache.spark.sql.Row
 +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7333] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7335] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7337] -  + declared fields: 4
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7337] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7337] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7337] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7337] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7337] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7338] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7338] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7338] -  + inner classes: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7338] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7338] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7338] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7339] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7340] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7340] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7340] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7342] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -  + inner classes: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7343] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7344] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7344] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7344] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7345] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7345] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7345] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7345] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -  + declared fields: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7346] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7347] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7347] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7347] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7347] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7348] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7349] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7349] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7349] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7349] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7349] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7350] - Got job 2 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7350] - Final stage: ResultStage 2 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7351] - Parents of final stage: List()
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7352] - Missing parents: List()
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7352] - submitStage(ResultStage 2)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7352] - missing: List()
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7352] - Submitting ResultStage 2 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7352] - submitMissingTasks(ResultStage 2)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7360] - Block broadcast_2 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7362] - Put block broadcast_2 locally took  3 ms
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7362] - Putting block broadcast_2 without replication took  3 ms
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7364] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:23:13  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7365] - Added broadcast_2_piece0 in memory on 172.18.10.41:50198 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7366] - Updated info of block broadcast_2_piece0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7366] - Told master about block broadcast_2_piece0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7366] - Put block broadcast_2_piece0 locally took  2 ms
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7366] - Putting block broadcast_2_piece0 without replication took  2 ms
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7367] - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7367] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7367] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7367] - Adding task set 2.0 with 1 tasks
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7367] - Epoch for TaskSet 2.0: 0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7367] - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7368] - parentName: , name: TaskSet_2, runningTasks: 0
[INFO ]2016-12-29 17:23:13  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7369] - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7369] - Running task 0.0 in stage 2.0 (TID 2)
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7370] - Task 2's epoch is 0
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7371] - Getting local block broadcast_2
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7371] - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7389] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7390] - closed connection
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7391] - Finished task 0.0 in stage 2.0 (TID 2). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7396] - parentName: , name: TaskSet_2, runningTasks: 0
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7401] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:23:13  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7402] - Finished task 0.0 in stage 2.0 (TID 2) in 34 ms on localhost (1/1)
[INFO ]2016-12-29 17:23:13  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7402] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7402] - ResultStage 2 (count at RddServiceImpl.java:85) finished in 0.035 s
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7402] - After removal of stage 2, remaining stages = 0
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7404] - Job 2 finished: count at RddServiceImpl.java:85, took 0.054306 s
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7405] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -  + outer classes: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -      org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -  + outer objects: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7406] -      <function0>
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7407] -      MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7407] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7408] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7408] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7408] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7408] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7408] -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7409] -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7409] - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -  + inner classes: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7410] -  + outer classes: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7411] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7411] -  + outer objects: 1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7411] -      MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7411] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7411] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7411] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7412] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7412] -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7412] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7413] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7413] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7413] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7413] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7414] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7414] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7414] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7414] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7414] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7414] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7415] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7415] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7415] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7415] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7416] - Starting job: collect at RddServiceImpl.java:86
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7417] - Got job 3 (collect at RddServiceImpl.java:86) with 1 output partitions
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7417] - Final stage: ResultStage 3 (collect at RddServiceImpl.java:86)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7417] - Parents of final stage: List()
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7417] - Missing parents: List()
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7417] - submitStage(ResultStage 3)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7417] - missing: List()
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7417] - Submitting ResultStage 3 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7417] - submitMissingTasks(ResultStage 3)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7418] - Block broadcast_3 stored as values in memory (estimated size 11.3 KB, free 905.9 MB)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7420] - Put block broadcast_3 locally took  2 ms
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7420] - Putting block broadcast_3 without replication took  2 ms
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7421] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KB, free 905.9 MB)
[INFO ]2016-12-29 17:23:13  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7423] - Added broadcast_3_piece0 in memory on 172.18.10.41:50198 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7424] - Updated info of block broadcast_3_piece0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7424] - Told master about block broadcast_3_piece0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7424] - Put block broadcast_3_piece0 locally took  3 ms
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7424] - Putting block broadcast_3_piece0 without replication took  3 ms
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7425] - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7425] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7425] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7425] - Adding task set 3.0 with 1 tasks
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7425] - Epoch for TaskSet 3.0: 0
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7425] - Valid locality levels for TaskSet 3.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7426] - parentName: , name: TaskSet_3, runningTasks: 0
[INFO ]2016-12-29 17:23:13  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7427] - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5169 bytes)
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7428] - Running task 0.0 in stage 3.0 (TID 3)
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7429] - Task 3's epoch is 0
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7429] - Getting local block broadcast_3
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7429] - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7444] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7445] - closed connection
[INFO ]2016-12-29 17:23:13  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7446] - Finished task 0.0 in stage 3.0 (TID 3). 2439 bytes result sent to driver
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7447] - parentName: , name: TaskSet_3, runningTasks: 0
[DEBUG]2016-12-29 17:23:13  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7448] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:23:13  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7449] - Finished task 0.0 in stage 3.0 (TID 3) in 23 ms on localhost (1/1)
[INFO ]2016-12-29 17:23:13  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7449] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7449] - ResultStage 3 (collect at RddServiceImpl.java:86) finished in 0.024 s
[DEBUG]2016-12-29 17:23:13  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7449] - After removal of stage 3, remaining stages = 0
[INFO ]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7450] - Job 3 finished: collect at RddServiceImpl.java:86, took 0.033536 s
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7450] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -  + declared fields: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -  + declared methods: 2
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -  + inner classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -  + outer classes: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7451] -  + outer objects: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7452] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7452] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7452] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:23:13  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7452] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[INFO ]2016-12-29 17:25:25  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):0] - Running Spark version 2.0.0
[DEBUG]2016-12-29 17:25:25  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):63] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:25:25  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):71] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
[DEBUG]2016-12-29 17:25:25  [main:org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42):72] - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
[DEBUG]2016-12-29 17:25:25  [main:org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:232):72] - UgiMetrics, User and group related metrics
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.authentication.util.KerberosName.<clinit>(KerberosName.java:88):230] - Kerberos krb5 configuration not found, setting default realm to empty
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:301):232] -  Creating new Groups object
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:46):234] - Trying to load the custom-built native-hadoop library...
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:50):236] - Loaded the native-hadoop library
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:50):237] - Using JniBasedUnixGroupsMapping for Group resolution
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:45):237] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.Groups.<init>(Groups.java:112):293] - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.login(UserGroupInformation.java:221):298] - hadoop login
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:156):299] - hadoop login commit
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:186):302] - using local user:NTUserPrincipal: pujjr
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:192):303] - Using user: "NTUserPrincipal: pujjr" with name pujjr
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:202):304] - User entry: "pujjr"
[DEBUG]2016-12-29 17:25:26  [main:org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:826):304] - UGI loginUser:pujjr (auth:SIMPLE)
[WARN ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):313] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):314] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):314] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):337] - Changing view acls to: pujjr
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):338] - Changing modify acls to: pujjr
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):338] - Changing view acls groups to: 
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):339] - Changing modify acls groups to: 
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):339] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[DEBUG]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):349] - Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):448] - Using SLF4J as the default logging framework
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):452] - java.nio.Buffer.address: available
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):453] - sun.misc.Unsafe.theUnsafe: available
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):454] - sun.misc.Unsafe.copyMemory: available
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):454] - java.nio.Bits.unaligned: true
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):455] - Platform: Windows
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):455] - Java version: 8
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):456] - -Dio.netty.noUnsafe: false
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):456] - sun.misc.Unsafe: available
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):456] - -Dio.netty.noJavassist: false
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):533] - Javassist: available
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):533] - -Dio.netty.tmpdir: C:\Users\pujjr\AppData\Local\Temp (java.io.tmpdir)
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):533] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):533] - -Dio.netty.noPreferDirect: false
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):535] - Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):538] - Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):545] - -Dio.netty.eventLoopThreads: 8
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):558] - -Dio.netty.noKeySetOptimization: false
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):558] - -Dio.netty.selectorAutoRebuildThreshold: 512
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):589] - -Dio.netty.allocator.numHeapArenas: 8
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):589] - -Dio.netty.allocator.numDirectArenas: 8
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.pageSize: 8192
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.maxOrder: 11
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.chunkSize: 16777216
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.tinyCacheSize: 512
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.smallCacheSize: 256
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.normalCacheSize: 64
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):590] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):591] - -Dio.netty.allocator.cacheTrimInterval: 8192
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:71):621] - -Dio.netty.initialSeedUniquifier: 0x330a0fc1703fe178 (took 6 ms)
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):643] - -Dio.netty.allocator.type: unpooled
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):644] - -Dio.netty.threadLocalDirectBufferSize: 65536
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:86):706] - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
[DEBUG]2016-12-29 17:25:26  [main:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):708] - \proc\sys\net\core\somaxconn: 200 (non-existent)
[DEBUG]2016-12-29 17:25:26  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):717] - Shuffle server started on port :50241
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):720] - Successfully started service 'sparkDriver' on port 50241.
[DEBUG]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):721] - Using serializer: class org.apache.spark.serializer.JavaSerializer
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):735] - Registering MapOutputTracker
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):750] - Registering BlockManagerMaster
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):877] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-a9a5a702-5d3a-480c-823a-f36d2ed750bf
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):894] - MemoryStore started with capacity 906.0 MB
[INFO ]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):967] - Registering OutputCommitCoordinator
[DEBUG]2016-12-29 17:25:26  [main:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):977] - Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:176):1031] - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):1034] - Logging initialized @1542ms
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1043] - o.s.j.s.ServletContextHandler@4044fb95{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@aa549e5,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1046] - org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1047] - org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-72758afa,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1048] - o.s.j.s.ServletContextHandler@40cb698e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3382f8ae,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1048] - org.spark_project.jetty.servlet.ServletHandler@3382f8ae added {org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1049] - org.spark_project.jetty.servlet.ServletHandler@3382f8ae added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-60641ec8,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1050] - o.s.j.s.ServletContextHandler@75390459{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7756c3cd,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1050] - org.spark_project.jetty.servlet.ServletHandler@7756c3cd added {org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1050] - org.spark_project.jetty.servlet.ServletHandler@7756c3cd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2313052e,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - o.s.j.s.ServletContextHandler@2bd2b28e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@16746061,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - org.spark_project.jetty.servlet.ServletHandler@16746061 added {org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - org.spark_project.jetty.servlet.ServletHandler@16746061 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1051] - o.s.j.s.ServletContextHandler@52045dbe{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@674658f7,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1052] - org.spark_project.jetty.servlet.ServletHandler@674658f7 added {org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1052] - org.spark_project.jetty.servlet.ServletHandler@674658f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1052] - o.s.j.s.ServletContextHandler@565b064f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@26425897,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1052] - org.spark_project.jetty.servlet.ServletHandler@26425897 added {org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1052] - org.spark_project.jetty.servlet.ServletHandler@26425897 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-73163d48,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1053] - o.s.j.s.ServletContextHandler@56a4479a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62163b39,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1053] - org.spark_project.jetty.servlet.ServletHandler@62163b39 added {org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1053] - org.spark_project.jetty.servlet.ServletHandler@62163b39 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1053] - o.s.j.s.ServletContextHandler@62f4ff3b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1698fc68,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1053] - org.spark_project.jetty.servlet.ServletHandler@1698fc68 added {org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - org.spark_project.jetty.servlet.ServletHandler@1698fc68 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-4504d271,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - o.s.j.s.ServletContextHandler@65b3a85a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@34997338,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - org.spark_project.jetty.servlet.ServletHandler@34997338 added {org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - org.spark_project.jetty.servlet.ServletHandler@34997338 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-57eda880,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - o.s.j.s.ServletContextHandler@2b5825fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53d1b9b3,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1054] - org.spark_project.jetty.servlet.ServletHandler@53d1b9b3 added {org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1055] - org.spark_project.jetty.servlet.ServletHandler@53d1b9b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2cae1042,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1057] - o.s.j.s.ServletContextHandler@788fcafb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4febb875,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1058] - org.spark_project.jetty.servlet.ServletHandler@4febb875 added {org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1058] - org.spark_project.jetty.servlet.ServletHandler@4febb875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-25e2a451,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1058] - o.s.j.s.ServletContextHandler@1698ee84{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c626be,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1058] - org.spark_project.jetty.servlet.ServletHandler@10c626be added {org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1059] - org.spark_project.jetty.servlet.ServletHandler@10c626be added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1059] - o.s.j.s.ServletContextHandler@63b1d4fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@42e3ede4,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1059] - org.spark_project.jetty.servlet.ServletHandler@42e3ede4 added {org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1059] - org.spark_project.jetty.servlet.ServletHandler@42e3ede4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1059] - o.s.j.s.ServletContextHandler@75459c75{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@183e8023,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1060] - org.spark_project.jetty.servlet.ServletHandler@183e8023 added {org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1060] - org.spark_project.jetty.servlet.ServletHandler@183e8023 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-45efc20d,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1061] - o.s.j.s.ServletContextHandler@30bcf3c1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2a3c96e3,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1061] - org.spark_project.jetty.servlet.ServletHandler@2a3c96e3 added {org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1061] - org.spark_project.jetty.servlet.ServletHandler@2a3c96e3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-15cafec7,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1061] - o.s.j.s.ServletContextHandler@5b444398{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@cb191ca,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1062] - org.spark_project.jetty.servlet.ServletHandler@cb191ca added {org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1062] - org.spark_project.jetty.servlet.ServletHandler@cb191ca added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-42f48531,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1064] - o.s.j.s.ServletContextHandler@6821ea29{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@338494fa,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1065] - org.spark_project.jetty.servlet.ServletHandler@338494fa added {org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1065] - org.spark_project.jetty.servlet.ServletHandler@338494fa added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1065] - o.s.j.s.ServletContextHandler@758c83d8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@129b4fe2,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1065] - org.spark_project.jetty.servlet.ServletHandler@129b4fe2 added {org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1065] - org.spark_project.jetty.servlet.ServletHandler@129b4fe2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1065] - o.s.j.s.ServletContextHandler@10993713{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58359ebd,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1066] - org.spark_project.jetty.servlet.ServletHandler@58359ebd added {org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1066] - org.spark_project.jetty.servlet.ServletHandler@58359ebd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1066] - o.s.j.s.ServletContextHandler@72cf2de5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2bb7bd00,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1066] - org.spark_project.jetty.servlet.ServletHandler@2bb7bd00 added {org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1066] - org.spark_project.jetty.servlet.ServletHandler@2bb7bd00 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1067] - o.s.j.s.ServletContextHandler@45c8d09f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53812a9b,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1074] - org.spark_project.jetty.servlet.ServletHandler@53812a9b added {org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1074] - org.spark_project.jetty.servlet.ServletHandler@53812a9b added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-5974109,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1075] - o.s.j.s.ServletContextHandler@502f1f4c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6f8f9349,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1075] - org.spark_project.jetty.servlet.ServletHandler@6f8f9349 added {org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1075] - org.spark_project.jetty.servlet.ServletHandler@6f8f9349 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1076] - o.s.j.s.ServletContextHandler@4fbda97b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@75f5fd58,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1079] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1079] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-f73dcd6,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1080] - o.s.j.s.ServletContextHandler@30d4b288{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1080] - org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a added {org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1080] - org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1098] - org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c mime types IncludeExclude@207ea13{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4bff1903,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62dae540}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1098] - org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c added {o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1099] - org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16 mime types IncludeExclude@654d8173{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@56c9bbd8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@630cb4a4}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1100] - org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16 added {o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1100] - org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc mime types IncludeExclude@f79a760{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@14f5da2c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@12dae582}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1101] - org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc added {o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1102] - org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29 mime types IncludeExclude@5b057c8c{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1eb6749b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@652a7737}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29 added {o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1102] - org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d mime types IncludeExclude@2bef51f2{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@650eab8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@30f5a68a}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1102] - org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d added {o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1103] - org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956 mime types IncludeExclude@4f2c9ba6{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4e28bdd1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@53f48368}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1107] - org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956 added {o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1108] - org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9 mime types IncludeExclude@f0e995e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4c37b5b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@73db4768}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1108] - org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9 added {o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1109] - org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed mime types IncludeExclude@3c435123{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@50fe837a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3a62c01e}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1109] - org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed added {o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1109] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663 mime types IncludeExclude@5ce33a58{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@78a287ed,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@546ccad7}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1110] - org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663 added {o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1110] - org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287 mime types IncludeExclude@1623134f{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7a527389,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@485a3466}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1110] - org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287 added {o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1110] - org.spark_project.jetty.servlets.gzip.GzipHandler@25748410 mime types IncludeExclude@2b43529a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4264b240,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b04476e}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1111] - org.spark_project.jetty.servlets.gzip.GzipHandler@25748410 added {o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1111] - org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a mime types IncludeExclude@6bb75258{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@c260bdc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@75e01201}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1111] - org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a added {o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1112] - org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b mime types IncludeExclude@76f7d241{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4a335fa8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3f363cf5}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1112] - org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b added {o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1112] - org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1 mime types IncludeExclude@4baf352a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1bb1fde8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@15eebbff}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1112] - org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1 added {o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1113] - org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11 mime types IncludeExclude@30990c1b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2453f95d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@44828f6b}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1113] - org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11 added {o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1113] - org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d mime types IncludeExclude@553f1d75{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6e1d8f9e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3e34ace1}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1114] - org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d added {o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1114] - org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067 mime types IncludeExclude@4f071df8{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4de41af9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@56ace400}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1114] - org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067 added {o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1114] - org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea mime types IncludeExclude@305f7627{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5d018107,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6cbcf243}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1114] - org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea added {o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1115] - org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25 mime types IncludeExclude@62435e70{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@339bf286,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@38be305c}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1115] - org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25 added {o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1115] - org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad mime types IncludeExclude@5ed731d0{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3234f74e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7bc10d84}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1116] - org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad added {o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1116] - org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372 mime types IncludeExclude@40e10ff8{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@557a1e2d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@26a4842b}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1116] - org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372 added {o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1117] - org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe mime types IncludeExclude@366ef90e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@33e01298,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@31e75d13}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1117] - org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe added {o.s.j.s.ServletContextHandler@502f1f4c{/,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1117] - org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86 mime types IncludeExclude@4b3c354a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@78fb9a67,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@73ff4fae}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1117] - org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86 added {o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlets.gzip.GzipHandler.<init>(GzipHandler.java:100):1117] - org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c mime types IncludeExclude@b968a76{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2f9a01c1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, video/x-sgi-movie, audio/mpeg, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2611b9a3}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1118] - org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c added {o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1124] - org.spark_project.jetty.server.Server@2dbf4cbd added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1133] - HttpConnectionFactory@1de5f0ef{HTTP/1.1} added {HttpConfiguration@376a312c{32768/8192,8192/8192,https://:0,[]},POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1135] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@2dbf4cbd,UNMANAGED}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1136] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1136] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1136] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@7c56e013,POJO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1136] - ServerConnector@4275c20c{null}{0.0.0.0:0} added {HttpConnectionFactory@1de5f0ef{HTTP/1.1},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1138] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af,MANAGED}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1139] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c] added {org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1139] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1139] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc] added {org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1140] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29] added {org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1140] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1140] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956] added {org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1140] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9] added {org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1140] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed] added {org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1141] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1141] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1142] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410] added {org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1142] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a] added {org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1142] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1142] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1] added {org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1142] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11] added {org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1143] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d] added {org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1143] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067] added {org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1143] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea] added {org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1143] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25] added {org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1143] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad] added {org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1144] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372] added {org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1144] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe] added {org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1146] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86] added {org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1146] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c] added {org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1147] - org.spark_project.jetty.server.Server@2dbf4cbd added {ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040},AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1149] - org.spark_project.jetty.server.Server@2dbf4cbd added {org.spark_project.jetty.server.handler.ErrorHandler@6a66a204,AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1149] - org.spark_project.jetty.server.Server@2dbf4cbd added {org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c],AUTO}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1149] - starting org.spark_project.jetty.server.Server@2dbf4cbd
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.Server.doStart(Server.java:327):1152] - jetty-9.2.z-SNAPSHOT
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1161] - starting org.spark_project.jetty.server.Server@2dbf4cbd
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1161] - starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1671ms SparkUI{STARTED,8<=8<=200,i=2,q=0}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1162] - starting org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1162] - starting org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1162] - STARTED @1671ms org.spark_project.jetty.server.handler.ErrorHandler@6a66a204
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1163] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1164] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1164] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1164] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1164] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1165] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1165] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1165] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1165] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1165] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1165] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1166] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1166] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1166] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1166] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1166] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1166] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1166] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1167] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1167] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1167] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1167] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1167] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1167] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1167] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null}]}]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1167] - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1168] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1168] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1168] - starting o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1169] - starting o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1169] - starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1170] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-72758afa from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1171] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1171] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1171] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1171] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1171] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-72758afa=org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1172] - starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1172] - STARTED @1680ms org.spark_project.jetty.servlet.ServletHandler@aa549e5
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1172] - starting org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1173] - STARTED @1682ms org.apache.spark.ui.JettyUtils$$anon$2-72758afa@93dd48ea==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1174] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@6d0b5baf for org.apache.spark.ui.JettyUtils$$anon$2-72758afa
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1174] - Started o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1683ms o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1174] - STARTED @1683ms org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1174] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1175] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1175] - starting o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1175] - starting o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1175] - starting org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1175] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1175] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1175] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1175] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1175] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1175] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-60641ec8=org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1176] - starting org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1684ms org.spark_project.jetty.servlet.ServletHandler@3382f8ae
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1176] - starting org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1684ms org.apache.spark.ui.JettyUtils$$anon$2-60641ec8@c069954e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1176] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@2a3591c5 for org.apache.spark.ui.JettyUtils$$anon$2-60641ec8
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1176] - Started o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1685ms o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1176] - STARTED @1685ms org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1176] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1176] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1177] - starting o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1177] - starting o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1177] - starting org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1177] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2313052e from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1177] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1177] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1177] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1177] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1178] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2313052e=org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1178] - starting org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1686ms org.spark_project.jetty.servlet.ServletHandler@7756c3cd
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1178] - starting org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1687ms org.apache.spark.ui.JettyUtils$$anon$2-2313052e@b70012a8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1178] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@346a361 for org.apache.spark.ui.JettyUtils$$anon$2-2313052e
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1178] - Started o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1687ms o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1178] - STARTED @1687ms org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1178] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1179] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1179] - starting o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1179] - starting o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1179] - starting org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1179] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1179] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1179] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1179] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1179] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1180] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9=org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1180] - starting org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1180] - STARTED @1689ms org.spark_project.jetty.servlet.ServletHandler@16746061
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1180] - starting org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1180] - STARTED @1689ms org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9@1f63ecfb==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1181] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@186978a6 for org.apache.spark.ui.JettyUtils$$anon$2-57fd91c9
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1181] - Started o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1181] - STARTED @1690ms o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1181] - STARTED @1690ms org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1181] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1181] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1181] - starting o.s.j.s.ServletContextHandler@52045dbe{/stages,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1181] - starting o.s.j.s.ServletContextHandler@52045dbe{/stages,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1181] - starting org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1182] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1182] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1182] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1182] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1182] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1182] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f=org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1182] - starting org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1182] - STARTED @1691ms org.spark_project.jetty.servlet.ServletHandler@674658f7
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1182] - starting org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1182] - STARTED @1691ms org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f@e89a049e==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1183] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@482d776b for org.apache.spark.ui.JettyUtils$$anon$2-5c8eee0f
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1183] - Started o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1183] - STARTED @1691ms o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1183] - STARTED @1691ms org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1183] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1183] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1183] - starting o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1183] - starting o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1183] - starting org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1183] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-73163d48 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1183] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1183] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1184] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1184] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1184] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-73163d48=org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1184] - starting org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1184] - STARTED @1693ms org.spark_project.jetty.servlet.ServletHandler@26425897
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1184] - starting org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1184] - STARTED @1693ms org.apache.spark.ui.JettyUtils$$anon$2-73163d48@be924723==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1184] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@132ddbab for org.apache.spark.ui.JettyUtils$$anon$2-73163d48
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1184] - Started o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1184] - STARTED @1693ms o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1185] - STARTED @1693ms org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1185] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1185] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1185] - starting o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1185] - starting o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1185] - starting org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1185] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1185] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1185] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1185] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1186] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1186] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e=org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1186] - starting org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1186] - STARTED @1694ms org.spark_project.jetty.servlet.ServletHandler@62163b39
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1186] - starting org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1186] - STARTED @1695ms org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e@6a92be68==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1186] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@acb0951 for org.apache.spark.ui.JettyUtils$$anon$2-20a8a64e
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1186] - Started o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1186] - STARTED @1695ms o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1186] - STARTED @1695ms org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1187] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1187] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1187] - starting o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1187] - starting o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1187] - starting org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1187] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-4504d271 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1187] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1187] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1188] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1188] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1188] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-4504d271=org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1188] - starting org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1697ms org.spark_project.jetty.servlet.ServletHandler@1698fc68
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1188] - starting org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1697ms org.apache.spark.ui.JettyUtils$$anon$2-4504d271@eeffba3a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1188] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@267f474e for org.apache.spark.ui.JettyUtils$$anon$2-4504d271
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1188] - Started o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1188] - STARTED @1697ms o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1189] - STARTED @1697ms org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1189] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1189] - starting o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1189] - starting org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1189] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-57eda880 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1189] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1189] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1189] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1189] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1189] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-57eda880=org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1190] - starting org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1698ms org.spark_project.jetty.servlet.ServletHandler@34997338
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1190] - starting org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1698ms org.apache.spark.ui.JettyUtils$$anon$2-57eda880@1dc1583d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1190] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@28276e50 for org.apache.spark.ui.JettyUtils$$anon$2-57eda880
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1190] - Started o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1699ms o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1190] - STARTED @1699ms org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1190] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1190] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1190] - starting o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1191] - starting o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1191] - starting org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1191] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1191] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1191] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1191] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1191] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1191] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2cae1042=org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1191] - starting org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1191] - STARTED @1700ms org.spark_project.jetty.servlet.ServletHandler@53d1b9b3
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1192] - starting org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1700ms org.apache.spark.ui.JettyUtils$$anon$2-2cae1042@f6d4c57f==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1192] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3efe7086 for org.apache.spark.ui.JettyUtils$$anon$2-2cae1042
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1192] - Started o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1700ms o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1192] - STARTED @1701ms org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1192] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1192] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1192] - starting o.s.j.s.ServletContextHandler@788fcafb{/storage,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1192] - starting o.s.j.s.ServletContextHandler@788fcafb{/storage,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1192] - starting org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1192] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1193] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1193] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1193] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1193] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1193] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-25e2a451=org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1193] - starting org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1193] - STARTED @1702ms org.spark_project.jetty.servlet.ServletHandler@4febb875
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1193] - starting org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1703ms org.apache.spark.ui.JettyUtils$$anon$2-25e2a451@7990b48c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1195] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@741b3bc3 for org.apache.spark.ui.JettyUtils$$anon$2-25e2a451
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1195] - Started o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1704ms o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1195] - STARTED @1704ms org.spark_project.jetty.servlets.gzip.GzipHandler@25748410
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1195] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1195] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1195] - starting o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1195] - starting o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1196] - starting org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1196] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1196] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1196] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1196] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1197] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1197] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3=org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1197] - starting org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1197] - STARTED @1705ms org.spark_project.jetty.servlet.ServletHandler@10c626be
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1197] - starting org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1197] - STARTED @1705ms org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3@4f2a4025==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1197] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@63648ee9 for org.apache.spark.ui.JettyUtils$$anon$2-2fc0cc3
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1198] - Started o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1200] - STARTED @1708ms o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1200] - STARTED @1708ms org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1200] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1200] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1200] - starting o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1200] - starting o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1200] - starting org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1200] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1201] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1201] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1201] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1201] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1201] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f=org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1201] - starting org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1201] - STARTED @1709ms org.spark_project.jetty.servlet.ServletHandler@42e3ede4
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1201] - starting org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1201] - STARTED @1709ms org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f@1ae71538==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1201] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@45be7cd5 for org.apache.spark.ui.JettyUtils$$anon$2-201b6b6f
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1202] - Started o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1202] - STARTED @1710ms o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1202] - STARTED @1710ms org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1202] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1202] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1202] - starting o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1202] - starting o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1202] - starting org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1202] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1203] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1203] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1203] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1203] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1203] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-45efc20d=org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1203] - starting org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1203] - STARTED @1711ms org.spark_project.jetty.servlet.ServletHandler@183e8023
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1204] - starting org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1204] - STARTED @1712ms org.apache.spark.ui.JettyUtils$$anon$2-45efc20d@4c30b552==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1204] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3185fa6b for org.apache.spark.ui.JettyUtils$$anon$2-45efc20d
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1204] - Started o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1204] - STARTED @1712ms o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1205] - STARTED @1714ms org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1206] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1206] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1206] - starting o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1206] - starting o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1206] - starting org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1206] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1206] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1206] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1207] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1207] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1207] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-15cafec7=org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1207] - starting org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1207] - STARTED @1715ms org.spark_project.jetty.servlet.ServletHandler@2a3c96e3
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1207] - starting org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1208] - STARTED @1716ms org.apache.spark.ui.JettyUtils$$anon$2-15cafec7@10df2a82==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1208] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@5b58ed3c for org.apache.spark.ui.JettyUtils$$anon$2-15cafec7
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1208] - Started o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1208] - STARTED @1716ms o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1208] - STARTED @1716ms org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1208] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1208] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1208] - starting o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1208] - starting o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1208] - starting org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1209] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-42f48531 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1209] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1209] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1209] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1209] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1209] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-42f48531=org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1209] - starting org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1209] - STARTED @1718ms org.spark_project.jetty.servlet.ServletHandler@cb191ca
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1210] - starting org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1210] - STARTED @1718ms org.apache.spark.ui.JettyUtils$$anon$2-42f48531@ac5ec474==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1210] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@3a320ade for org.apache.spark.ui.JettyUtils$$anon$2-42f48531
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1210] - Started o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1210] - STARTED @1718ms o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1210] - STARTED @1718ms org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1210] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1210] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1210] - starting o.s.j.s.ServletContextHandler@6821ea29{/executors,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1211] - starting o.s.j.s.ServletContextHandler@6821ea29{/executors,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1211] - starting org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1211] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1211] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1211] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1211] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1211] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1211] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c=org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1211] - starting org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1211] - STARTED @1720ms org.spark_project.jetty.servlet.ServletHandler@338494fa
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1212] - starting org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1212] - STARTED @1720ms org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c@59514b8b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1213] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7813cb11 for org.apache.spark.ui.JettyUtils$$anon$2-505a9d7c
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1213] - Started o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1213] - STARTED @1721ms o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1213] - STARTED @1721ms org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1213] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1213] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1213] - starting o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1213] - starting o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1213] - starting org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1213] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1213] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1214] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1214] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1214] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1214] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f=org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1214] - starting org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1214] - STARTED @1722ms org.spark_project.jetty.servlet.ServletHandler@129b4fe2
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1214] - starting org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1214] - STARTED @1722ms org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f@e5804cf1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1214] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@21005f6c for org.apache.spark.ui.JettyUtils$$anon$2-5af3a0f
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1215] - Started o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1215] - STARTED @1723ms o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1215] - STARTED @1723ms org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1215] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1215] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1215] - starting o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1215] - starting o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1216] - starting org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1216] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1216] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1216] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1216] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1216] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1216] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6=org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1216] - starting org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1216] - STARTED @1724ms org.spark_project.jetty.servlet.ServletHandler@58359ebd
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1216] - starting org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1216] - STARTED @1725ms org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6@3fc4d6c9==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1217] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@545de5a4 for org.apache.spark.ui.JettyUtils$$anon$2-24b6b8f6
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1217] - Started o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1217] - STARTED @1725ms o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1217] - STARTED @1725ms org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1217] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1217] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1217] - starting o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1217] - starting o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1217] - starting org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1217] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1217] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1218] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1218] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1218] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1218] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd=org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1218] - starting org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1218] - STARTED @1726ms org.spark_project.jetty.servlet.ServletHandler@2bb7bd00
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1218] - starting org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1218] - STARTED @1726ms org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd@76cdbcf7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1218] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@ab7a938 for org.apache.spark.ui.JettyUtils$$anon$2-5f031ebd
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1218] - Started o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1218] - STARTED @1727ms o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1219] - STARTED @1727ms org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1219] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1219] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1219] - starting o.s.j.s.ServletContextHandler@45c8d09f{/static,null,null}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1220] - starting o.s.j.s.ServletContextHandler@45c8d09f{/static,null,STARTING}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1220] - starting org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1220] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-5974109 from default=false
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1220] - filterNameMap={}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1220] - pathFilters=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1220] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1221] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1221] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-5974109=org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1221] - starting org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1221] - STARTED @1730ms org.spark_project.jetty.servlet.ServletHandler@53812a9b
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1222] - starting org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1222] - STARTED @1730ms org.spark_project.jetty.servlet.DefaultServlet-5974109@ea4ebea==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1222] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@4648ce9 for org.spark_project.jetty.servlet.DefaultServlet-5974109
[DEBUG]2016-12-29 17:25:26  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1228] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-core_2.11-2.0.0.jar!/org/apache/spark/ui/static
[INFO ]2016-12-29 17:25:26  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1228] - Started o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1229] - STARTED @1737ms o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1229] - STARTED @1737ms org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1229] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1230] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1230] - starting o.s.j.s.ServletContextHandler@502f1f4c{/,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1230] - starting o.s.j.s.ServletContextHandler@502f1f4c{/,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1230] - starting org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1230] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1230] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1230] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1230] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1230] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1231] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b=org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1231] - starting org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1231] - STARTED @1739ms org.spark_project.jetty.servlet.ServletHandler@6f8f9349
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1231] - starting org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1231] - STARTED @1739ms org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b@723ad65e==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1231] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@305f031 for org.apache.spark.ui.JettyUtils$$anon$3-75c9e76b
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1231] - Started o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1231] - STARTED @1739ms o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1232] - STARTED @1740ms org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1232] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1232] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1232] - starting o.s.j.s.ServletContextHandler@4fbda97b{/api,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1232] - starting o.s.j.s.ServletContextHandler@4fbda97b{/api,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1232] - starting org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1232] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-f73dcd6 from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1232] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1233] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1233] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1233] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1233] - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-f73dcd6=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.doStart(ServletHandler.java:165):1233] - Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1235] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1235] - org.spark_project.jetty.servlet.ServletHandler@75f5fd58 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5,POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1235] - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-f73dcd6 from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1235] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5 from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1235] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1235] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1235] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1236] - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1236] - servletNameMap={org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false, org.glassfish.jersey.servlet.ServletContainer-f73dcd6=org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1236] - starting org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1236] - STARTED @1744ms org.spark_project.jetty.servlet.ServletHandler@75f5fd58
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1236] - starting org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1236] - STARTED @1744ms org.glassfish.jersey.servlet.ServletContainer-f73dcd6@e6ee7385==org.glassfish.jersey.servlet.ServletContainer,-1,false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1236] - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1236] - STARTED @1744ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e16b8b5@b2959081==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1236] - Started o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1237] - STARTED @1745ms o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1237] - STARTED @1745ms org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1237] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1237] - starting org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1237] - starting o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1237] - starting o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1237] - starting org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1237] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1237] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1237] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1238] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1238] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1238] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b=org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1238] - starting org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1238] - STARTED @1746ms org.spark_project.jetty.servlet.ServletHandler@4cc6fa2a
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1238] - starting org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1238] - STARTED @1746ms org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b@36c54447==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1238] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1536602f for org.apache.spark.ui.JettyUtils$$anon$3-40f1be1b
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1238] - Started o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1238] - STARTED @1747ms o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1239] - STARTED @1747ms org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1239] - STARTED @1747ms org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1239] - starting ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1239] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1240] - starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1240] - STARTED @1748ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51850751
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1240] - starting HttpConnectionFactory@1de5f0ef{HTTP/1.1}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1240] - STARTED @1748ms HttpConnectionFactory@1de5f0ef{HTTP/1.1}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1240] - starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1243] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=-1 selected=-1
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1245] - STARTED @1753ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=0 selected=0
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1246] - starting org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=-1 selected=-1
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1247] - STARTED @1755ms org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=0 selected=0
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1248] - STARTED @1756ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@16f7b4af
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1249] - ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040} added {acceptor-0@36b0fcd5,POJO}
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):1250] - Started ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1250] - STARTED @1758ms ServerConnector@4275c20c{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.Server.doStart(Server.java:379):1253] - Started @1758ms
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1253] - STARTED @1761ms org.spark_project.jetty.server.Server@2dbf4cbd
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1253] - Successfully started service 'SparkUI' on port 4040.
[DEBUG]2016-12-29 17:25:27  [SparkUI-35-selector-ServerConnectorManager@16f7b4af/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1255] - Starting Thread[SparkUI-35-selector-ServerConnectorManager@16f7b4af/0,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@649725e3 keys=0 selected=0
[DEBUG]2016-12-29 17:25:27  [SparkUI-37-selector-ServerConnectorManager@16f7b4af/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.run(SelectorManager.java:548):1256] - Starting Thread[SparkUI-37-selector-ServerConnectorManager@16f7b4af/1,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@52b56a3e keys=0 selected=0
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1259] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[DEBUG]2016-12-29 17:25:27  [SparkUI-35-selector-ServerConnectorManager@16f7b4af/0:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1303] - Selector loop waiting on select
[DEBUG]2016-12-29 17:25:27  [SparkUI-37-selector-ServerConnectorManager@16f7b4af/1:org.spark_project.jetty.io.SelectorManager$ManagedSelector.select(SelectorManager.java:600):1304] - Selector loop waiting on select
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1365] - Starting executor ID driver on host localhost
[DEBUG]2016-12-29 17:25:27  [main:org.apache.spark.network.server.TransportServer.init(TransportServer.java:133):1389] - Shuffle server started on port :50250
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1389] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50250.
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1390] - Server created on 172.18.10.41:50250
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1391] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 50250)
[INFO ]2016-12-29 17:25:27  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1393] - Registering block manager 172.18.10.41:50250 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 50250)
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1395] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 50250)
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1517] - o.s.j.s.ServletContextHandler@9fecdf1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3b809711,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1517] - org.spark_project.jetty.servlet.ServletHandler@3b809711 added {org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d@d643d66a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1518] - org.spark_project.jetty.servlet.ServletHandler@3b809711 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d,POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1519] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,null}] added {o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1520] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1521] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1522] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1523] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1524] - metrics/json->[{o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,null},[o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,null}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1524] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1524] - starting o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1524] - starting o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1524] - starting org.spark_project.jetty.servlet.ServletHandler@3b809711
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1524] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1524] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1524] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1524] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1524] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d@d643d66a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1525] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d=org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d@d643d66a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1525] - starting org.spark_project.jetty.servlet.ServletHandler@3b809711
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1525] - STARTED @2033ms org.spark_project.jetty.servlet.ServletHandler@3b809711
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1525] - starting org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d@d643d66a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1525] - STARTED @2033ms org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d@d643d66a==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1525] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@71ea1fda for org.apache.spark.ui.JettyUtils$$anon$2-3b0f7d9d
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1525] - Started o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1525] - STARTED @2033ms o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}
[WARN ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):1552] - Use an existing SparkContext, some configuration may not take effect.
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1581] - o.s.j.s.ServletContextHandler@2d140a7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@347bdeef,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1583] - org.spark_project.jetty.servlet.ServletHandler@347bdeef added {org.apache.spark.ui.JettyUtils$$anon$2-2aa27288@8a3c6288==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1583] - org.spark_project.jetty.servlet.ServletHandler@347bdeef added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2aa27288,POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1583] - o.s.j.s.ServletContextHandler@7f34a967{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77e80a5e,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1584] - org.spark_project.jetty.servlet.ServletHandler@77e80a5e added {org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea@7de463dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1584] - org.spark_project.jetty.servlet.ServletHandler@77e80a5e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea,POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1584] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,null}] added {o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1584] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1584] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1585] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1586] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1587] - SQL->[{o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,null},[o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,null}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1587] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1587] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1588] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1588] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1588] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1588] - metrics/json->[{o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1589] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1589] - starting o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1589] - starting o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1589] - starting org.spark_project.jetty.servlet.ServletHandler@347bdeef
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1590] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2aa27288 from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1590] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1590] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1590] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1590] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-2aa27288@8a3c6288==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1590] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2aa27288=org.apache.spark.ui.JettyUtils$$anon$2-2aa27288@8a3c6288==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1590] - starting org.spark_project.jetty.servlet.ServletHandler@347bdeef
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1590] - STARTED @2098ms org.spark_project.jetty.servlet.ServletHandler@347bdeef
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1590] - starting org.apache.spark.ui.JettyUtils$$anon$2-2aa27288@8a3c6288==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1591] - STARTED @2099ms org.apache.spark.ui.JettyUtils$$anon$2-2aa27288@8a3c6288==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1591] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@7ea4d397 for org.apache.spark.ui.JettyUtils$$anon$2-2aa27288
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1591] - Started o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1591] - STARTED @2099ms o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1593] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,null}] added {o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1594] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1595] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1595] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1595] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1595] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1596] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1596] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1596] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1596] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1596] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1596] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1596] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1597] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1599] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1599] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1599] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1600] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1600] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1600] - SQL->[{o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1600] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1600] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1600] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1600] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1601] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1601] - SQL/json->[{o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,null},[o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,null}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1601] - metrics/json->[{o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1601] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1601] - starting o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1602] - starting o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1602] - starting org.spark_project.jetty.servlet.ServletHandler@77e80a5e
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1602] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1602] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1602] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1602] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1605] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea@7de463dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1605] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea=org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea@7de463dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1605] - starting org.spark_project.jetty.servlet.ServletHandler@77e80a5e
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1605] - STARTED @2113ms org.spark_project.jetty.servlet.ServletHandler@77e80a5e
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1605] - starting org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea@7de463dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1606] - STARTED @2114ms org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea@7de463dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1606] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@253c1256 for org.apache.spark.ui.JettyUtils$$anon$2-1d8e2eea
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1606] - Started o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1606] - STARTED @2114ms o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1606] - o.s.j.s.ServletContextHandler@503fbbc6{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@55f45b92,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1606] - org.spark_project.jetty.servlet.ServletHandler@55f45b92 added {org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8@c0e4a3dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1607] - org.spark_project.jetty.servlet.ServletHandler@55f45b92 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8,POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1607] - o.s.j.s.ServletContextHandler@67fe380b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a325eb9,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1607] - org.spark_project.jetty.servlet.ServletHandler@4a325eb9 added {org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6@9a77d344==org.apache.spark.ui.JettyUtils$$anon$2,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1607] - org.spark_project.jetty.servlet.ServletHandler@4a325eb9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6,POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1608] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,null}] added {o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1609] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1609] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1609] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1609] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1609] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1609] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1609] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1610] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - SQL->[{o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1611] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - SQL/json->[{o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - metrics/json->[{o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - SQL/execution->[{o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,null},[o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,null}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1612] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1612] - starting o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1612] - starting o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1612] - starting org.spark_project.jetty.servlet.ServletHandler@55f45b92
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1613] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8 from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1613] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1613] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1613] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1613] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8@c0e4a3dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1613] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8=org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8@c0e4a3dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1613] - starting org.spark_project.jetty.servlet.ServletHandler@55f45b92
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1613] - STARTED @2122ms org.spark_project.jetty.servlet.ServletHandler@55f45b92
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1614] - starting org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8@c0e4a3dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1614] - STARTED @2122ms org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8@c0e4a3dc==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1614] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@415e0bcb for org.apache.spark.ui.JettyUtils$$anon$2-109f5dd8
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1614] - Started o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1614] - STARTED @2122ms o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1614] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,null}] added {o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1615] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1615] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1615] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,null},[o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,null}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1616] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - SQL->[{o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1617] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - SQL/json->[{o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - metrics/json->[{o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1618] - SQL/execution->[{o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1619] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1619] - starting o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1619] - starting o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1619] - starting org.spark_project.jetty.servlet.ServletHandler@4a325eb9
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1619] - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6 from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1620] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1620] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1620] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1620] - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6@9a77d344==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1620] - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6=org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6@9a77d344==org.apache.spark.ui.JettyUtils$$anon$2,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1620] - starting org.spark_project.jetty.servlet.ServletHandler@4a325eb9
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1620] - STARTED @2128ms org.spark_project.jetty.servlet.ServletHandler@4a325eb9
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1620] - starting org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6@9a77d344==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1620] - STARTED @2128ms org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6@9a77d344==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1620] - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@49d98dc5 for org.apache.spark.ui.JettyUtils$$anon$2-3dedb4a6
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1621] - Started o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1621] - STARTED @2129ms o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1621] - o.s.j.s.ServletContextHandler@bf71cec{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@22d6cac2,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1622] - org.spark_project.jetty.servlet.ServletHandler@22d6cac2 added {org.spark_project.jetty.servlet.DefaultServlet-30cdae70@67ee5e8a==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1622] - org.spark_project.jetty.servlet.ServletHandler@22d6cac2 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-30cdae70,POJO}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.ContainerLifeCycle.addBean(ContainerLifeCycle.java:324):1623] - org.spark_project.jetty.server.handler.ContextHandlerCollection@71ae31b0[org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c, org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16, org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc, org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29, org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d, org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956, org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9, org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed, org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663, org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287, org.spark_project.jetty.servlets.gzip.GzipHandler@25748410, org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a, org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b, org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1, org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11, org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d, org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067, org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea, org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25, org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad, org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372, org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe, org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86, org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c, o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}, o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE}, o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,AVAILABLE}, o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,null}] added {o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,null},UNMANAGED}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1624] - ->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7e38a7fe,[o.s.j.s.ServletContextHandler@502f1f4c{/,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1624] - storage/rdd->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2783717b,[o.s.j.s.ServletContextHandler@63b1d4fa{/storage/rdd,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1624] - storage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@25748410,[o.s.j.s.ServletContextHandler@788fcafb{/storage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1624] - storage/rdd/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@3829ac1,[o.s.j.s.ServletContextHandler@75459c75{/storage/rdd/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1624] - SQL/execution/json->[{o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@67fe380b{/SQL/execution/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1624] - api->[{org.spark_project.jetty.servlets.gzip.GzipHandler@a5b0b86,[o.s.j.s.ServletContextHandler@4fbda97b{/api,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1624] - stages/pool/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5357c287,[o.s.j.s.ServletContextHandler@2b5825fa{/stages/pool/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1625] - stages/pool->[{org.spark_project.jetty.servlets.gzip.GzipHandler@7a8fa663,[o.s.j.s.ServletContextHandler@65b3a85a{/stages/pool,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1625] - jobs/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5827af16,[o.s.j.s.ServletContextHandler@40cb698e{/jobs/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1625] - static->[{org.spark_project.jetty.servlets.gzip.GzipHandler@275fe372,[o.s.j.s.ServletContextHandler@45c8d09f{/static,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1626] - executors/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@47404bea,[o.s.j.s.ServletContextHandler@758c83d8{/executors/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1626] - stages/stage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@150ab4ed,[o.s.j.s.ServletContextHandler@62f4ff3b{/stages/stage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1626] - executors/threadDump/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@269f4bad,[o.s.j.s.ServletContextHandler@72cf2de5{/executors/threadDump/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1626] - environment/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@2dbe250d,[o.s.j.s.ServletContextHandler@5b444398{/environment/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1626] - jobs/job/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@619bfe29,[o.s.j.s.ServletContextHandler@2bd2b28e{/jobs/job/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1626] - jobs->[{org.spark_project.jetty.servlets.gzip.GzipHandler@45cff11c,[o.s.j.s.ServletContextHandler@4044fb95{/jobs,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - stages/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@1e1d3956,[o.s.j.s.ServletContextHandler@565b064f{/stages/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - stages/stage->[{org.spark_project.jetty.servlets.gzip.GzipHandler@24d4d7c9,[o.s.j.s.ServletContextHandler@56a4479a{/stages/stage,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - storage/json->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5ad10c1a,[o.s.j.s.ServletContextHandler@1698ee84{/storage/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - SQL->[{o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE},[o.s.j.s.ServletContextHandler@2d140a7{/SQL,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - static/sql->[{o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,null},[o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,null}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - stages/stage/kill->[{org.spark_project.jetty.servlets.gzip.GzipHandler@21aa6d6c,[o.s.j.s.ServletContextHandler@30d4b288{/stages/stage/kill,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - environment->[{org.spark_project.jetty.servlets.gzip.GzipHandler@22d6f11,[o.s.j.s.ServletContextHandler@30bcf3c1{/environment,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - jobs/job->[{org.spark_project.jetty.servlets.gzip.GzipHandler@636e8cc,[o.s.j.s.ServletContextHandler@75390459{/jobs/job,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - stages->[{org.spark_project.jetty.servlets.gzip.GzipHandler@5b7ea70d,[o.s.j.s.ServletContextHandler@52045dbe{/stages,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1627] - executors->[{org.spark_project.jetty.servlets.gzip.GzipHandler@62fe6067,[o.s.j.s.ServletContextHandler@6821ea29{/executors,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1628] - SQL/json->[{o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@7f34a967{/SQL/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1628] - metrics/json->[{o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE},[o.s.j.s.ServletContextHandler@9fecdf1{/metrics/json,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1628] - SQL/execution->[{o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE},[o.s.j.s.ServletContextHandler@503fbbc6{/SQL/execution,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandlerCollection.mapContexts(ContextHandlerCollection.java:141):1628] - executors/threadDump->[{org.spark_project.jetty.servlets.gzip.GzipHandler@29e6eb25,[o.s.j.s.ServletContextHandler@10993713{/executors/threadDump,null,AVAILABLE}]}]
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1628] - starting o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,null}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1628] - starting o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,STARTING}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1628] - starting org.spark_project.jetty.servlet.ServletHandler@22d6cac2
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1495):1628] - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-30cdae70 from default=false
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1516):1628] - filterNameMap={}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1517):1628] - pathFilters=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1518):1628] - servletFilterMap=null
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1519):1629] - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-30cdae70@67ee5e8a==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHandler.updateMappings(ServletHandler.java:1520):1629] - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-30cdae70=org.spark_project.jetty.servlet.DefaultServlet-30cdae70@67ee5e8a==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58):1629] - starting org.spark_project.jetty.servlet.ServletHandler@22d6cac2
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1629] - STARTED @2137ms org.spark_project.jetty.servlet.ServletHandler@22d6cac2
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarting(AbstractLifeCycle.java:185):1629] - starting org.spark_project.jetty.servlet.DefaultServlet-30cdae70@67ee5e8a==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1629] - STARTED @2137ms org.spark_project.jetty.servlet.DefaultServlet-30cdae70@67ee5e8a==org.spark_project.jetty.servlet.DefaultServlet,-1,true
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:615):1629] - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@2577d6c8 for org.spark_project.jetty.servlet.DefaultServlet-30cdae70
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.servlet.DefaultServlet.init(DefaultServlet.java:311):1630] - resource base = jar:file:/E:/TangDocs/%e5%ae%89%e8%a3%85%e5%8c%85/BigData/Spark/spark-2.0.0-bin-hadoop2.7/spark-2.0.0-bin-hadoop2.7/jars/spark-sql_2.11-2.0.0.jar!/org/apache/spark/sql/execution/ui/static
[INFO ]2016-12-29 17:25:27  [main:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):1630] - Started o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,AVAILABLE}
[DEBUG]2016-12-29 17:25:27  [main:org.spark_project.jetty.util.component.AbstractLifeCycle.setStarted(AbstractLifeCycle.java:177):1630] - STARTED @2138ms o.s.j.s.ServletContextHandler@bf71cec{/static/sql,null,AVAILABLE}
[INFO ]2016-12-29 17:25:27  [main:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):1642] - Warehouse path is 'd:/path/to/my/'.
[INFO ]2016-12-29 17:25:27  [main:com.pujjr.antifraud.http.AntiFraudHttpServer.run(AntiFraudHttpServer.java:42):1656] - 服务启动成功，监听端口：10080
[DEBUG]2016-12-29 17:25:31  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:81):5422] - -Dio.netty.leakDetectionLevel: simple
[DEBUG]2016-12-29 17:25:31  [nioEventLoopGroup-3-1:io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76):5439] - -Dio.netty.recycler.maxCapacity.default: 262144
[DEBUG]2016-12-29 17:25:31  [nioEventLoopGroup-3-1:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):5455] - uri:/antifraud
[INFO ]2016-12-29 17:25:31  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):5459] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:25:31  [nioEventLoopGroup-3-1:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):5513] - Rdd服务
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7338] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#6: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#6: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#0, name#1, sex#2]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#0, name#1, sex#2]
        
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7359] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#7: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#0.toString, name#1.toString, sex#2.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#7: org.apache.spark.sql.Row
 +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#0,name#1,sex#2] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7645] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7705] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[INFO ]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7826] - Code generated in 159.671105 ms
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7833] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7848] -  + declared fields: 4
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7849] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7849] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7849] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7849] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7850] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7850] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7850] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7851] -  + inner classes: 1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7851] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7852] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7852] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7854] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7859] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7860] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7861] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7883] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -  + inner classes: 1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7885] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7886] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7886] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7887] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7887] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7887] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7896] -  + declared fields: 1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7897] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7898] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7898] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7898] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7899] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7900] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7901] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7902] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7902] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7902] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:25:33  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7903] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7916] - Got job 0 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7917] - Final stage: ResultStage 0 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7917] - Parents of final stage: List()
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7919] - Missing parents: List()
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7921] - submitStage(ResultStage 0)
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7922] - missing: List()
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):7924] - Submitting ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):7925] - submitMissingTasks(ResultStage 0)
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8027] - Block broadcast_0 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8029] - Put block broadcast_0 locally took  53 ms
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8030] - Putting block broadcast_0 without replication took  54 ms
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8072] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:25:33  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8074] - Added broadcast_0_piece0 in memory on 172.18.10.41:50250 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8075] - Updated info of block broadcast_0_piece0
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8075] - Told master about block broadcast_0_piece0
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8076] - Put block broadcast_0_piece0 locally took  6 ms
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8076] - Putting block broadcast_0_piece0 without replication took  6 ms
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8077] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8080] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8081] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8082] - Adding task set 0.0 with 1 tasks
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8086] - Epoch for TaskSet 0.0: 0
[DEBUG]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8088] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:25:33  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8098] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:25:33  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8099] - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
[INFO ]2016-12-29 17:25:33  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8117] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8123] - Running task 0.0 in stage 0.0 (TID 0)
[DEBUG]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8133] - Task 0's epoch is 0
[DEBUG]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8136] - Getting local block broadcast_0
[DEBUG]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8137] - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8178] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[DEBUG]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8183] - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8195] - Code generated in 16.297318 ms
[INFO ]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8199] - closed connection
[INFO ]2016-12-29 17:25:33  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8211] - Finished task 0.0 in stage 0.0 (TID 0). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:25:33  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8213] - parentName: , name: TaskSet_0, runningTasks: 0
[DEBUG]2016-12-29 17:25:33  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8216] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:25:33  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8219] - Finished task 0.0 in stage 0.0 (TID 0) in 118 ms on localhost (1/1)
[INFO ]2016-12-29 17:25:33  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8220] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:25:33  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8223] - ResultStage 0 (count at RddServiceImpl.java:85) finished in 0.131 s
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8323] - After removal of stage 0, remaining stages = 0
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8324] - Job 0 finished: count at RddServiceImpl.java:85, took 0.420983 s
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8326] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8327] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8327] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8327] -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8327] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8327] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8327] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8327] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8328] -  + outer classes: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8328] -      org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8328] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8328] -  + outer objects: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8328] -      <function0>
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8329] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8329] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8330] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8331] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8331] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8332] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8332] -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8333] -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8334] - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -  + inner classes: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -  + outer classes: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -  + outer objects: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8335] -      MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8336] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8336] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8336] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8336] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8336] -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8336] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8338] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8339] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8340] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8340] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8340] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8340] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8340] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8342] - Starting job: collect at RddServiceImpl.java:86
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8342] - Got job 1 (collect at RddServiceImpl.java:86) with 1 output partitions
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8343] - Final stage: ResultStage 1 (collect at RddServiceImpl.java:86)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8343] - Parents of final stage: List()
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8343] - Missing parents: List()
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8343] - submitStage(ResultStage 1)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8343] - missing: List()
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8343] - Submitting ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8343] - submitMissingTasks(ResultStage 1)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8345] - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8345] - Put block broadcast_1 locally took  0 ms
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8346] - Putting block broadcast_1 without replication took  1 ms
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8347] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:25:34  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8350] - Added broadcast_1_piece0 in memory on 172.18.10.41:50250 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8351] - Updated info of block broadcast_1_piece0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8351] - Told master about block broadcast_1_piece0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8351] - Put block broadcast_1_piece0 locally took  4 ms
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8351] - Putting block broadcast_1_piece0 without replication took  4 ms
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8351] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8351] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8351] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8351] - Adding task set 1.0 with 1 tasks
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8352] - Epoch for TaskSet 1.0: 0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8352] - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8352] - parentName: , name: TaskSet_1, runningTasks: 0
[INFO ]2016-12-29 17:25:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8353] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5168 bytes)
[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8353] - Running task 0.0 in stage 1.0 (TID 1)
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8355] - Task 1's epoch is 0
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8355] - Getting local block broadcast_1
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8355] - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8371] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8371] - closed connection
[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8373] - Finished task 0.0 in stage 1.0 (TID 1). 2526 bytes result sent to driver
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8374] - parentName: , name: TaskSet_1, runningTasks: 0
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8374] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:25:34  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8376] - Finished task 0.0 in stage 1.0 (TID 1) in 23 ms on localhost (1/1)
[INFO ]2016-12-29 17:25:34  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8376] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8376] - ResultStage 1 (collect at RddServiceImpl.java:86) finished in 0.024 s
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8377] - After removal of stage 1, remaining stages = 0
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8377] - Job 1 finished: collect at RddServiceImpl.java:86, took 0.035558 s
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8380] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8380] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8381] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8382] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8382] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8382] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:com.pujjr.antifraud.http.AntiFraudHttpServerInboundHandler.channelRead(AntiFraudHttpServerInboundHandler.java:59):8391] - uri:/antifraud
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.ReceiverServiceImpl.doReceive(ReceiverServiceImpl.java:26):8391] - receive from client：{"tranCode":"10001","appId":"00011611030300N2"}
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:com.pujjr.antifraud.service.impl.RddServiceImpl.selectCurr(RddServiceImpl.java:30):8391] - Rdd服务
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8407] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#14: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#14: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [userid#8, name#9, sex#10]                                                                                                                                                                                                                                                                                             +- LocalRelation <empty>, [userid#8, name#9, sex#10]
        
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8411] - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true))), obj#15: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(userid#8.toString, name#9.toString, sex#10.toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)), obj#15: org.apache.spark.sql.Row
 +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)                                                                                                                                                                                                                                                                                    +- Relation[userid#8,name#9,sex#10] JDBCRelation(t_user_test)
        
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8417] - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private org.apache.spark.sql.execution.metric.SQLMetric scan_numOutputRows;
/* 008 */   private scala.collection.Iterator scan_input;
/* 009 */   private UnsafeRow scan_result;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder scan_holder;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter scan_rowWriter;
/* 012 */
/* 013 */   public GeneratedIterator(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator inputs[]) {
/* 018 */     partitionIndex = index;
/* 019 */     this.scan_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[0];
/* 020 */     scan_input = inputs[0];
/* 021 */     scan_result = new UnsafeRow(3);
/* 022 */     this.scan_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(scan_result, 96);
/* 023 */     this.scan_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(scan_holder, 3);
/* 024 */   }
/* 025 */
/* 026 */   protected void processNext() throws java.io.IOException {
/* 027 */     while (scan_input.hasNext()) {
/* 028 */       InternalRow scan_row = (InternalRow) scan_input.next();
/* 029 */       scan_numOutputRows.add(1);
/* 030 */       boolean scan_isNull = scan_row.isNullAt(0);
/* 031 */       UTF8String scan_value = scan_isNull ? null : (scan_row.getUTF8String(0));
/* 032 */       boolean scan_isNull1 = scan_row.isNullAt(1);
/* 033 */       UTF8String scan_value1 = scan_isNull1 ? null : (scan_row.getUTF8String(1));
/* 034 */       boolean scan_isNull2 = scan_row.isNullAt(2);
/* 035 */       UTF8String scan_value2 = scan_isNull2 ? null : (scan_row.getUTF8String(2));
/* 036 */       scan_holder.reset();
/* 037 */
/* 038 */       scan_rowWriter.zeroOutNullBytes();
/* 039 */
/* 040 */       if (scan_isNull) {
/* 041 */         scan_rowWriter.setNullAt(0);
/* 042 */       } else {
/* 043 */         scan_rowWriter.write(0, scan_value);
/* 044 */       }
/* 045 */
/* 046 */       if (scan_isNull1) {
/* 047 */         scan_rowWriter.setNullAt(1);
/* 048 */       } else {
/* 049 */         scan_rowWriter.write(1, scan_value1);
/* 050 */       }
/* 051 */
/* 052 */       if (scan_isNull2) {
/* 053 */         scan_rowWriter.setNullAt(2);
/* 054 */       } else {
/* 055 */         scan_rowWriter.write(2, scan_value2);
/* 056 */       }
/* 057 */       scan_result.setTotalSize(scan_holder.totalSize());
/* 058 */       append(scan_result);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */ }

[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8418] - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -  + declared fields: 4
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.cleanedSource$2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.references$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.durationMs$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(int,scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8420] -  + inner classes: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8421] -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8421] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8421] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8421] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8423] -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8425] - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      public static final long org.apache.spark.sql.Dataset$$anonfun$52.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$52.objectType$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$52.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$52.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + inner classes: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -      org.apache.spark.sql.Dataset$$anonfun$52$$anonfun$apply$20
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8426] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8427] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8428] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8428] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8428] -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$52) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8429] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -  + declared fields: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8430] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8435] -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8436] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8436] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8436] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8436] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8437] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8437] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8437] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8437] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8438] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8439] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8439] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8439] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8439] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8439] - Starting job: count at RddServiceImpl.java:85
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8440] - Got job 2 (count at RddServiceImpl.java:85) with 1 output partitions
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8440] - Final stage: ResultStage 2 (count at RddServiceImpl.java:85)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8440] - Parents of final stage: List()
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8440] - Missing parents: List()
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8441] - submitStage(ResultStage 2)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8441] - missing: List()
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8441] - Submitting ResultStage 2 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8441] - submitMissingTasks(ResultStage 2)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8443] - Block broadcast_2 stored as values in memory (estimated size 11.2 KB, free 906.0 MB)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8444] - Put block broadcast_2 locally took  1 ms
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8445] - Putting block broadcast_2 without replication took  2 ms
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8446] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KB, free 906.0 MB)
[INFO ]2016-12-29 17:25:34  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8447] - Added broadcast_2_piece0 in memory on 172.18.10.41:50250 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8448] - Updated info of block broadcast_2_piece0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8448] - Told master about block broadcast_2_piece0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8448] - Put block broadcast_2_piece0 locally took  2 ms
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8448] - Putting block broadcast_2_piece0 without replication took  2 ms
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8449] - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8449] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8449] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8449] - Adding task set 2.0 with 1 tasks
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8449] - Epoch for TaskSet 2.0: 0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8449] - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8450] - parentName: , name: TaskSet_2, runningTasks: 0
[INFO ]2016-12-29 17:25:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8451] - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8452] - Running task 0.0 in stage 2.0 (TID 2)
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8453] - Task 2's epoch is 0
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8454] - Getting local block broadcast_2
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8454] - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8471] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8474] - closed connection
[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8475] - Finished task 0.0 in stage 2.0 (TID 2). 1181 bytes result sent to driver
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8478] - parentName: , name: TaskSet_2, runningTasks: 0
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8479] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:25:34  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8479] - Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (1/1)
[INFO ]2016-12-29 17:25:34  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8479] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8480] - ResultStage 2 (count at RddServiceImpl.java:85) finished in 0.031 s
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8480] - After removal of stage 2, remaining stages = 0
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8480] - Job 2 finished: count at RddServiceImpl.java:85, took 0.041033 s
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8481] - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8482] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8482] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8482] -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8482] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8482] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -  + outer classes: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -      org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -  + outer objects: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -      <function0>
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -      MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8483] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8484] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8484] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8484] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8484] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8485] - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  + inner classes: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -  + outer classes: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8486] -      org.apache.spark.rdd.RDD
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8487] -  + outer objects: 1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8487] -      MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8487] -  + fields accessed by starting closure: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8487] -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8487] -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8487] -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8488] -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8488] -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8489] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8490] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8490] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8490] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8490] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8490] -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8491] - Starting job: collect at RddServiceImpl.java:86
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8491] - Got job 3 (collect at RddServiceImpl.java:86) with 1 output partitions
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8492] - Final stage: ResultStage 3 (collect at RddServiceImpl.java:86)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8492] - Parents of final stage: List()
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8492] - Missing parents: List()
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8492] - submitStage(ResultStage 3)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8492] - missing: List()
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8492] - Submitting ResultStage 3 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84), which has no missing parents
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8492] - submitMissingTasks(ResultStage 3)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8493] - Block broadcast_3 stored as values in memory (estimated size 11.3 KB, free 905.9 MB)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8499] - Put block broadcast_3 locally took  6 ms
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8499] - Putting block broadcast_3 without replication took  6 ms
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8501] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KB, free 905.9 MB)
[INFO ]2016-12-29 17:25:34  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8502] - Added broadcast_3_piece0 in memory on 172.18.10.41:50250 (size: 5.5 KB, free: 906.0 MB)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8503] - Updated info of block broadcast_3_piece0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8503] - Told master about block broadcast_3_piece0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8503] - Put block broadcast_3_piece0 locally took  2 ms
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8503] - Putting block broadcast_3_piece0 without replication took  2 ms
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8504] - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8504] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[7] at javaRDD at RddServiceImpl.java:84)
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8504] - New pending partitions: Set(0)
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8504] - Adding task set 3.0 with 1 tasks
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8504] - Epoch for TaskSet 3.0: 0
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8504] - Valid locality levels for TaskSet 3.0: NO_PREF, ANY
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8505] - parentName: , name: TaskSet_3, runningTasks: 0
[INFO ]2016-12-29 17:25:34  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8506] - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5169 bytes)
[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8506] - Running task 0.0 in stage 3.0 (TID 3)
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8507] - Task 3's epoch is 0
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8507] - Getting local block broadcast_3
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8508] - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
[DEBUG]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8526] - code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, StructField(userid,StringType,true), StructField(name,StringType,true), StructField(sex,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private org.apache.spark.sql.types.StructType schema;
/* 011 */
/* 012 */
/* 013 */   public SpecificSafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     mutableRow = (MutableRow) references[references.length - 1];
/* 016 */
/* 017 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 018 */   }
/* 019 */
/* 020 */   public java.lang.Object apply(java.lang.Object _i) {
/* 021 */     InternalRow i = (InternalRow) _i;
/* 022 */
/* 023 */     values = new Object[3];
/* 024 */
/* 025 */     boolean isNull2 = i.isNullAt(0);
/* 026 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 027 */
/* 028 */     boolean isNull1 = isNull2;
/* 029 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 030 */     isNull1 = value1 == null;
/* 031 */     if (isNull1) {
/* 032 */       values[0] = null;
/* 033 */     } else {
/* 034 */       values[0] = value1;
/* 035 */     }
/* 036 */
/* 037 */     boolean isNull4 = i.isNullAt(1);
/* 038 */     UTF8String value4 = isNull4 ? null : (i.getUTF8String(1));
/* 039 */
/* 040 */     boolean isNull3 = isNull4;
/* 041 */     final java.lang.String value3 = isNull3 ? null : (java.lang.String) value4.toString();
/* 042 */     isNull3 = value3 == null;
/* 043 */     if (isNull3) {
/* 044 */       values[1] = null;
/* 045 */     } else {
/* 046 */       values[1] = value3;
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull6 = i.isNullAt(2);
/* 050 */     UTF8String value6 = isNull6 ? null : (i.getUTF8String(2));
/* 051 */
/* 052 */     boolean isNull5 = isNull6;
/* 053 */     final java.lang.String value5 = isNull5 ? null : (java.lang.String) value6.toString();
/* 054 */     isNull5 = value5 == null;
/* 055 */     if (isNull5) {
/* 056 */       values[2] = null;
/* 057 */     } else {
/* 058 */       values[2] = value5;
/* 059 */     }
/* 060 */
/* 061 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 062 */     if (false) {
/* 063 */       mutableRow.setNullAt(0);
/* 064 */     } else {
/* 065 */
/* 066 */       mutableRow.update(0, value);
/* 067 */     }
/* 068 */
/* 069 */     return mutableRow;
/* 070 */   }
/* 071 */ }

[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8526] - closed connection
[INFO ]2016-12-29 17:25:34  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8527] - Finished task 0.0 in stage 3.0 (TID 3). 2439 bytes result sent to driver
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8529] - parentName: , name: TaskSet_3, runningTasks: 0
[DEBUG]2016-12-29 17:25:34  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8529] - No tasks for locality level NO_PREF, so moving to locality level ANY
[INFO ]2016-12-29 17:25:34  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8532] - Finished task 0.0 in stage 3.0 (TID 3) in 27 ms on localhost (1/1)
[INFO ]2016-12-29 17:25:34  [task-result-getter-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8532] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO ]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8533] - ResultStage 3 (collect at RddServiceImpl.java:86) finished in 0.029 s
[DEBUG]2016-12-29 17:25:34  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8533] - After removal of stage 3, remaining stages = 0
[INFO ]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):8533] - Job 3 finished: collect at RddServiceImpl.java:86, took 0.042325 s
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8534] - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) +++
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8534] -  + declared fields: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8534] -      public static final long org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.serialVersionUID
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8534] -      private final org.apache.spark.api.java.function.Function org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.f$1
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8535] -  + declared methods: 2
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8535] -      public final java.lang.Object org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8535] -      public final boolean org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(java.lang.Object)
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8535] -  + inner classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8535] -  + outer classes: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8535] -  + outer objects: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8535] -  + populating accessed fields because this is the starting closure
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8536] -  + fields accessed by starting closure: 0
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8536] -  + there are no enclosing objects!
[DEBUG]2016-12-29 17:25:34  [nioEventLoopGroup-3-2:org.apache.spark.internal.Logging$class.logDebug(Logging.scala:58):8536] -  +++ closure <function1> (org.apache.spark.api.java.JavaRDD$$anonfun$filter$1) is now cleaned +++
